{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SL5xZZ15UY3H"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1-lY0CENrbBX"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YO4RARamPxOv",
    "outputId": "61213605-7e52-47cf-ccaf-8df33ba4b35e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "rCnT-Go9QrG-"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/content/drive/My Drive/house/data_frames/housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dFwz65V6Je7s",
    "outputId": "e9095532-faee-4dcc-f395-d9c021925ae5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2582, 270)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SX6KrtXtJ8Fn",
    "outputId": "8a18aa92-0ebf-454a-a809-9f46a0347f3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PID', 'GrLivArea', 'SalePrice', 'LotFrontage', 'LotArea',\n",
       "       'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea',\n",
       "       ...\n",
       "       'total_returns', 'adj_gross_inc', 'agi_per_ret', 'perc_business_ret',\n",
       "       'perc_farm_ret', 'perc_umemp_ret', 'perc_ssn_benefits',\n",
       "       'perc_student_loans', 'perc_child_credits', 'Perc_earned_inc_tax'],\n",
       "      dtype='object', length=270)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-72QIxR_nwVY"
   },
   "outputs": [],
   "source": [
    "df_lasso = data.drop('PID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "gHjyF8iyoUzh"
   },
   "outputs": [],
   "source": [
    "X = df_lasso.drop(\"SalePrice\", axis=1)\n",
    "y = df_lasso[\"SalePrice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "KGhI6emGohG_"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "At-Nbq4Qotvd"
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "6ArW1GGepxGF"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "DOzWuGXRp9NI",
    "outputId": "3646965f-faca-415c-8d59-8b84428bc7e6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lasso(alpha=50)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso(alpha=50)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Lasso(alpha=50)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 50\n",
    "\n",
    "lasso = Lasso(alpha=alpha)\n",
    "lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VXTCMrlwqLDh",
    "outputId": "847c6106-60c7-4ee9-e3d3-9851dc6f7141"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 13821.883371522743\n"
     ]
    }
   ],
   "source": [
    "y_pred = lasso.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cz6SPN61eXmj",
    "outputId": "b2285418-5003-42be-abff-1470992e75f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 13203.698088846833\n"
     ]
    }
   ],
   "source": [
    "y_pred = lasso.predict(X_train)\n",
    "mae = mean_absolute_error(y_train, y_pred)\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k8QMBsvhsfU7",
    "outputId": "74488db1-0c69-46ee-bc55-00fd466bfd21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Important features: ['GrLivArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'ExterQual', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinSF2', 'TotalBsmtSF', 'HeatingQC', '2ndFlrSF', 'BsmtFullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenQual', 'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'ScreenPorch', 'PoolQC', 'Fence', 'MoSold', 'YrSold', 'MSSubClass_20', 'MSSubClass_50', 'MSSubClass_60', 'MSSubClass_80', 'MSSubClass_90', 'MSSubClass_120', 'MSSubClass_160', 'MSZoning_C (all)', 'MSZoning_RL', 'Street_Grvl', 'Street_Pave', 'Alley_Grvl', 'LotShape_IR1', 'LotShape_IR2', 'LandContour_Bnk', 'LandContour_HLS', 'LandContour_Low', 'LandContour_Lvl', 'LotConfig_Corner', 'LotConfig_CulDSac', 'LotConfig_FR2', 'LandSlope_Mod', 'LandSlope_Sev', 'Neighborhood_BrDale', 'Neighborhood_BrkSide', 'Neighborhood_CollgCr', 'Neighborhood_Crawfor', 'Neighborhood_Edwards', 'Neighborhood_Gilbert', 'Neighborhood_IDOTRR', 'Neighborhood_MeadowV', 'Neighborhood_NAmes', 'Neighborhood_NPkVill', 'Neighborhood_NWAmes', 'Neighborhood_NoRidge', 'Neighborhood_NridgHt', 'Neighborhood_OldTown', 'Neighborhood_SWISU', 'Neighborhood_Somerst', 'Neighborhood_StoneBr', 'Neighborhood_Timber', 'Neighborhood_Veenker', 'Condition1_Feedr', 'Condition1_Norm', 'Condition1_PosN', 'Condition2_PosA', 'Condition2_PosN', 'BldgType_1Fam', 'BldgType_Duplex', 'BldgType_Twnhs', 'HouseStyle_1.5Fin', 'HouseStyle_1Story', 'HouseStyle_2Story', 'RoofStyle_Hip', 'RoofStyle_Mansard', 'RoofMatl_CompShg', 'RoofMatl_WdShngl', 'Exterior1st_BrkFace', 'Exterior1st_MetalSd', 'Exterior1st_Plywood', 'Exterior1st_Wd Sdng', 'Exterior2nd_BrkFace', 'Exterior2nd_HdBoard', 'Exterior2nd_Plywood', 'Exterior2nd_Wd Sdng', 'Exterior2nd_Wd Shng', 'MasVnrType_BrkFace', 'MasVnrType_None', 'Foundation_BrkTil', 'Foundation_CBlock', 'Foundation_Slab', 'Heating_GasA', 'Electrical_FuseF', 'Electrical_SBrkr', 'GarageType_2Types', 'GarageType_Attchd', 'GarageType_Basment', 'GarageType_BuiltIn', 'GarageFinish_Fin', 'GarageFinish_NA', 'GarageFinish_RFn', 'GarageFinish_Unf', 'PavedDrive_P', 'PavedDrive_Y', 'SaleType_ConLD', 'SaleType_WD ', 'SaleCondition_Abnorml', 'SaleCondition_Family', 'SaleCondition_Normal', 'SaleCondition_Partial', 'TtlVal_AsrYr', 'agi_per_ret']\n"
     ]
    }
   ],
   "source": [
    "important_features = [feature for feature, coef in zip(X.columns, lasso.coef_) if coef != 0]\n",
    "print(\"Important features:\", important_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "0XcNmDFEbBK9"
   },
   "outputs": [],
   "source": [
    "important_features_coef = [coef for feature, coef in zip(X.columns, lasso.coef_) if coef != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oklTIQiDbLl-",
    "outputId": "fd06888c-1c1f-4646-e13c-5edad55d398b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(important_features_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "S_r2cIeubT6N"
   },
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame(\n",
    "    {'Feature':important_features,\n",
    "     'Coefficient': important_features_coef   \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "pvGbv_1VbqBd",
    "outputId": "1108fab2-a345-41ac-835d-af3a8a592baa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-dd2180ba-7dcf-47d5-b350-616af9e9a490\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GrLivArea</td>\n",
       "      <td>126847.771679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OverallQual</td>\n",
       "      <td>61862.439857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OverallCond</td>\n",
       "      <td>29254.217577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YearBuilt</td>\n",
       "      <td>6043.746112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>YearRemodAdd</td>\n",
       "      <td>3401.207540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>SaleCondition_Family</td>\n",
       "      <td>-11733.641905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>SaleCondition_Normal</td>\n",
       "      <td>4296.642195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>SaleCondition_Partial</td>\n",
       "      <td>10766.577888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>TtlVal_AsrYr</td>\n",
       "      <td>276982.920203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>agi_per_ret</td>\n",
       "      <td>-1289.377550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123 rows × 2 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd2180ba-7dcf-47d5-b350-616af9e9a490')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-dd2180ba-7dcf-47d5-b350-616af9e9a490 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-dd2180ba-7dcf-47d5-b350-616af9e9a490');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                   Feature    Coefficient\n",
       "0                GrLivArea  126847.771679\n",
       "1              OverallQual   61862.439857\n",
       "2              OverallCond   29254.217577\n",
       "3                YearBuilt    6043.746112\n",
       "4             YearRemodAdd    3401.207540\n",
       "..                     ...            ...\n",
       "118   SaleCondition_Family  -11733.641905\n",
       "119   SaleCondition_Normal    4296.642195\n",
       "120  SaleCondition_Partial   10766.577888\n",
       "121           TtlVal_AsrYr  276982.920203\n",
       "122            agi_per_ret   -1289.377550\n",
       "\n",
       "[123 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "dqUqcuYwbusL"
   },
   "outputs": [],
   "source": [
    "sorted_features = feature_importance.reindex(feature_importance.Coefficient.abs().sort_values(ascending=False).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "aTkOEgovb4D7",
    "outputId": "e2ebabd9-bb2d-427d-c2a3-516787a24ce8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-95eebe9c-94ce-4e7a-ac8b-7d18dc538ad0\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>TtlVal_AsrYr</td>\n",
       "      <td>276982.920203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GrLivArea</td>\n",
       "      <td>126847.771679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Condition2_PosN</td>\n",
       "      <td>-76082.131543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OverallQual</td>\n",
       "      <td>61862.439857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Condition2_PosA</td>\n",
       "      <td>45875.423242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-95eebe9c-94ce-4e7a-ac8b-7d18dc538ad0')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-95eebe9c-94ce-4e7a-ac8b-7d18dc538ad0 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-95eebe9c-94ce-4e7a-ac8b-7d18dc538ad0');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "             Feature    Coefficient\n",
       "121     TtlVal_AsrYr  276982.920203\n",
       "0          GrLivArea  126847.771679\n",
       "77   Condition2_PosN  -76082.131543\n",
       "1        OverallQual   61862.439857\n",
       "76   Condition2_PosA   45875.423242"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_features.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hE3ASLHpbuQf"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "72tOlHFcZhgc",
    "outputId": "8b0b7cf2-6da5-481d-d4ea-d840b9908cd5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GrLivArea', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond',\n",
       "       'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'ExterQual', 'ExterCond',\n",
       "       ...\n",
       "       'total_returns', 'adj_gross_inc', 'agi_per_ret', 'perc_business_ret',\n",
       "       'perc_farm_ret', 'perc_umemp_ret', 'perc_ssn_benefits',\n",
       "       'perc_student_loans', 'perc_child_credits', 'Perc_earned_inc_tax'],\n",
       "      dtype='object', length=268)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i0pvl4hQaVv-",
    "outputId": "8ddd4c11-9446-4d56-b13e-67ed87f70249"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.26847772e+05,  0.00000000e+00,  0.00000000e+00,  6.18624399e+04,\n",
       "        2.92542176e+04,  6.04374611e+03,  3.40120754e+03,  3.89569578e+04,\n",
       "        2.07454571e+04, -0.00000000e+00,  4.08701771e+03, -8.54579888e+03,\n",
       "        1.54578298e+04, -1.69215765e+02,  3.39031288e+04,  0.00000000e+00,\n",
       "        8.44210149e+03, -0.00000000e+00,  1.49585545e+04,  6.12351840e+03,\n",
       "        0.00000000e+00,  8.65946991e+03,  0.00000000e+00,  5.93883363e+03,\n",
       "        0.00000000e+00,  0.00000000e+00,  2.65856774e+03, -7.41989845e+03,\n",
       "        0.00000000e+00,  1.61126077e+04,  2.76434601e+03,  2.34901014e+04,\n",
       "        1.80778465e+04,  0.00000000e+00, -0.00000000e+00,  5.46403213e+03,\n",
       "        1.74900432e+04, -0.00000000e+00, -0.00000000e+00,  1.16406638e+03,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.61156841e+04,\n",
       "       -0.00000000e+00,  1.45433411e+04,  5.01653723e+01, -0.00000000e+00,\n",
       "       -1.37008466e+03, -1.03676204e+03,  3.13580541e+03, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  1.54319419e+02, -1.18823995e+03,\n",
       "        0.00000000e+00,  0.00000000e+00, -1.17507001e+03,  0.00000000e+00,\n",
       "        2.61511981e+03, -2.94826138e+03, -0.00000000e+00, -7.35019127e+02,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -2.13566747e+03,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  4.68349970e+03,\n",
       "       -0.00000000e+00, -2.54951880e+03,  1.04295797e-11, -1.21832443e+03,\n",
       "        0.00000000e+00,  0.00000000e+00, -4.07211847e+02,  1.25910679e+03,\n",
       "        0.00000000e+00, -0.00000000e+00, -8.43919065e+03,  2.38414123e+03,\n",
       "       -3.84608887e+03,  1.09795349e+02,  0.00000000e+00, -0.00000000e+00,\n",
       "        2.99940157e+02,  2.16004453e+03, -1.58972033e+03, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  3.29819102e+03, -1.43524337e+02,\n",
       "       -0.00000000e+00,  0.00000000e+00,  2.40508050e+03,  7.64967756e+02,\n",
       "        0.00000000e+00, -1.56977531e+03,  1.36738684e+03, -5.37975035e+03,\n",
       "       -1.25357840e+03,  0.00000000e+00,  0.00000000e+00, -2.49568235e+03,\n",
       "        0.00000000e+00,  8.40685524e+02, -0.00000000e+00, -5.31400261e+03,\n",
       "        6.97202425e+03, -4.02021321e+03,  2.03246288e+04,  2.02869939e+04,\n",
       "       -5.96335375e+03, -7.10889928e+03,  0.00000000e+00, -0.00000000e+00,\n",
       "        1.10340609e+04,  2.55440408e+04, -2.30232061e+03, -3.73078187e+03,\n",
       "       -0.00000000e+00, -1.35791688e+02,  4.49006286e+03, -0.00000000e+00,\n",
       "        1.13511339e+03, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        4.58754232e+04, -7.60821315e+04, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  9.55904156e+03, -0.00000000e+00,  2.92548380e+02,\n",
       "       -3.26525930e+03, -0.00000000e+00, -1.98701982e+03,  0.00000000e+00,\n",
       "        1.78944541e+03,  0.00000000e+00,  0.00000000e+00, -1.32633580e+03,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  2.65558804e+03, -1.29710139e+03, -0.00000000e+00,\n",
       "       -9.53218685e+02,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00,  4.09489838e+04, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  1.44537194e+04, -0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00,  2.55465045e+03,\n",
       "       -2.41463706e+03,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -2.74850220e+03, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -4.14681732e+02,  0.00000000e+00,  0.00000000e+00,\n",
       "       -1.80923032e+03,  0.00000000e+00, -0.00000000e+00, -2.42009038e+03,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        9.28491088e+01, -1.39269468e+03, -0.00000000e+00, -2.37162360e+03,\n",
       "        3.04096323e+03,  0.00000000e+00, -7.11746029e+02, -2.13182490e+03,\n",
       "        0.00000000e+00,  3.12173247e+03,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -2.23255074e+03,  0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  3.03513648e+03,  0.00000000e+00,  0.00000000e+00,\n",
       "       -1.60163452e+02, -1.25078554e+03,  1.79486948e+02, -2.72666755e+03,\n",
       "       -1.42085928e+03,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        2.25047663e+03,  4.83332450e+03, -3.43812928e+03, -4.32618941e+02,\n",
       "       -0.00000000e+00, -2.00906377e+02,  1.10326317e+02,  0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  5.68632048e+02,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -8.96205215e+02, -4.56661034e+03, -0.00000000e+00,\n",
       "        0.00000000e+00, -1.17336419e+04,  4.29664220e+03,  1.07665779e+04,\n",
       "        2.76982920e+05, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -1.28937755e+03, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "id": "QLwbV8NsZZYl",
    "outputId": "3ccc01f8-daf8-4c08-ade5-2865940e114c"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-da94023b5f97>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    'Feature': X.columns for feature, coef in zip(X.columns, lasso.coef_),\u001b[0m\n\u001b[0m                                                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns for feature, coef in zip(X.columns, lasso.coef_),\n",
    "    'Coefficient': lasso.coef_\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PjQ1q296tD5s",
    "outputId": "b7042257-b9a3-4560-a0a4-487bc6f3724a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(important_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "-CD8CgYRtPn8",
    "outputId": "949f6713-3391-4222-ab21-5da7c547429a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-0065ae30-5abd-4689-aacd-3b3006c5b81e\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YearRemodAdd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577</th>\n",
       "      <td>1950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2578</th>\n",
       "      <td>1955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2579</th>\n",
       "      <td>1950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2580</th>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2581</th>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2582 rows × 1 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0065ae30-5abd-4689-aacd-3b3006c5b81e')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-0065ae30-5abd-4689-aacd-3b3006c5b81e button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-0065ae30-5abd-4689-aacd-3b3006c5b81e');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      YearRemodAdd\n",
       "0             1950\n",
       "1             1984\n",
       "2             2007\n",
       "3             2003\n",
       "4             2001\n",
       "...            ...\n",
       "2577          1950\n",
       "2578          1955\n",
       "2579          1950\n",
       "2580          2000\n",
       "2581          1994\n",
       "\n",
       "[2582 rows x 1 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['YearRemodAdd']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ohrZNXNiwMWg"
   },
   "outputs": [],
   "source": [
    "df = data.drop('PID',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v9PF3LQVwUOK"
   },
   "outputs": [],
   "source": [
    "df = df[important_features + ['SalePrice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "7Jhlaj4WwhIa",
    "outputId": "fd171dfe-6319-4a5e-e5d7-ba0b5c300e2b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-8a47fd55-8e63-4300-999e-ebb37d23e288\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>...</th>\n",
       "      <th>PavedDrive_Y</th>\n",
       "      <th>SaleType_ConLD</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_Abnorml</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "      <th>TtlVal_AsrYr</th>\n",
       "      <th>agi_per_ret</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>856</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1939</td>\n",
       "      <td>1950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149000.000000</td>\n",
       "      <td>73571.327182</td>\n",
       "      <td>126000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1049</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1984</td>\n",
       "      <td>1984</td>\n",
       "      <td>149.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>174100.000000</td>\n",
       "      <td>77236.460177</td>\n",
       "      <td>139500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1930</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>164300.000000</td>\n",
       "      <td>73571.327182</td>\n",
       "      <td>124900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1039</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1900</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>124400.000000</td>\n",
       "      <td>73571.327182</td>\n",
       "      <td>114000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1665</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>2001</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>257100.000000</td>\n",
       "      <td>73571.327182</td>\n",
       "      <td>227000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577</th>\n",
       "      <td>952</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1916</td>\n",
       "      <td>1950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>138500.000000</td>\n",
       "      <td>73571.327182</td>\n",
       "      <td>121000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2578</th>\n",
       "      <td>1733</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1955</td>\n",
       "      <td>1955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>185100.000000</td>\n",
       "      <td>77236.460177</td>\n",
       "      <td>139600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2579</th>\n",
       "      <td>2002</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1949</td>\n",
       "      <td>1950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>221337.445022</td>\n",
       "      <td>75180.309062</td>\n",
       "      <td>145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2580</th>\n",
       "      <td>1842</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>144.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>265200.000000</td>\n",
       "      <td>77236.460177</td>\n",
       "      <td>217500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2581</th>\n",
       "      <td>1911</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1993</td>\n",
       "      <td>1994</td>\n",
       "      <td>125.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>250600.000000</td>\n",
       "      <td>77236.460177</td>\n",
       "      <td>215000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2582 rows × 124 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a47fd55-8e63-4300-999e-ebb37d23e288')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-8a47fd55-8e63-4300-999e-ebb37d23e288 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-8a47fd55-8e63-4300-999e-ebb37d23e288');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      GrLivArea  OverallQual  OverallCond  YearBuilt  YearRemodAdd  \\\n",
       "0           856            6            6       1939          1950   \n",
       "1          1049            5            5       1984          1984   \n",
       "2          1001            5            9       1930          2007   \n",
       "3          1039            4            8       1900          2003   \n",
       "4          1665            8            6       2001          2001   \n",
       "...         ...          ...          ...        ...           ...   \n",
       "2577        952            6            6       1916          1950   \n",
       "2578       1733            3            5       1955          1955   \n",
       "2579       2002            5            6       1949          1950   \n",
       "2580       1842            7            5       2000          2000   \n",
       "2581       1911            8            5       1993          1994   \n",
       "\n",
       "      MasVnrArea  ExterQual  BsmtQual  BsmtCond  BsmtExposure  ...  \\\n",
       "0            0.0          3         3         3             1  ...   \n",
       "1          149.0          4         4         3             2  ...   \n",
       "2            0.0          4         3         3             1  ...   \n",
       "3            0.0          4         2         3             1  ...   \n",
       "4            0.0          4         4         3             1  ...   \n",
       "...          ...        ...       ...       ...           ...  ...   \n",
       "2577         0.0          3         3         3             1  ...   \n",
       "2578         0.0          3         0         0             0  ...   \n",
       "2579         0.0          3         3         3             1  ...   \n",
       "2580       144.0          4         4         3             1  ...   \n",
       "2581       125.0          4         4         3             1  ...   \n",
       "\n",
       "      PavedDrive_Y  SaleType_ConLD  SaleType_WD   SaleCondition_Abnorml  \\\n",
       "0                1               0             1                      0   \n",
       "1                1               0             1                      0   \n",
       "2                0               0             1                      0   \n",
       "3                0               0             1                      0   \n",
       "4                1               0             1                      0   \n",
       "...            ...             ...           ...                    ...   \n",
       "2577             0               0             1                      0   \n",
       "2578             1               0             1                      0   \n",
       "2579             1               0             1                      0   \n",
       "2580             1               0             1                      0   \n",
       "2581             1               0             1                      0   \n",
       "\n",
       "      SaleCondition_Family  SaleCondition_Normal  SaleCondition_Partial  \\\n",
       "0                        0                     1                      0   \n",
       "1                        0                     1                      0   \n",
       "2                        0                     1                      0   \n",
       "3                        0                     1                      0   \n",
       "4                        0                     1                      0   \n",
       "...                    ...                   ...                    ...   \n",
       "2577                     0                     1                      0   \n",
       "2578                     0                     1                      0   \n",
       "2579                     0                     1                      0   \n",
       "2580                     0                     1                      0   \n",
       "2581                     0                     1                      0   \n",
       "\n",
       "       TtlVal_AsrYr   agi_per_ret  SalePrice  \n",
       "0     149000.000000  73571.327182     126000  \n",
       "1     174100.000000  77236.460177     139500  \n",
       "2     164300.000000  73571.327182     124900  \n",
       "3     124400.000000  73571.327182     114000  \n",
       "4     257100.000000  73571.327182     227000  \n",
       "...             ...           ...        ...  \n",
       "2577  138500.000000  73571.327182     121000  \n",
       "2578  185100.000000  77236.460177     139600  \n",
       "2579  221337.445022  75180.309062     145000  \n",
       "2580  265200.000000  77236.460177     217500  \n",
       "2581  250600.000000  77236.460177     215000  \n",
       "\n",
       "[2582 rows x 124 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eU1KxgBXwsS3"
   },
   "outputs": [],
   "source": [
    "X = df.drop('SalePrice', axis=1)\n",
    "y = df['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xnZWP-_ZwuJk"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gaYGgan6w0fe"
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0OjrnXDvxN7e"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(83, activation='relu', input_shape=(123,)))\n",
    "model.add(keras.layers.Dense(83, activation='relu'))\n",
    "model.add(keras.layers.Dense(1))\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=MeanSquaredError(),metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0pP6nYc08URe"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ee_FirVc_gDO"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import MeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PfcS5EKF8PJn"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=100, mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MZjDJ2FS4tKk",
    "outputId": "1bd07d34-23fa-4719-d1f3-53b937519411"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 187807008.0000 - mae: 9412.4766 - val_loss: 472514240.0000 - val_mae: 12689.0752\n",
      "Epoch 3502/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 187434704.0000 - mae: 9411.5215 - val_loss: 472842400.0000 - val_mae: 12682.2871\n",
      "Epoch 3503/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 187862512.0000 - mae: 9407.2861 - val_loss: 474014272.0000 - val_mae: 12788.2832\n",
      "Epoch 3504/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 188680400.0000 - mae: 9438.1494 - val_loss: 473152224.0000 - val_mae: 12746.2188\n",
      "Epoch 3505/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 187520416.0000 - mae: 9422.2861 - val_loss: 472744416.0000 - val_mae: 12696.5244\n",
      "Epoch 3506/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 186898848.0000 - mae: 9390.5498 - val_loss: 473248224.0000 - val_mae: 12738.4004\n",
      "Epoch 3507/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 188141952.0000 - mae: 9423.0996 - val_loss: 472742496.0000 - val_mae: 12708.1680\n",
      "Epoch 3508/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 187630128.0000 - mae: 9427.6846 - val_loss: 473881696.0000 - val_mae: 12757.1143\n",
      "Epoch 3509/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 187069392.0000 - mae: 9416.7617 - val_loss: 473519424.0000 - val_mae: 12716.7998\n",
      "Epoch 3510/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 187352640.0000 - mae: 9413.8330 - val_loss: 473057440.0000 - val_mae: 12712.7227\n",
      "Epoch 3511/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 186866912.0000 - mae: 9395.9453 - val_loss: 473686656.0000 - val_mae: 12748.3516\n",
      "Epoch 3512/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 186380560.0000 - mae: 9385.6484 - val_loss: 473404288.0000 - val_mae: 12697.7490\n",
      "Epoch 3513/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 187618896.0000 - mae: 9410.5625 - val_loss: 473303936.0000 - val_mae: 12695.1426\n",
      "Epoch 3514/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 188178896.0000 - mae: 9397.0996 - val_loss: 472849344.0000 - val_mae: 12695.4844\n",
      "Epoch 3515/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 186428896.0000 - mae: 9406.4766 - val_loss: 474304160.0000 - val_mae: 12762.3545\n",
      "Epoch 3516/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 186797344.0000 - mae: 9384.7295 - val_loss: 473600384.0000 - val_mae: 12686.7158\n",
      "Epoch 3517/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 187072128.0000 - mae: 9433.2598 - val_loss: 473726432.0000 - val_mae: 12706.0928\n",
      "Epoch 3518/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 187266128.0000 - mae: 9398.5605 - val_loss: 473655584.0000 - val_mae: 12698.9902\n",
      "Epoch 3519/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 186662944.0000 - mae: 9376.5791 - val_loss: 475150048.0000 - val_mae: 12822.0693\n",
      "Epoch 3520/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 188282992.0000 - mae: 9462.5312 - val_loss: 474004448.0000 - val_mae: 12727.5586\n",
      "Epoch 3521/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 186326656.0000 - mae: 9387.7539 - val_loss: 474479680.0000 - val_mae: 12768.3389\n",
      "Epoch 3522/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 186244112.0000 - mae: 9376.5381 - val_loss: 474635040.0000 - val_mae: 12774.2227\n",
      "Epoch 3523/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 186644480.0000 - mae: 9387.9170 - val_loss: 473864448.0000 - val_mae: 12709.9375\n",
      "Epoch 3524/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 186364448.0000 - mae: 9379.9590 - val_loss: 474526368.0000 - val_mae: 12770.8330\n",
      "Epoch 3525/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 186070848.0000 - mae: 9384.2480 - val_loss: 474352672.0000 - val_mae: 12737.2207\n",
      "Epoch 3526/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 187406320.0000 - mae: 9403.3965 - val_loss: 474048864.0000 - val_mae: 12703.7822\n",
      "Epoch 3527/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 186493360.0000 - mae: 9407.7803 - val_loss: 473954560.0000 - val_mae: 12701.6152\n",
      "Epoch 3528/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 187401088.0000 - mae: 9373.2061 - val_loss: 475501184.0000 - val_mae: 12808.8379\n",
      "Epoch 3529/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 186559216.0000 - mae: 9401.0068 - val_loss: 475854304.0000 - val_mae: 12812.9307\n",
      "Epoch 3530/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 185738352.0000 - mae: 9395.6318 - val_loss: 474018080.0000 - val_mae: 12704.8193\n",
      "Epoch 3531/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 186636000.0000 - mae: 9416.0752 - val_loss: 477493024.0000 - val_mae: 12917.0605\n",
      "Epoch 3532/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 186717584.0000 - mae: 9394.8818 - val_loss: 475504768.0000 - val_mae: 12799.2637\n",
      "Epoch 3533/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 186155776.0000 - mae: 9384.5742 - val_loss: 475380992.0000 - val_mae: 12805.4189\n",
      "Epoch 3534/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 186530928.0000 - mae: 9390.3105 - val_loss: 477121216.0000 - val_mae: 12866.2373\n",
      "Epoch 3535/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 185765760.0000 - mae: 9364.1650 - val_loss: 473915584.0000 - val_mae: 12731.5137\n",
      "Epoch 3536/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 186276592.0000 - mae: 9390.2178 - val_loss: 474237376.0000 - val_mae: 12757.9746\n",
      "Epoch 3537/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 185614976.0000 - mae: 9399.6904 - val_loss: 474167520.0000 - val_mae: 12701.9229\n",
      "Epoch 3538/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 185808304.0000 - mae: 9357.0234 - val_loss: 474560576.0000 - val_mae: 12764.9375\n",
      "Epoch 3539/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 186017088.0000 - mae: 9384.3672 - val_loss: 475474624.0000 - val_mae: 12810.2891\n",
      "Epoch 3540/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 185672000.0000 - mae: 9374.0400 - val_loss: 474116864.0000 - val_mae: 12720.2822\n",
      "Epoch 3541/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 185247424.0000 - mae: 9356.8037 - val_loss: 474974016.0000 - val_mae: 12776.8682\n",
      "Epoch 3542/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 185549568.0000 - mae: 9367.4238 - val_loss: 474258240.0000 - val_mae: 12737.3701\n",
      "Epoch 3543/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 185569648.0000 - mae: 9374.0117 - val_loss: 474261344.0000 - val_mae: 12743.2432\n",
      "Epoch 3544/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 185799104.0000 - mae: 9378.6846 - val_loss: 473630432.0000 - val_mae: 12720.8086\n",
      "Epoch 3545/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 185015904.0000 - mae: 9355.4697 - val_loss: 474218976.0000 - val_mae: 12741.9434\n",
      "Epoch 3546/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 184956688.0000 - mae: 9355.7852 - val_loss: 474982560.0000 - val_mae: 12794.9814\n",
      "Epoch 3547/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 186897808.0000 - mae: 9397.3555 - val_loss: 474061600.0000 - val_mae: 12703.6973\n",
      "Epoch 3548/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 185044112.0000 - mae: 9382.0283 - val_loss: 474175520.0000 - val_mae: 12736.7842\n",
      "Epoch 3549/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 185528464.0000 - mae: 9379.9287 - val_loss: 475331808.0000 - val_mae: 12803.2207\n",
      "Epoch 3550/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 184614224.0000 - mae: 9346.4482 - val_loss: 473861088.0000 - val_mae: 12715.5869\n",
      "Epoch 3551/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 185568000.0000 - mae: 9396.8496 - val_loss: 473909408.0000 - val_mae: 12713.5303\n",
      "Epoch 3552/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 185221216.0000 - mae: 9368.2861 - val_loss: 474472320.0000 - val_mae: 12780.3340\n",
      "Epoch 3553/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 184812672.0000 - mae: 9350.7578 - val_loss: 474561408.0000 - val_mae: 12773.4043\n",
      "Epoch 3554/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 185342592.0000 - mae: 9423.1631 - val_loss: 474947520.0000 - val_mae: 12715.8496\n",
      "Epoch 3555/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 185879024.0000 - mae: 9376.0742 - val_loss: 474607680.0000 - val_mae: 12778.6572\n",
      "Epoch 3556/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 185389520.0000 - mae: 9359.9863 - val_loss: 474144864.0000 - val_mae: 12752.4531\n",
      "Epoch 3557/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 185260560.0000 - mae: 9374.7480 - val_loss: 474365120.0000 - val_mae: 12735.0723\n",
      "Epoch 3558/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 184672016.0000 - mae: 9360.4580 - val_loss: 474193888.0000 - val_mae: 12722.3730\n",
      "Epoch 3559/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 184262464.0000 - mae: 9337.7520 - val_loss: 475032928.0000 - val_mae: 12794.2949\n",
      "Epoch 3560/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 184813008.0000 - mae: 9382.9590 - val_loss: 474608064.0000 - val_mae: 12714.7334\n",
      "Epoch 3561/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 185071296.0000 - mae: 9367.6729 - val_loss: 475237056.0000 - val_mae: 12819.5039\n",
      "Epoch 3562/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 184739456.0000 - mae: 9367.3594 - val_loss: 473894304.0000 - val_mae: 12759.5342\n",
      "Epoch 3563/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 185034672.0000 - mae: 9381.8945 - val_loss: 474307520.0000 - val_mae: 12739.5146\n",
      "Epoch 3564/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 184580896.0000 - mae: 9363.6816 - val_loss: 474330080.0000 - val_mae: 12746.9238\n",
      "Epoch 3565/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 184276080.0000 - mae: 9343.5117 - val_loss: 475195392.0000 - val_mae: 12824.5068\n",
      "Epoch 3566/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 184469264.0000 - mae: 9359.5840 - val_loss: 474351712.0000 - val_mae: 12758.0068\n",
      "Epoch 3567/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 185415296.0000 - mae: 9381.2607 - val_loss: 477353088.0000 - val_mae: 12896.0352\n",
      "Epoch 3568/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 184603568.0000 - mae: 9355.8818 - val_loss: 474701792.0000 - val_mae: 12783.9541\n",
      "Epoch 3569/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 184289872.0000 - mae: 9361.2002 - val_loss: 473851424.0000 - val_mae: 12727.3496\n",
      "Epoch 3570/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 183786768.0000 - mae: 9333.3604 - val_loss: 475938176.0000 - val_mae: 12862.3516\n",
      "Epoch 3571/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 184511504.0000 - mae: 9406.6055 - val_loss: 474858464.0000 - val_mae: 12716.3496\n",
      "Epoch 3572/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 184518192.0000 - mae: 9353.9990 - val_loss: 475031360.0000 - val_mae: 12788.6182\n",
      "Epoch 3573/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 184216816.0000 - mae: 9362.7910 - val_loss: 474471232.0000 - val_mae: 12770.1514\n",
      "Epoch 3574/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 184843712.0000 - mae: 9350.0439 - val_loss: 476483168.0000 - val_mae: 12872.3340\n",
      "Epoch 3575/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 184184880.0000 - mae: 9356.3896 - val_loss: 474819616.0000 - val_mae: 12798.5215\n",
      "Epoch 3576/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 183821024.0000 - mae: 9351.8398 - val_loss: 474043840.0000 - val_mae: 12726.1709\n",
      "Epoch 3577/6000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 184118480.0000 - mae: 9334.1035 - val_loss: 473934240.0000 - val_mae: 12739.9092\n",
      "Epoch 3578/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 183710960.0000 - mae: 9339.0059 - val_loss: 473965408.0000 - val_mae: 12749.3643\n",
      "Epoch 3579/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 184659776.0000 - mae: 9361.0283 - val_loss: 475312352.0000 - val_mae: 12821.2061\n",
      "Epoch 3580/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 183949600.0000 - mae: 9339.7939 - val_loss: 474312640.0000 - val_mae: 12765.8818\n",
      "Epoch 3581/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 184176160.0000 - mae: 9342.4053 - val_loss: 473849440.0000 - val_mae: 12729.4121\n",
      "Epoch 3582/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 183825760.0000 - mae: 9327.4707 - val_loss: 475000896.0000 - val_mae: 12790.9805\n",
      "Epoch 3583/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 183728416.0000 - mae: 9339.7090 - val_loss: 474917440.0000 - val_mae: 12808.7217\n",
      "Epoch 3584/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 183983120.0000 - mae: 9350.8604 - val_loss: 474182560.0000 - val_mae: 12729.3428\n",
      "Epoch 3585/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 183523504.0000 - mae: 9358.2588 - val_loss: 474182688.0000 - val_mae: 12743.7168\n",
      "Epoch 3586/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 184845520.0000 - mae: 9360.2393 - val_loss: 474245472.0000 - val_mae: 12735.0859\n",
      "Epoch 3587/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 184925104.0000 - mae: 9367.7783 - val_loss: 474038592.0000 - val_mae: 12722.2480\n",
      "Epoch 3588/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 183949840.0000 - mae: 9355.9736 - val_loss: 475064832.0000 - val_mae: 12804.3633\n",
      "Epoch 3589/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 183353600.0000 - mae: 9314.0059 - val_loss: 474740960.0000 - val_mae: 12789.8672\n",
      "Epoch 3590/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 184122864.0000 - mae: 9348.2266 - val_loss: 474257280.0000 - val_mae: 12756.5605\n",
      "Epoch 3591/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 184152448.0000 - mae: 9370.9326 - val_loss: 475354336.0000 - val_mae: 12822.6523\n",
      "Epoch 3592/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 183168912.0000 - mae: 9344.7568 - val_loss: 474557408.0000 - val_mae: 12763.4482\n",
      "Epoch 3593/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 182893152.0000 - mae: 9314.2812 - val_loss: 474132096.0000 - val_mae: 12750.9932\n",
      "Epoch 3594/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 184357664.0000 - mae: 9382.4775 - val_loss: 475772672.0000 - val_mae: 12725.4951\n",
      "Epoch 3595/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 185531664.0000 - mae: 9405.9160 - val_loss: 474488288.0000 - val_mae: 12746.8525\n",
      "Epoch 3596/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 183121392.0000 - mae: 9324.4756 - val_loss: 474771200.0000 - val_mae: 12793.4736\n",
      "Epoch 3597/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 183656464.0000 - mae: 9379.9053 - val_loss: 475017632.0000 - val_mae: 12719.0371\n",
      "Epoch 3598/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 184616592.0000 - mae: 9346.5488 - val_loss: 474036896.0000 - val_mae: 12747.8926\n",
      "Epoch 3599/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 183097872.0000 - mae: 9319.1963 - val_loss: 474126592.0000 - val_mae: 12751.6807\n",
      "Epoch 3600/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 182618288.0000 - mae: 9315.0645 - val_loss: 474575744.0000 - val_mae: 12776.9697\n",
      "Epoch 3601/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 182834320.0000 - mae: 9310.7080 - val_loss: 474962368.0000 - val_mae: 12812.0693\n",
      "Epoch 3602/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 182624320.0000 - mae: 9348.9746 - val_loss: 474089056.0000 - val_mae: 12740.0293\n",
      "Epoch 3603/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 183758880.0000 - mae: 9353.3213 - val_loss: 474209856.0000 - val_mae: 12719.3291\n",
      "Epoch 3604/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 184420192.0000 - mae: 9375.0869 - val_loss: 477213632.0000 - val_mae: 12909.6719\n",
      "Epoch 3605/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 183040464.0000 - mae: 9321.8643 - val_loss: 476195168.0000 - val_mae: 12840.9082\n",
      "Epoch 3606/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 182495984.0000 - mae: 9321.5791 - val_loss: 474293280.0000 - val_mae: 12744.0957\n",
      "Epoch 3607/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 182523568.0000 - mae: 9309.8271 - val_loss: 474381344.0000 - val_mae: 12777.2236\n",
      "Epoch 3608/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 183120256.0000 - mae: 9324.5791 - val_loss: 476780352.0000 - val_mae: 12869.9395\n",
      "Epoch 3609/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 183031264.0000 - mae: 9335.0850 - val_loss: 474778208.0000 - val_mae: 12773.8594\n",
      "Epoch 3610/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 182893568.0000 - mae: 9338.8291 - val_loss: 474416576.0000 - val_mae: 12726.3271\n",
      "Epoch 3611/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 182658544.0000 - mae: 9342.5332 - val_loss: 474081696.0000 - val_mae: 12729.3516\n",
      "Epoch 3612/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 181958736.0000 - mae: 9272.5957 - val_loss: 478729408.0000 - val_mae: 12966.9551\n",
      "Epoch 3613/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 183086096.0000 - mae: 9384.6553 - val_loss: 474294400.0000 - val_mae: 12754.0840\n",
      "Epoch 3614/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 182182640.0000 - mae: 9297.1201 - val_loss: 474844032.0000 - val_mae: 12789.6094\n",
      "Epoch 3615/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 182342064.0000 - mae: 9316.7080 - val_loss: 474393632.0000 - val_mae: 12735.0947\n",
      "Epoch 3616/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 181921680.0000 - mae: 9301.9795 - val_loss: 474499648.0000 - val_mae: 12763.7422\n",
      "Epoch 3617/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 182014256.0000 - mae: 9309.6475 - val_loss: 475407936.0000 - val_mae: 12822.6172\n",
      "Epoch 3618/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 181728256.0000 - mae: 9306.1133 - val_loss: 474581632.0000 - val_mae: 12769.8516\n",
      "Epoch 3619/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 181789568.0000 - mae: 9289.5781 - val_loss: 474823648.0000 - val_mae: 12784.2168\n",
      "Epoch 3620/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 181671184.0000 - mae: 9314.5322 - val_loss: 474911808.0000 - val_mae: 12737.8164\n",
      "Epoch 3621/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 182437264.0000 - mae: 9322.9639 - val_loss: 474411264.0000 - val_mae: 12751.5508\n",
      "Epoch 3622/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 181795040.0000 - mae: 9302.8652 - val_loss: 473968480.0000 - val_mae: 12752.1582\n",
      "Epoch 3623/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 181750368.0000 - mae: 9302.7129 - val_loss: 476135200.0000 - val_mae: 12843.8652\n",
      "Epoch 3624/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 181399744.0000 - mae: 9317.1475 - val_loss: 474625408.0000 - val_mae: 12747.6055\n",
      "Epoch 3625/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 181920848.0000 - mae: 9299.1797 - val_loss: 475258432.0000 - val_mae: 12818.2021\n",
      "Epoch 3626/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 181769360.0000 - mae: 9295.5811 - val_loss: 474855008.0000 - val_mae: 12800.4385\n",
      "Epoch 3627/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 181759360.0000 - mae: 9296.3564 - val_loss: 474870592.0000 - val_mae: 12790.5098\n",
      "Epoch 3628/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 181384464.0000 - mae: 9308.5068 - val_loss: 474540928.0000 - val_mae: 12760.4961\n",
      "Epoch 3629/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 182308640.0000 - mae: 9307.2666 - val_loss: 475159360.0000 - val_mae: 12804.5068\n",
      "Epoch 3630/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 181194624.0000 - mae: 9294.4355 - val_loss: 474036928.0000 - val_mae: 12730.8174\n",
      "Epoch 3631/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 181260960.0000 - mae: 9290.4434 - val_loss: 474901952.0000 - val_mae: 12780.8701\n",
      "Epoch 3632/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 181722800.0000 - mae: 9296.6650 - val_loss: 474949824.0000 - val_mae: 12775.7002\n",
      "Epoch 3633/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 181370736.0000 - mae: 9293.0566 - val_loss: 477214912.0000 - val_mae: 12899.0820\n",
      "Epoch 3634/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 181880720.0000 - mae: 9326.1445 - val_loss: 474192224.0000 - val_mae: 12755.6299\n",
      "Epoch 3635/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 181072272.0000 - mae: 9301.6016 - val_loss: 475096320.0000 - val_mae: 12791.5410\n",
      "Epoch 3636/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 181271920.0000 - mae: 9285.9111 - val_loss: 476330336.0000 - val_mae: 12862.5977\n",
      "Epoch 3637/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 181790272.0000 - mae: 9336.7275 - val_loss: 474980832.0000 - val_mae: 12789.5186\n",
      "Epoch 3638/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 181395456.0000 - mae: 9314.7021 - val_loss: 474512800.0000 - val_mae: 12736.0654\n",
      "Epoch 3639/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 180981392.0000 - mae: 9291.4521 - val_loss: 474312192.0000 - val_mae: 12780.6113\n",
      "Epoch 3640/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 180747728.0000 - mae: 9263.0303 - val_loss: 475396128.0000 - val_mae: 12819.7949\n",
      "Epoch 3641/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 180947024.0000 - mae: 9287.1562 - val_loss: 474280000.0000 - val_mae: 12735.9531\n",
      "Epoch 3642/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 180930272.0000 - mae: 9303.3174 - val_loss: 475725536.0000 - val_mae: 12826.7949\n",
      "Epoch 3643/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 181014064.0000 - mae: 9292.6660 - val_loss: 475535328.0000 - val_mae: 12737.4639\n",
      "Epoch 3644/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 180602896.0000 - mae: 9273.2793 - val_loss: 476462336.0000 - val_mae: 12870.6152\n",
      "Epoch 3645/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 181294688.0000 - mae: 9314.5762 - val_loss: 475192000.0000 - val_mae: 12794.1162\n",
      "Epoch 3646/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 180994544.0000 - mae: 9279.8662 - val_loss: 474497248.0000 - val_mae: 12775.1016\n",
      "Epoch 3647/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 180460144.0000 - mae: 9276.6270 - val_loss: 474288320.0000 - val_mae: 12764.5615\n",
      "Epoch 3648/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 181037216.0000 - mae: 9299.5039 - val_loss: 474481024.0000 - val_mae: 12757.4902\n",
      "Epoch 3649/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 181367184.0000 - mae: 9303.0625 - val_loss: 476580448.0000 - val_mae: 12886.1602\n",
      "Epoch 3650/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 180926432.0000 - mae: 9300.6748 - val_loss: 475352128.0000 - val_mae: 12817.7559\n",
      "Epoch 3651/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 181127376.0000 - mae: 9275.0176 - val_loss: 478963040.0000 - val_mae: 12967.9688\n",
      "Epoch 3652/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 181810240.0000 - mae: 9375.8350 - val_loss: 474108768.0000 - val_mae: 12752.0098\n",
      "Epoch 3653/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 180976336.0000 - mae: 9291.7461 - val_loss: 474400192.0000 - val_mae: 12743.4785\n",
      "Epoch 3654/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 180322704.0000 - mae: 9279.2676 - val_loss: 474698752.0000 - val_mae: 12780.5215\n",
      "Epoch 3655/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 180077648.0000 - mae: 9260.9385 - val_loss: 475485632.0000 - val_mae: 12823.3115\n",
      "Epoch 3656/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 180096704.0000 - mae: 9268.4990 - val_loss: 474789984.0000 - val_mae: 12773.1182\n",
      "Epoch 3657/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 180279424.0000 - mae: 9282.8984 - val_loss: 474816640.0000 - val_mae: 12778.1182\n",
      "Epoch 3658/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 180135040.0000 - mae: 9257.6621 - val_loss: 475264768.0000 - val_mae: 12812.3496\n",
      "Epoch 3659/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 180056016.0000 - mae: 9269.1963 - val_loss: 474721472.0000 - val_mae: 12766.0049\n",
      "Epoch 3660/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 179959440.0000 - mae: 9271.9990 - val_loss: 474568128.0000 - val_mae: 12783.1055\n",
      "Epoch 3661/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 179946320.0000 - mae: 9262.9453 - val_loss: 476331968.0000 - val_mae: 12861.6982\n",
      "Epoch 3662/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 180150928.0000 - mae: 9274.9180 - val_loss: 474510304.0000 - val_mae: 12771.4033\n",
      "Epoch 3663/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 179715776.0000 - mae: 9259.2783 - val_loss: 475342528.0000 - val_mae: 12818.3643\n",
      "Epoch 3664/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 179788080.0000 - mae: 9268.7471 - val_loss: 474731712.0000 - val_mae: 12759.4043\n",
      "Epoch 3665/6000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 180020272.0000 - mae: 9293.4053 - val_loss: 474842752.0000 - val_mae: 12761.6875\n",
      "Epoch 3666/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 180142544.0000 - mae: 9281.1104 - val_loss: 475702848.0000 - val_mae: 12838.2119\n",
      "Epoch 3667/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 179864464.0000 - mae: 9269.8115 - val_loss: 475408128.0000 - val_mae: 12832.6660\n",
      "Epoch 3668/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 180035552.0000 - mae: 9277.5879 - val_loss: 475372832.0000 - val_mae: 12828.6660\n",
      "Epoch 3669/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 180112768.0000 - mae: 9261.8984 - val_loss: 474108416.0000 - val_mae: 12780.8232\n",
      "Epoch 3670/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 180075040.0000 - mae: 9297.9688 - val_loss: 475380064.0000 - val_mae: 12812.5107\n",
      "Epoch 3671/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 179382928.0000 - mae: 9249.0381 - val_loss: 475288864.0000 - val_mae: 12833.1123\n",
      "Epoch 3672/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 179333792.0000 - mae: 9277.1133 - val_loss: 474684800.0000 - val_mae: 12751.1318\n",
      "Epoch 3673/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 180052720.0000 - mae: 9281.0068 - val_loss: 475435552.0000 - val_mae: 12836.9883\n",
      "Epoch 3674/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 180365680.0000 - mae: 9298.9805 - val_loss: 476376736.0000 - val_mae: 12872.2109\n",
      "Epoch 3675/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 179509280.0000 - mae: 9266.3643 - val_loss: 475132128.0000 - val_mae: 12815.6816\n",
      "Epoch 3676/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 179178592.0000 - mae: 9260.1113 - val_loss: 474598848.0000 - val_mae: 12784.6455\n",
      "Epoch 3677/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 179611760.0000 - mae: 9268.2793 - val_loss: 474848000.0000 - val_mae: 12779.7178\n",
      "Epoch 3678/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 179393184.0000 - mae: 9263.6328 - val_loss: 479411552.0000 - val_mae: 12997.9551\n",
      "Epoch 3679/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 180147280.0000 - mae: 9317.2559 - val_loss: 474379200.0000 - val_mae: 12760.4541\n",
      "Epoch 3680/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 179500816.0000 - mae: 9281.3770 - val_loss: 474830208.0000 - val_mae: 12788.6787\n",
      "Epoch 3681/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 179070656.0000 - mae: 9266.8564 - val_loss: 474713888.0000 - val_mae: 12753.0947\n",
      "Epoch 3682/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 179566064.0000 - mae: 9260.9277 - val_loss: 474597344.0000 - val_mae: 12788.5879\n",
      "Epoch 3683/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 179624592.0000 - mae: 9244.1035 - val_loss: 475657152.0000 - val_mae: 12859.4600\n",
      "Epoch 3684/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 179241936.0000 - mae: 9260.9150 - val_loss: 475991552.0000 - val_mae: 12855.6377\n",
      "Epoch 3685/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 179144576.0000 - mae: 9257.0508 - val_loss: 475270176.0000 - val_mae: 12821.8027\n",
      "Epoch 3686/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 179231872.0000 - mae: 9241.4707 - val_loss: 475204896.0000 - val_mae: 12839.4053\n",
      "Epoch 3687/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 179140944.0000 - mae: 9304.4727 - val_loss: 474834016.0000 - val_mae: 12759.4199\n",
      "Epoch 3688/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 179522416.0000 - mae: 9259.0527 - val_loss: 474370048.0000 - val_mae: 12758.3584\n",
      "Epoch 3689/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 178853024.0000 - mae: 9235.0195 - val_loss: 475179584.0000 - val_mae: 12813.1074\n",
      "Epoch 3690/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 178555616.0000 - mae: 9238.9092 - val_loss: 474975744.0000 - val_mae: 12803.9258\n",
      "Epoch 3691/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 179845264.0000 - mae: 9279.0625 - val_loss: 474845696.0000 - val_mae: 12809.0859\n",
      "Epoch 3692/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 178629472.0000 - mae: 9259.2666 - val_loss: 474508928.0000 - val_mae: 12781.7217\n",
      "Epoch 3693/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 179058944.0000 - mae: 9260.4053 - val_loss: 475011520.0000 - val_mae: 12761.5439\n",
      "Epoch 3694/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 179500640.0000 - mae: 9256.7324 - val_loss: 474355808.0000 - val_mae: 12777.0449\n",
      "Epoch 3695/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 178513312.0000 - mae: 9230.4756 - val_loss: 475026752.0000 - val_mae: 12818.9453\n",
      "Epoch 3696/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 178421152.0000 - mae: 9249.3877 - val_loss: 474693120.0000 - val_mae: 12792.4932\n",
      "Epoch 3697/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 178397360.0000 - mae: 9230.8613 - val_loss: 475304192.0000 - val_mae: 12818.8936\n",
      "Epoch 3698/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 178164896.0000 - mae: 9240.3174 - val_loss: 474714752.0000 - val_mae: 12769.3281\n",
      "Epoch 3699/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 178711888.0000 - mae: 9258.8516 - val_loss: 474782048.0000 - val_mae: 12770.0615\n",
      "Epoch 3700/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 178759952.0000 - mae: 9242.6826 - val_loss: 474685376.0000 - val_mae: 12785.6924\n",
      "Epoch 3701/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 178300448.0000 - mae: 9221.5938 - val_loss: 476138880.0000 - val_mae: 12862.8633\n",
      "Epoch 3702/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 178859792.0000 - mae: 9272.9658 - val_loss: 475169824.0000 - val_mae: 12795.2275\n",
      "Epoch 3703/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 179016064.0000 - mae: 9290.0137 - val_loss: 475011168.0000 - val_mae: 12766.0039\n",
      "Epoch 3704/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 178772192.0000 - mae: 9260.9443 - val_loss: 474646080.0000 - val_mae: 12773.0010\n",
      "Epoch 3705/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 178965888.0000 - mae: 9233.6748 - val_loss: 475162592.0000 - val_mae: 12812.2881\n",
      "Epoch 3706/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 178456208.0000 - mae: 9230.8193 - val_loss: 474325760.0000 - val_mae: 12765.8789\n",
      "Epoch 3707/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 178084000.0000 - mae: 9244.2773 - val_loss: 476427232.0000 - val_mae: 12887.9355\n",
      "Epoch 3708/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 178094304.0000 - mae: 9253.0771 - val_loss: 475302528.0000 - val_mae: 12753.1299\n",
      "Epoch 3709/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 177470272.0000 - mae: 9231.3271 - val_loss: 478957472.0000 - val_mae: 12982.0537\n",
      "Epoch 3710/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 178623024.0000 - mae: 9312.5215 - val_loss: 474779008.0000 - val_mae: 12777.1455\n",
      "Epoch 3711/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 178142768.0000 - mae: 9236.9990 - val_loss: 475983872.0000 - val_mae: 12859.5244\n",
      "Epoch 3712/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 177716752.0000 - mae: 9231.7393 - val_loss: 475204000.0000 - val_mae: 12799.7539\n",
      "Epoch 3713/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 177878000.0000 - mae: 9239.9131 - val_loss: 474760480.0000 - val_mae: 12786.2334\n",
      "Epoch 3714/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 178925744.0000 - mae: 9277.8496 - val_loss: 477869504.0000 - val_mae: 12932.6094\n",
      "Epoch 3715/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 177612416.0000 - mae: 9224.1094 - val_loss: 475263872.0000 - val_mae: 12808.2129\n",
      "Epoch 3716/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 177658816.0000 - mae: 9239.1064 - val_loss: 475532384.0000 - val_mae: 12800.7529\n",
      "Epoch 3717/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 177602480.0000 - mae: 9214.8965 - val_loss: 475418016.0000 - val_mae: 12811.1318\n",
      "Epoch 3718/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 177537008.0000 - mae: 9212.1299 - val_loss: 476007488.0000 - val_mae: 12852.4902\n",
      "Epoch 3719/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 177217568.0000 - mae: 9239.5869 - val_loss: 475544288.0000 - val_mae: 12773.8301\n",
      "Epoch 3720/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 179281072.0000 - mae: 9271.9521 - val_loss: 479316672.0000 - val_mae: 12995.8682\n",
      "Epoch 3721/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 178086880.0000 - mae: 9237.5293 - val_loss: 475360384.0000 - val_mae: 12809.0664\n",
      "Epoch 3722/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 177282640.0000 - mae: 9218.4385 - val_loss: 475679456.0000 - val_mae: 12825.0312\n",
      "Epoch 3723/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 177156944.0000 - mae: 9235.2256 - val_loss: 475076128.0000 - val_mae: 12792.8691\n",
      "Epoch 3724/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 177772752.0000 - mae: 9222.2578 - val_loss: 475498752.0000 - val_mae: 12786.1816\n",
      "Epoch 3725/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 177242784.0000 - mae: 9230.9434 - val_loss: 475578432.0000 - val_mae: 12788.2969\n",
      "Epoch 3726/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 177258736.0000 - mae: 9232.3838 - val_loss: 476044384.0000 - val_mae: 12842.9336\n",
      "Epoch 3727/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 177062544.0000 - mae: 9216.6807 - val_loss: 475134848.0000 - val_mae: 12790.5820\n",
      "Epoch 3728/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 177585840.0000 - mae: 9261.3115 - val_loss: 475817216.0000 - val_mae: 12779.6533\n",
      "Epoch 3729/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 178950432.0000 - mae: 9261.1787 - val_loss: 475547392.0000 - val_mae: 12816.3496\n",
      "Epoch 3730/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 177660544.0000 - mae: 9247.0576 - val_loss: 477693568.0000 - val_mae: 12909.8984\n",
      "Epoch 3731/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 177330160.0000 - mae: 9207.9092 - val_loss: 476059744.0000 - val_mae: 12860.3799\n",
      "Epoch 3732/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 177077088.0000 - mae: 9226.6875 - val_loss: 475819168.0000 - val_mae: 12772.8047\n",
      "Epoch 3733/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 177585024.0000 - mae: 9231.2178 - val_loss: 475453760.0000 - val_mae: 12780.3633\n",
      "Epoch 3734/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 177847248.0000 - mae: 9262.8340 - val_loss: 475216736.0000 - val_mae: 12784.1816\n",
      "Epoch 3735/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 177404368.0000 - mae: 9220.5439 - val_loss: 476039488.0000 - val_mae: 12846.7422\n",
      "Epoch 3736/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 176969904.0000 - mae: 9220.5439 - val_loss: 476460640.0000 - val_mae: 12861.1074\n",
      "Epoch 3737/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 177040352.0000 - mae: 9217.1680 - val_loss: 475738368.0000 - val_mae: 12826.9609\n",
      "Epoch 3738/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 176669264.0000 - mae: 9218.3223 - val_loss: 476294432.0000 - val_mae: 12828.8691\n",
      "Epoch 3739/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 176725328.0000 - mae: 9206.5586 - val_loss: 475732768.0000 - val_mae: 12819.8379\n",
      "Epoch 3740/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 176606448.0000 - mae: 9227.0996 - val_loss: 475729664.0000 - val_mae: 12802.2441\n",
      "Epoch 3741/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 177025408.0000 - mae: 9226.7725 - val_loss: 476225568.0000 - val_mae: 12857.1504\n",
      "Epoch 3742/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 176867344.0000 - mae: 9217.8936 - val_loss: 477466112.0000 - val_mae: 12913.9541\n",
      "Epoch 3743/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 177345376.0000 - mae: 9228.4102 - val_loss: 475202048.0000 - val_mae: 12801.3398\n",
      "Epoch 3744/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 176454000.0000 - mae: 9204.8799 - val_loss: 475205632.0000 - val_mae: 12791.9258\n",
      "Epoch 3745/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 176975280.0000 - mae: 9210.4893 - val_loss: 475496576.0000 - val_mae: 12796.1621\n",
      "Epoch 3746/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 176493600.0000 - mae: 9192.0820 - val_loss: 478218176.0000 - val_mae: 12958.5312\n",
      "Epoch 3747/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 176531456.0000 - mae: 9227.5410 - val_loss: 475743904.0000 - val_mae: 12822.7510\n",
      "Epoch 3748/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 176431424.0000 - mae: 9190.4375 - val_loss: 475976672.0000 - val_mae: 12836.2744\n",
      "Epoch 3749/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 176296032.0000 - mae: 9214.3350 - val_loss: 475697056.0000 - val_mae: 12826.1230\n",
      "Epoch 3750/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 176269664.0000 - mae: 9192.9336 - val_loss: 476065440.0000 - val_mae: 12848.5234\n",
      "Epoch 3751/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 176287728.0000 - mae: 9203.7637 - val_loss: 476138432.0000 - val_mae: 12824.3896\n",
      "Epoch 3752/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 176164304.0000 - mae: 9191.8857 - val_loss: 475399776.0000 - val_mae: 12798.5088\n",
      "Epoch 3753/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 176353920.0000 - mae: 9218.0518 - val_loss: 475871264.0000 - val_mae: 12796.1836\n",
      "Epoch 3754/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 176207440.0000 - mae: 9207.0234 - val_loss: 477101440.0000 - val_mae: 12892.7734\n",
      "Epoch 3755/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 176124224.0000 - mae: 9195.8643 - val_loss: 475705664.0000 - val_mae: 12821.0254\n",
      "Epoch 3756/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 175970528.0000 - mae: 9206.6006 - val_loss: 475613504.0000 - val_mae: 12838.0186\n",
      "Epoch 3757/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 177076208.0000 - mae: 9230.9404 - val_loss: 477874592.0000 - val_mae: 12931.0850\n",
      "Epoch 3758/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 176318160.0000 - mae: 9204.3428 - val_loss: 476472256.0000 - val_mae: 12866.2910\n",
      "Epoch 3759/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 175734512.0000 - mae: 9205.2266 - val_loss: 476247008.0000 - val_mae: 12810.1357\n",
      "Epoch 3760/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 176521712.0000 - mae: 9218.2031 - val_loss: 478532768.0000 - val_mae: 12947.7646\n",
      "Epoch 3761/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 175520912.0000 - mae: 9179.3857 - val_loss: 475927872.0000 - val_mae: 12824.5508\n",
      "Epoch 3762/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 175970096.0000 - mae: 9205.7734 - val_loss: 475802816.0000 - val_mae: 12806.5557\n",
      "Epoch 3763/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 176763936.0000 - mae: 9230.6201 - val_loss: 476960608.0000 - val_mae: 12896.8076\n",
      "Epoch 3764/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 176107200.0000 - mae: 9199.9180 - val_loss: 475684576.0000 - val_mae: 12832.4053\n",
      "Epoch 3765/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 175462720.0000 - mae: 9189.7393 - val_loss: 476731008.0000 - val_mae: 12867.2949\n",
      "Epoch 3766/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 175734176.0000 - mae: 9191.7607 - val_loss: 475786272.0000 - val_mae: 12810.3896\n",
      "Epoch 3767/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 175719296.0000 - mae: 9187.5146 - val_loss: 475784416.0000 - val_mae: 12788.5342\n",
      "Epoch 3768/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 175041760.0000 - mae: 9177.9990 - val_loss: 477906944.0000 - val_mae: 12925.8535\n",
      "Epoch 3769/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 176335760.0000 - mae: 9219.7344 - val_loss: 475344224.0000 - val_mae: 12810.5488\n",
      "Epoch 3770/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 175480176.0000 - mae: 9209.0537 - val_loss: 475471296.0000 - val_mae: 12796.9814\n",
      "Epoch 3771/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 175594592.0000 - mae: 9182.2510 - val_loss: 474862592.0000 - val_mae: 12806.6143\n",
      "Epoch 3772/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 175355136.0000 - mae: 9161.8525 - val_loss: 476532224.0000 - val_mae: 12872.5674\n",
      "Epoch 3773/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 175580896.0000 - mae: 9199.1445 - val_loss: 475494784.0000 - val_mae: 12826.7939\n",
      "Epoch 3774/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 175688464.0000 - mae: 9191.5488 - val_loss: 475230880.0000 - val_mae: 12815.4463\n",
      "Epoch 3775/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 175414736.0000 - mae: 9185.6748 - val_loss: 475886368.0000 - val_mae: 12850.3574\n",
      "Epoch 3776/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 175668816.0000 - mae: 9176.5000 - val_loss: 475851776.0000 - val_mae: 12854.3691\n",
      "Epoch 3777/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 174990880.0000 - mae: 9186.2461 - val_loss: 475549056.0000 - val_mae: 12799.8896\n",
      "Epoch 3778/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 176766128.0000 - mae: 9231.4883 - val_loss: 475198560.0000 - val_mae: 12800.0850\n",
      "Epoch 3779/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 175004608.0000 - mae: 9192.7900 - val_loss: 475998112.0000 - val_mae: 12848.8428\n",
      "Epoch 3780/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 174869184.0000 - mae: 9176.4258 - val_loss: 475734624.0000 - val_mae: 12836.0254\n",
      "Epoch 3781/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 175062032.0000 - mae: 9168.6318 - val_loss: 475908704.0000 - val_mae: 12851.9082\n",
      "Epoch 3782/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 176213568.0000 - mae: 9215.3193 - val_loss: 475588960.0000 - val_mae: 12824.6309\n",
      "Epoch 3783/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 175078672.0000 - mae: 9186.2002 - val_loss: 475984832.0000 - val_mae: 12853.5664\n",
      "Epoch 3784/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 174665696.0000 - mae: 9169.6104 - val_loss: 475280352.0000 - val_mae: 12830.9980\n",
      "Epoch 3785/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 175049872.0000 - mae: 9173.7754 - val_loss: 475663648.0000 - val_mae: 12817.7305\n",
      "Epoch 3786/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 174921808.0000 - mae: 9195.3623 - val_loss: 475563840.0000 - val_mae: 12831.9463\n",
      "Epoch 3787/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 174830288.0000 - mae: 9166.6475 - val_loss: 475952896.0000 - val_mae: 12862.0303\n",
      "Epoch 3788/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 174464544.0000 - mae: 9170.7891 - val_loss: 475941184.0000 - val_mae: 12830.5488\n",
      "Epoch 3789/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 174442432.0000 - mae: 9154.9502 - val_loss: 476750880.0000 - val_mae: 12893.1719\n",
      "Epoch 3790/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 174494368.0000 - mae: 9167.6445 - val_loss: 475671200.0000 - val_mae: 12814.5342\n",
      "Epoch 3791/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 175251696.0000 - mae: 9176.0674 - val_loss: 475146112.0000 - val_mae: 12826.3271\n",
      "Epoch 3792/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 174935616.0000 - mae: 9179.5527 - val_loss: 475783296.0000 - val_mae: 12832.6377\n",
      "Epoch 3793/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 174513280.0000 - mae: 9170.3623 - val_loss: 476112960.0000 - val_mae: 12860.6182\n",
      "Epoch 3794/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 174072816.0000 - mae: 9210.3896 - val_loss: 477454912.0000 - val_mae: 12802.1328\n",
      "Epoch 3795/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 176283584.0000 - mae: 9248.3867 - val_loss: 475715616.0000 - val_mae: 12852.2734\n",
      "Epoch 3796/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 173918320.0000 - mae: 9140.9121 - val_loss: 476521920.0000 - val_mae: 12865.3857\n",
      "Epoch 3797/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 173916224.0000 - mae: 9156.6660 - val_loss: 475584352.0000 - val_mae: 12826.0518\n",
      "Epoch 3798/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 174091760.0000 - mae: 9153.0742 - val_loss: 476238336.0000 - val_mae: 12862.4795\n",
      "Epoch 3799/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 174111264.0000 - mae: 9155.6631 - val_loss: 477046976.0000 - val_mae: 12898.3223\n",
      "Epoch 3800/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 174214112.0000 - mae: 9162.4717 - val_loss: 475822496.0000 - val_mae: 12847.3682\n",
      "Epoch 3801/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 174235296.0000 - mae: 9148.2480 - val_loss: 475447840.0000 - val_mae: 12830.1748\n",
      "Epoch 3802/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 173873872.0000 - mae: 9160.8750 - val_loss: 475683968.0000 - val_mae: 12852.8887\n",
      "Epoch 3803/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 174193728.0000 - mae: 9155.8457 - val_loss: 477956480.0000 - val_mae: 12933.6914\n",
      "Epoch 3804/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 174332576.0000 - mae: 9182.3828 - val_loss: 475215328.0000 - val_mae: 12807.4736\n",
      "Epoch 3805/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 174435744.0000 - mae: 9202.1875 - val_loss: 477272704.0000 - val_mae: 12914.9844\n",
      "Epoch 3806/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 174370144.0000 - mae: 9148.1807 - val_loss: 477838400.0000 - val_mae: 12945.3438\n",
      "Epoch 3807/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 173849104.0000 - mae: 9153.3271 - val_loss: 475972736.0000 - val_mae: 12824.7998\n",
      "Epoch 3808/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 173788512.0000 - mae: 9153.4043 - val_loss: 475763616.0000 - val_mae: 12823.4512\n",
      "Epoch 3809/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 173554032.0000 - mae: 9142.9102 - val_loss: 476237536.0000 - val_mae: 12855.3320\n",
      "Epoch 3810/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 173283872.0000 - mae: 9143.7959 - val_loss: 475717280.0000 - val_mae: 12827.7891\n",
      "Epoch 3811/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 173999408.0000 - mae: 9164.9541 - val_loss: 476254912.0000 - val_mae: 12855.8691\n",
      "Epoch 3812/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 173729888.0000 - mae: 9159.0518 - val_loss: 477625152.0000 - val_mae: 12926.9082\n",
      "Epoch 3813/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 173816192.0000 - mae: 9153.7568 - val_loss: 475764544.0000 - val_mae: 12810.1621\n",
      "Epoch 3814/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 173964336.0000 - mae: 9187.5068 - val_loss: 475851968.0000 - val_mae: 12803.4414\n",
      "Epoch 3815/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 173503264.0000 - mae: 9144.2500 - val_loss: 477832128.0000 - val_mae: 12942.3945\n",
      "Epoch 3816/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 173269488.0000 - mae: 9140.0068 - val_loss: 475566016.0000 - val_mae: 12805.0811\n",
      "Epoch 3817/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 173531984.0000 - mae: 9163.3203 - val_loss: 476530304.0000 - val_mae: 12811.1064\n",
      "Epoch 3818/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 173744928.0000 - mae: 9187.0615 - val_loss: 478779552.0000 - val_mae: 12976.0586\n",
      "Epoch 3819/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 173618080.0000 - mae: 9171.7705 - val_loss: 476585024.0000 - val_mae: 12877.8848\n",
      "Epoch 3820/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 173168752.0000 - mae: 9144.3145 - val_loss: 476257280.0000 - val_mae: 12848.2812\n",
      "Epoch 3821/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 173170096.0000 - mae: 9144.4062 - val_loss: 476808672.0000 - val_mae: 12876.5234\n",
      "Epoch 3822/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 173303424.0000 - mae: 9151.1504 - val_loss: 475754400.0000 - val_mae: 12803.8643\n",
      "Epoch 3823/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 173290400.0000 - mae: 9146.0518 - val_loss: 476343136.0000 - val_mae: 12842.3828\n",
      "Epoch 3824/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 173645232.0000 - mae: 9153.0479 - val_loss: 477465856.0000 - val_mae: 12915.8350\n",
      "Epoch 3825/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 173074176.0000 - mae: 9142.6572 - val_loss: 476309056.0000 - val_mae: 12872.6318\n",
      "Epoch 3826/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 173621760.0000 - mae: 9160.2656 - val_loss: 476113472.0000 - val_mae: 12850.0234\n",
      "Epoch 3827/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 172719632.0000 - mae: 9151.9375 - val_loss: 476178496.0000 - val_mae: 12799.2559\n",
      "Epoch 3828/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 172882624.0000 - mae: 9152.6670 - val_loss: 478409632.0000 - val_mae: 12961.0205\n",
      "Epoch 3829/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 173416480.0000 - mae: 9152.5723 - val_loss: 476304672.0000 - val_mae: 12871.4590\n",
      "Epoch 3830/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 172531680.0000 - mae: 9129.3047 - val_loss: 476061152.0000 - val_mae: 12847.9150\n",
      "Epoch 3831/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 173424720.0000 - mae: 9158.2344 - val_loss: 476920800.0000 - val_mae: 12894.2314\n",
      "Epoch 3832/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 173490064.0000 - mae: 9143.4824 - val_loss: 477273504.0000 - val_mae: 12908.7002\n",
      "Epoch 3833/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 172945424.0000 - mae: 9145.0498 - val_loss: 476796512.0000 - val_mae: 12893.3340\n",
      "Epoch 3834/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 172782192.0000 - mae: 9157.2158 - val_loss: 476306656.0000 - val_mae: 12806.9248\n",
      "Epoch 3835/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 172617488.0000 - mae: 9140.8926 - val_loss: 476654976.0000 - val_mae: 12872.2393\n",
      "Epoch 3836/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 172979488.0000 - mae: 9138.6484 - val_loss: 477451616.0000 - val_mae: 12929.7275\n",
      "Epoch 3837/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 172465680.0000 - mae: 9134.9512 - val_loss: 476007008.0000 - val_mae: 12858.4795\n",
      "Epoch 3838/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 172840144.0000 - mae: 9128.4131 - val_loss: 476635424.0000 - val_mae: 12876.0566\n",
      "Epoch 3839/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 172471792.0000 - mae: 9126.4863 - val_loss: 475781440.0000 - val_mae: 12854.3594\n",
      "Epoch 3840/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 172494704.0000 - mae: 9144.6709 - val_loss: 476267776.0000 - val_mae: 12842.1406\n",
      "Epoch 3841/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 171895824.0000 - mae: 9108.6523 - val_loss: 478188736.0000 - val_mae: 12947.4023\n",
      "Epoch 3842/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 172734144.0000 - mae: 9137.5928 - val_loss: 476997184.0000 - val_mae: 12884.9414\n",
      "Epoch 3843/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 172015440.0000 - mae: 9125.0068 - val_loss: 476619936.0000 - val_mae: 12858.6602\n",
      "Epoch 3844/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 172371104.0000 - mae: 9119.4414 - val_loss: 476960288.0000 - val_mae: 12889.7188\n",
      "Epoch 3845/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 172418816.0000 - mae: 9136.7217 - val_loss: 476632544.0000 - val_mae: 12859.4980\n",
      "Epoch 3846/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 171920320.0000 - mae: 9101.2500 - val_loss: 476293920.0000 - val_mae: 12853.9346\n",
      "Epoch 3847/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 171994592.0000 - mae: 9111.3975 - val_loss: 476561728.0000 - val_mae: 12884.0156\n",
      "Epoch 3848/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 172761968.0000 - mae: 9144.9590 - val_loss: 478874144.0000 - val_mae: 12980.9355\n",
      "Epoch 3849/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 172350720.0000 - mae: 9122.8477 - val_loss: 477525408.0000 - val_mae: 12904.1729\n",
      "Epoch 3850/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 172306368.0000 - mae: 9121.9717 - val_loss: 476682112.0000 - val_mae: 12841.3320\n",
      "Epoch 3851/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 172139328.0000 - mae: 9124.8369 - val_loss: 477599424.0000 - val_mae: 12922.3135\n",
      "Epoch 3852/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 171686912.0000 - mae: 9117.3750 - val_loss: 476333248.0000 - val_mae: 12834.8857\n",
      "Epoch 3853/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 171869088.0000 - mae: 9119.1885 - val_loss: 476358656.0000 - val_mae: 12851.2490\n",
      "Epoch 3854/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 171603312.0000 - mae: 9110.0010 - val_loss: 477037408.0000 - val_mae: 12880.1367\n",
      "Epoch 3855/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 171662128.0000 - mae: 9115.6035 - val_loss: 477684960.0000 - val_mae: 12898.1211\n",
      "Epoch 3856/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 171778624.0000 - mae: 9128.5000 - val_loss: 477094784.0000 - val_mae: 12876.5586\n",
      "Epoch 3857/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 171739584.0000 - mae: 9111.3682 - val_loss: 478019456.0000 - val_mae: 12928.3730\n",
      "Epoch 3858/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 171789456.0000 - mae: 9129.4580 - val_loss: 477920128.0000 - val_mae: 12932.1953\n",
      "Epoch 3859/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 172309760.0000 - mae: 9179.4336 - val_loss: 477214272.0000 - val_mae: 12822.6270\n",
      "Epoch 3860/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 172543904.0000 - mae: 9158.6396 - val_loss: 476930240.0000 - val_mae: 12815.9072\n",
      "Epoch 3861/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 171801552.0000 - mae: 9139.2236 - val_loss: 477577280.0000 - val_mae: 12903.2637\n",
      "Epoch 3862/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 171736560.0000 - mae: 9104.6562 - val_loss: 477368032.0000 - val_mae: 12880.5625\n",
      "Epoch 3863/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 171331216.0000 - mae: 9115.8057 - val_loss: 479143616.0000 - val_mae: 12972.6855\n",
      "Epoch 3864/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 172104592.0000 - mae: 9138.1660 - val_loss: 477193888.0000 - val_mae: 12886.4551\n",
      "Epoch 3865/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 171003056.0000 - mae: 9091.0879 - val_loss: 476793536.0000 - val_mae: 12862.3682\n",
      "Epoch 3866/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 171314832.0000 - mae: 9111.1455 - val_loss: 477515424.0000 - val_mae: 12878.9004\n",
      "Epoch 3867/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 172337728.0000 - mae: 9141.7822 - val_loss: 476841152.0000 - val_mae: 12846.8848\n",
      "Epoch 3868/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 171159776.0000 - mae: 9102.8955 - val_loss: 479334816.0000 - val_mae: 12975.5439\n",
      "Epoch 3869/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 170840096.0000 - mae: 9111.8926 - val_loss: 476854784.0000 - val_mae: 12850.4893\n",
      "Epoch 3870/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 171232512.0000 - mae: 9097.6523 - val_loss: 476633504.0000 - val_mae: 12859.7988\n",
      "Epoch 3871/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 171000064.0000 - mae: 9103.9648 - val_loss: 477638784.0000 - val_mae: 12903.2207\n",
      "Epoch 3872/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 170663168.0000 - mae: 9098.6592 - val_loss: 477204992.0000 - val_mae: 12861.2480\n",
      "Epoch 3873/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 170834528.0000 - mae: 9084.5557 - val_loss: 477987968.0000 - val_mae: 12914.6396\n",
      "Epoch 3874/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 170887664.0000 - mae: 9094.2637 - val_loss: 477360064.0000 - val_mae: 12868.3740\n",
      "Epoch 3875/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 170812128.0000 - mae: 9091.7988 - val_loss: 477023808.0000 - val_mae: 12864.7979\n",
      "Epoch 3876/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 170796096.0000 - mae: 9092.1123 - val_loss: 477492768.0000 - val_mae: 12864.7080\n",
      "Epoch 3877/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 170595392.0000 - mae: 9093.7998 - val_loss: 480272736.0000 - val_mae: 13031.3164\n",
      "Epoch 3878/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 172192512.0000 - mae: 9121.0664 - val_loss: 478383072.0000 - val_mae: 12933.3398\n",
      "Epoch 3879/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 171147536.0000 - mae: 9108.4014 - val_loss: 477161856.0000 - val_mae: 12860.3242\n",
      "Epoch 3880/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 170240448.0000 - mae: 9076.9004 - val_loss: 477579200.0000 - val_mae: 12882.3574\n",
      "Epoch 3881/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 170607472.0000 - mae: 9105.6016 - val_loss: 477356064.0000 - val_mae: 12832.7334\n",
      "Epoch 3882/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 170552112.0000 - mae: 9085.0693 - val_loss: 479737088.0000 - val_mae: 12996.4941\n",
      "Epoch 3883/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 170953936.0000 - mae: 9121.2490 - val_loss: 477738944.0000 - val_mae: 12902.8242\n",
      "Epoch 3884/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 170241728.0000 - mae: 9102.2783 - val_loss: 477494112.0000 - val_mae: 12864.4150\n",
      "Epoch 3885/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 170356640.0000 - mae: 9091.4131 - val_loss: 478680960.0000 - val_mae: 12928.3164\n",
      "Epoch 3886/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 170135600.0000 - mae: 9075.5469 - val_loss: 477444160.0000 - val_mae: 12872.4600\n",
      "Epoch 3887/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 169923088.0000 - mae: 9068.4746 - val_loss: 477691104.0000 - val_mae: 12883.0420\n",
      "Epoch 3888/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 170840032.0000 - mae: 9122.7480 - val_loss: 478797920.0000 - val_mae: 12832.7930\n",
      "Epoch 3889/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 171130272.0000 - mae: 9123.4375 - val_loss: 476891584.0000 - val_mae: 12839.9854\n",
      "Epoch 3890/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 170348368.0000 - mae: 9091.2363 - val_loss: 477941280.0000 - val_mae: 12878.1768\n",
      "Epoch 3891/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 170119120.0000 - mae: 9072.9688 - val_loss: 477363424.0000 - val_mae: 12862.2783\n",
      "Epoch 3892/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 169734448.0000 - mae: 9080.3516 - val_loss: 477892096.0000 - val_mae: 12868.9697\n",
      "Epoch 3893/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 170108800.0000 - mae: 9091.8164 - val_loss: 478500000.0000 - val_mae: 12847.8438\n",
      "Epoch 3894/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 170589024.0000 - mae: 9099.8525 - val_loss: 478195168.0000 - val_mae: 12896.3906\n",
      "Epoch 3895/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 170129792.0000 - mae: 9093.7061 - val_loss: 478326464.0000 - val_mae: 12906.8330\n",
      "Epoch 3896/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 170102960.0000 - mae: 9095.0928 - val_loss: 478215744.0000 - val_mae: 12837.8682\n",
      "Epoch 3897/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 169935664.0000 - mae: 9084.8496 - val_loss: 478056096.0000 - val_mae: 12859.8223\n",
      "Epoch 3898/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 169649616.0000 - mae: 9086.5645 - val_loss: 478969824.0000 - val_mae: 12940.6172\n",
      "Epoch 3899/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 170235296.0000 - mae: 9091.4795 - val_loss: 478769408.0000 - val_mae: 12829.3594\n",
      "Epoch 3900/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 170885184.0000 - mae: 9102.3223 - val_loss: 477907776.0000 - val_mae: 12843.5156\n",
      "Epoch 3901/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 169848128.0000 - mae: 9088.0918 - val_loss: 478675872.0000 - val_mae: 12905.2764\n",
      "Epoch 3902/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 169637456.0000 - mae: 9081.7061 - val_loss: 478049472.0000 - val_mae: 12843.7383\n",
      "Epoch 3903/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 169581008.0000 - mae: 9085.1582 - val_loss: 479225248.0000 - val_mae: 12929.5234\n",
      "Epoch 3904/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 169552336.0000 - mae: 9065.6982 - val_loss: 479290048.0000 - val_mae: 12934.1514\n",
      "Epoch 3905/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 169635312.0000 - mae: 9091.6504 - val_loss: 478531104.0000 - val_mae: 12843.8828\n",
      "Epoch 3906/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 169839776.0000 - mae: 9088.7568 - val_loss: 478340832.0000 - val_mae: 12880.3623\n",
      "Epoch 3907/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 169439168.0000 - mae: 9061.5215 - val_loss: 479308128.0000 - val_mae: 12931.0801\n",
      "Epoch 3908/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 169525344.0000 - mae: 9088.9561 - val_loss: 478712288.0000 - val_mae: 12881.8320\n",
      "Epoch 3909/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 169591744.0000 - mae: 9072.1816 - val_loss: 479530208.0000 - val_mae: 12946.2119\n",
      "Epoch 3910/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 169450784.0000 - mae: 9065.2539 - val_loss: 479457184.0000 - val_mae: 12943.1914\n",
      "Epoch 3911/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 169201856.0000 - mae: 9073.7559 - val_loss: 478683552.0000 - val_mae: 12863.1357\n",
      "Epoch 3912/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 169271472.0000 - mae: 9068.6680 - val_loss: 478457216.0000 - val_mae: 12873.2539\n",
      "Epoch 3913/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 169070192.0000 - mae: 9063.9883 - val_loss: 479238240.0000 - val_mae: 12909.4912\n",
      "Epoch 3914/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 169199856.0000 - mae: 9061.0752 - val_loss: 479928032.0000 - val_mae: 12956.2773\n",
      "Epoch 3915/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 169128496.0000 - mae: 9060.0195 - val_loss: 478638688.0000 - val_mae: 12896.5039\n",
      "Epoch 3916/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 168789200.0000 - mae: 9075.7734 - val_loss: 479004928.0000 - val_mae: 12848.3955\n",
      "Epoch 3917/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 170162656.0000 - mae: 9105.4834 - val_loss: 478917024.0000 - val_mae: 12852.1572\n",
      "Epoch 3918/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 170424032.0000 - mae: 9081.4043 - val_loss: 478614816.0000 - val_mae: 12862.8271\n",
      "Epoch 3919/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 168890048.0000 - mae: 9058.8896 - val_loss: 479162272.0000 - val_mae: 12911.7510\n",
      "Epoch 3920/6000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 169023552.0000 - mae: 9069.0684 - val_loss: 479996640.0000 - val_mae: 12939.3545\n",
      "Epoch 3921/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 168929712.0000 - mae: 9057.4189 - val_loss: 478740960.0000 - val_mae: 12868.5312\n",
      "Epoch 3922/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 168769376.0000 - mae: 9071.9736 - val_loss: 479024032.0000 - val_mae: 12885.9004\n",
      "Epoch 3923/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 168820752.0000 - mae: 9056.7285 - val_loss: 479244128.0000 - val_mae: 12915.2891\n",
      "Epoch 3924/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 168928528.0000 - mae: 9070.0791 - val_loss: 480075712.0000 - val_mae: 12957.2588\n",
      "Epoch 3925/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 168620256.0000 - mae: 9067.9023 - val_loss: 479508672.0000 - val_mae: 12912.9541\n",
      "Epoch 3926/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 168650992.0000 - mae: 9071.4736 - val_loss: 479342560.0000 - val_mae: 12881.3926\n",
      "Epoch 3927/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 168620352.0000 - mae: 9048.4639 - val_loss: 480217376.0000 - val_mae: 12950.5547\n",
      "Epoch 3928/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 168870912.0000 - mae: 9070.0674 - val_loss: 481541088.0000 - val_mae: 13003.2520\n",
      "Epoch 3929/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 168719920.0000 - mae: 9112.2461 - val_loss: 479656288.0000 - val_mae: 12868.0869\n",
      "Epoch 3930/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 168866400.0000 - mae: 9069.7676 - val_loss: 479524480.0000 - val_mae: 12912.0947\n",
      "Epoch 3931/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 168410304.0000 - mae: 9039.7070 - val_loss: 480173376.0000 - val_mae: 12943.9414\n",
      "Epoch 3932/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 168082560.0000 - mae: 9046.0654 - val_loss: 479445344.0000 - val_mae: 12871.5244\n",
      "Epoch 3933/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 169204160.0000 - mae: 9074.0879 - val_loss: 480546080.0000 - val_mae: 12883.2773\n",
      "Epoch 3934/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 169196896.0000 - mae: 9074.7646 - val_loss: 480544704.0000 - val_mae: 12933.7764\n",
      "Epoch 3935/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 167963968.0000 - mae: 9051.6719 - val_loss: 479591808.0000 - val_mae: 12869.3184\n",
      "Epoch 3936/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 168296336.0000 - mae: 9043.2471 - val_loss: 482221216.0000 - val_mae: 13010.3164\n",
      "Epoch 3937/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 168080160.0000 - mae: 9068.7910 - val_loss: 480314016.0000 - val_mae: 12871.1143\n",
      "Epoch 3938/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 168349072.0000 - mae: 9072.8721 - val_loss: 480101984.0000 - val_mae: 12913.6826\n",
      "Epoch 3939/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 168641600.0000 - mae: 9112.5840 - val_loss: 481840256.0000 - val_mae: 12881.0059\n",
      "Epoch 3940/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 169125408.0000 - mae: 9081.8975 - val_loss: 479981504.0000 - val_mae: 12914.6514\n",
      "Epoch 3941/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 168263792.0000 - mae: 9070.3145 - val_loss: 480333216.0000 - val_mae: 12894.0615\n",
      "Epoch 3942/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 168475792.0000 - mae: 9057.6367 - val_loss: 481098464.0000 - val_mae: 12873.9658\n",
      "Epoch 3943/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 168349376.0000 - mae: 9056.1299 - val_loss: 480529184.0000 - val_mae: 12920.8145\n",
      "Epoch 3944/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 167956352.0000 - mae: 9034.5947 - val_loss: 480193312.0000 - val_mae: 12904.1064\n",
      "Epoch 3945/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 167626416.0000 - mae: 9032.4453 - val_loss: 481021152.0000 - val_mae: 12943.2061\n",
      "Epoch 3946/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 168822640.0000 - mae: 9081.5488 - val_loss: 480867776.0000 - val_mae: 12930.6855\n",
      "Epoch 3947/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 167855824.0000 - mae: 9038.0059 - val_loss: 480796448.0000 - val_mae: 12923.7031\n",
      "Epoch 3948/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 167901600.0000 - mae: 9048.4678 - val_loss: 480266528.0000 - val_mae: 12910.0039\n",
      "Epoch 3949/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 167947104.0000 - mae: 9061.6650 - val_loss: 480799360.0000 - val_mae: 12936.8926\n",
      "Epoch 3950/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 167817392.0000 - mae: 9065.6172 - val_loss: 480516128.0000 - val_mae: 12883.4658\n",
      "Epoch 3951/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 169632704.0000 - mae: 9095.8613 - val_loss: 482109024.0000 - val_mae: 12987.4180\n",
      "Epoch 3952/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 168439296.0000 - mae: 9067.6787 - val_loss: 482753792.0000 - val_mae: 13017.6406\n",
      "Epoch 3953/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 167983280.0000 - mae: 9050.3574 - val_loss: 480514112.0000 - val_mae: 12883.4229\n",
      "Epoch 3954/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 168072800.0000 - mae: 9074.8271 - val_loss: 481365056.0000 - val_mae: 12924.9404\n",
      "Epoch 3955/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 168457456.0000 - mae: 9067.0674 - val_loss: 481247168.0000 - val_mae: 12937.0947\n",
      "Epoch 3956/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 167531040.0000 - mae: 9051.0234 - val_loss: 481774528.0000 - val_mae: 12958.3252\n",
      "Epoch 3957/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 167065568.0000 - mae: 9040.3223 - val_loss: 480867296.0000 - val_mae: 12896.8184\n",
      "Epoch 3958/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 167183776.0000 - mae: 9021.9482 - val_loss: 481067360.0000 - val_mae: 12943.4492\n",
      "Epoch 3959/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 167777232.0000 - mae: 9049.1729 - val_loss: 481332096.0000 - val_mae: 12923.6152\n",
      "Epoch 3960/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 167736352.0000 - mae: 9039.8516 - val_loss: 481833856.0000 - val_mae: 12924.5586\n",
      "Epoch 3961/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 167111856.0000 - mae: 9030.2129 - val_loss: 481456288.0000 - val_mae: 12940.9639\n",
      "Epoch 3962/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 167244144.0000 - mae: 9034.3828 - val_loss: 481625856.0000 - val_mae: 12918.4678\n",
      "Epoch 3963/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 167410384.0000 - mae: 9034.8506 - val_loss: 481670624.0000 - val_mae: 12936.3447\n",
      "Epoch 3964/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 167161904.0000 - mae: 9028.0771 - val_loss: 481016352.0000 - val_mae: 12916.5186\n",
      "Epoch 3965/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 167456752.0000 - mae: 9056.5869 - val_loss: 481914400.0000 - val_mae: 12918.3633\n",
      "Epoch 3966/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 167149552.0000 - mae: 9020.7188 - val_loss: 481594304.0000 - val_mae: 12948.6670\n",
      "Epoch 3967/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 166990288.0000 - mae: 9026.0762 - val_loss: 482662272.0000 - val_mae: 12969.4043\n",
      "Epoch 3968/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 167293696.0000 - mae: 9035.5850 - val_loss: 482648512.0000 - val_mae: 12985.5879\n",
      "Epoch 3969/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 166973728.0000 - mae: 9043.6133 - val_loss: 481577696.0000 - val_mae: 12924.1318\n",
      "Epoch 3970/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 166779280.0000 - mae: 9020.0713 - val_loss: 483149120.0000 - val_mae: 13000.5537\n",
      "Epoch 3971/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 166914240.0000 - mae: 9025.7266 - val_loss: 482352864.0000 - val_mae: 12949.5166\n",
      "Epoch 3972/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 166621456.0000 - mae: 9035.6836 - val_loss: 482100192.0000 - val_mae: 12904.5186\n",
      "Epoch 3973/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 168031920.0000 - mae: 9059.0859 - val_loss: 482042944.0000 - val_mae: 12896.0488\n",
      "Epoch 3974/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 166744912.0000 - mae: 9008.1484 - val_loss: 484040352.0000 - val_mae: 13046.6602\n",
      "Epoch 3975/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 167024528.0000 - mae: 9069.0684 - val_loss: 482125184.0000 - val_mae: 12916.0713\n",
      "Epoch 3976/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 166714160.0000 - mae: 9021.0537 - val_loss: 481825248.0000 - val_mae: 12903.3887\n",
      "Epoch 3977/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 166970976.0000 - mae: 9044.6123 - val_loss: 481657312.0000 - val_mae: 12908.2920\n",
      "Epoch 3978/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 167745504.0000 - mae: 9074.3057 - val_loss: 482585728.0000 - val_mae: 12895.5869\n",
      "Epoch 3979/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 166497120.0000 - mae: 9017.8662 - val_loss: 482021152.0000 - val_mae: 12927.8555\n",
      "Epoch 3980/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 166828032.0000 - mae: 9019.8262 - val_loss: 483169888.0000 - val_mae: 12996.0498\n",
      "Epoch 3981/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 166742752.0000 - mae: 9028.2129 - val_loss: 483821312.0000 - val_mae: 13021.9443\n",
      "Epoch 3982/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 166637504.0000 - mae: 9046.9912 - val_loss: 482855232.0000 - val_mae: 12902.2334\n",
      "Epoch 3983/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 166609952.0000 - mae: 9023.6709 - val_loss: 482232640.0000 - val_mae: 12937.3652\n",
      "Epoch 3984/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 166190704.0000 - mae: 9014.4756 - val_loss: 482336032.0000 - val_mae: 12906.9404\n",
      "Epoch 3985/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 166830816.0000 - mae: 9021.7656 - val_loss: 482495616.0000 - val_mae: 12953.1250\n",
      "Epoch 3986/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 166008464.0000 - mae: 9009.7949 - val_loss: 482041952.0000 - val_mae: 12922.1162\n",
      "Epoch 3987/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 166598304.0000 - mae: 9035.6729 - val_loss: 483027648.0000 - val_mae: 12953.4072\n",
      "Epoch 3988/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 166596480.0000 - mae: 9031.6396 - val_loss: 482328032.0000 - val_mae: 12911.0518\n",
      "Epoch 3989/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 166367216.0000 - mae: 9022.9570 - val_loss: 482632224.0000 - val_mae: 12942.9785\n",
      "Epoch 3990/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 166188032.0000 - mae: 9024.4775 - val_loss: 483077504.0000 - val_mae: 12946.6982\n",
      "Epoch 3991/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 165826512.0000 - mae: 9000.2080 - val_loss: 482682208.0000 - val_mae: 12938.5371\n",
      "Epoch 3992/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 166330048.0000 - mae: 9023.8730 - val_loss: 483274432.0000 - val_mae: 12971.6816\n",
      "Epoch 3993/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 166500800.0000 - mae: 9037.5020 - val_loss: 482705856.0000 - val_mae: 12913.7051\n",
      "Epoch 3994/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 166255856.0000 - mae: 9024.4795 - val_loss: 482783744.0000 - val_mae: 12912.0391\n",
      "Epoch 3995/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 167098592.0000 - mae: 9047.4277 - val_loss: 483019072.0000 - val_mae: 12909.3340\n",
      "Epoch 3996/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 166399456.0000 - mae: 9031.7432 - val_loss: 483412576.0000 - val_mae: 12964.8447\n",
      "Epoch 3997/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 166388656.0000 - mae: 9038.7686 - val_loss: 483852800.0000 - val_mae: 12981.5908\n",
      "Epoch 3998/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 166211184.0000 - mae: 9016.5928 - val_loss: 485158880.0000 - val_mae: 13054.2002\n",
      "Epoch 3999/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 165924976.0000 - mae: 9035.3359 - val_loss: 483339200.0000 - val_mae: 12929.3887\n",
      "Epoch 4000/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 166076016.0000 - mae: 9019.5928 - val_loss: 482667072.0000 - val_mae: 12915.1572\n",
      "Epoch 4001/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 165545456.0000 - mae: 8999.8037 - val_loss: 483465824.0000 - val_mae: 12968.7373\n",
      "Epoch 4002/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 165540704.0000 - mae: 9018.1826 - val_loss: 483325568.0000 - val_mae: 12954.0850\n",
      "Epoch 4003/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 165629152.0000 - mae: 9007.0654 - val_loss: 483970976.0000 - val_mae: 12988.5234\n",
      "Epoch 4004/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 165412368.0000 - mae: 9005.2793 - val_loss: 483574944.0000 - val_mae: 12928.7881\n",
      "Epoch 4005/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 165449648.0000 - mae: 8982.6191 - val_loss: 485111904.0000 - val_mae: 13028.6855\n",
      "Epoch 4006/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 165728160.0000 - mae: 9016.5381 - val_loss: 483643712.0000 - val_mae: 12952.5049\n",
      "Epoch 4007/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 165651824.0000 - mae: 9017.8379 - val_loss: 483548416.0000 - val_mae: 12970.2227\n",
      "Epoch 4008/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 165816528.0000 - mae: 9018.2520 - val_loss: 485950784.0000 - val_mae: 13073.4385\n",
      "Epoch 4009/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 165599408.0000 - mae: 9040.9736 - val_loss: 483998752.0000 - val_mae: 12931.9893\n",
      "Epoch 4010/6000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 165659248.0000 - mae: 9005.9688 - val_loss: 483474144.0000 - val_mae: 12933.4482\n",
      "Epoch 4011/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 165330432.0000 - mae: 8993.0938 - val_loss: 484786848.0000 - val_mae: 12996.2646\n",
      "Epoch 4012/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 165312144.0000 - mae: 9014.1572 - val_loss: 483724320.0000 - val_mae: 12943.5615\n",
      "Epoch 4013/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 165094448.0000 - mae: 9004.1250 - val_loss: 485051840.0000 - val_mae: 13022.2373\n",
      "Epoch 4014/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 165697232.0000 - mae: 9008.8184 - val_loss: 484018560.0000 - val_mae: 12965.2861\n",
      "Epoch 4015/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 165907424.0000 - mae: 9024.8828 - val_loss: 483610400.0000 - val_mae: 12928.9307\n",
      "Epoch 4016/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 165149040.0000 - mae: 9002.3174 - val_loss: 483700384.0000 - val_mae: 12923.2588\n",
      "Epoch 4017/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 165069472.0000 - mae: 8995.3037 - val_loss: 483941760.0000 - val_mae: 12940.5254\n",
      "Epoch 4018/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 165284240.0000 - mae: 9008.0498 - val_loss: 484220704.0000 - val_mae: 12944.4375\n",
      "Epoch 4019/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 165046160.0000 - mae: 8999.2461 - val_loss: 483985344.0000 - val_mae: 12945.0361\n",
      "Epoch 4020/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 165149504.0000 - mae: 8995.4131 - val_loss: 483898496.0000 - val_mae: 12946.6113\n",
      "Epoch 4021/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 164784032.0000 - mae: 8999.3301 - val_loss: 485289216.0000 - val_mae: 13011.8115\n",
      "Epoch 4022/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 165292320.0000 - mae: 9018.2314 - val_loss: 485892288.0000 - val_mae: 13051.9258\n",
      "Epoch 4023/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 165229888.0000 - mae: 8999.0117 - val_loss: 484789536.0000 - val_mae: 12991.5518\n",
      "Epoch 4024/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 164681408.0000 - mae: 8992.1025 - val_loss: 484342208.0000 - val_mae: 12954.5869\n",
      "Epoch 4025/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 164729328.0000 - mae: 8988.7422 - val_loss: 484446944.0000 - val_mae: 12953.6143\n",
      "Epoch 4026/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 164560208.0000 - mae: 8992.4990 - val_loss: 484956480.0000 - val_mae: 12938.0869\n",
      "Epoch 4027/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 165081984.0000 - mae: 8994.0586 - val_loss: 487012544.0000 - val_mae: 13082.5977\n",
      "Epoch 4028/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 166291696.0000 - mae: 9041.9922 - val_loss: 486065792.0000 - val_mae: 13028.3320\n",
      "Epoch 4029/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 164729296.0000 - mae: 8982.2178 - val_loss: 484623136.0000 - val_mae: 12941.3643\n",
      "Epoch 4030/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 165022208.0000 - mae: 9004.3086 - val_loss: 484903872.0000 - val_mae: 12952.2139\n",
      "Epoch 4031/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 165009216.0000 - mae: 8992.2793 - val_loss: 486756992.0000 - val_mae: 13054.9385\n",
      "Epoch 4032/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 164239536.0000 - mae: 8979.0566 - val_loss: 484722336.0000 - val_mae: 12947.3135\n",
      "Epoch 4033/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 165117712.0000 - mae: 9000.0713 - val_loss: 485060864.0000 - val_mae: 12977.7529\n",
      "Epoch 4034/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 164423312.0000 - mae: 8990.3604 - val_loss: 484907776.0000 - val_mae: 12967.1807\n",
      "Epoch 4035/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 165144848.0000 - mae: 9017.7158 - val_loss: 484936992.0000 - val_mae: 12973.7373\n",
      "Epoch 4036/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 164780528.0000 - mae: 8987.8770 - val_loss: 485270560.0000 - val_mae: 12983.7871\n",
      "Epoch 4037/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 164412272.0000 - mae: 8986.0508 - val_loss: 485676416.0000 - val_mae: 13000.2539\n",
      "Epoch 4038/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 164038864.0000 - mae: 8983.8848 - val_loss: 485114240.0000 - val_mae: 12961.4414\n",
      "Epoch 4039/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 164133872.0000 - mae: 8981.3037 - val_loss: 485524064.0000 - val_mae: 12975.8740\n",
      "Epoch 4040/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 164142096.0000 - mae: 8971.2393 - val_loss: 485583232.0000 - val_mae: 12973.7314\n",
      "Epoch 4041/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 164114192.0000 - mae: 8980.1445 - val_loss: 485339648.0000 - val_mae: 12980.3193\n",
      "Epoch 4042/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 163994768.0000 - mae: 8984.6377 - val_loss: 485201952.0000 - val_mae: 12956.5449\n",
      "Epoch 4043/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 164357760.0000 - mae: 8986.3887 - val_loss: 485381664.0000 - val_mae: 12935.5371\n",
      "Epoch 4044/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 164110176.0000 - mae: 8993.7031 - val_loss: 487590976.0000 - val_mae: 13075.9854\n",
      "Epoch 4045/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 164194288.0000 - mae: 8991.6445 - val_loss: 485220768.0000 - val_mae: 12969.8418\n",
      "Epoch 4046/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 164021440.0000 - mae: 8991.3271 - val_loss: 485704512.0000 - val_mae: 12966.3076\n",
      "Epoch 4047/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 164525968.0000 - mae: 8980.2539 - val_loss: 485779456.0000 - val_mae: 12937.0254\n",
      "Epoch 4048/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 165328336.0000 - mae: 9009.8291 - val_loss: 485806496.0000 - val_mae: 12935.1182\n",
      "Epoch 4049/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 164249680.0000 - mae: 9004.2988 - val_loss: 485910720.0000 - val_mae: 12947.7490\n",
      "Epoch 4050/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 164350336.0000 - mae: 8987.3340 - val_loss: 485631328.0000 - val_mae: 12972.7529\n",
      "Epoch 4051/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 164308992.0000 - mae: 8983.3477 - val_loss: 485941792.0000 - val_mae: 12986.4512\n",
      "Epoch 4052/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 164244976.0000 - mae: 9008.0537 - val_loss: 485828128.0000 - val_mae: 12956.8467\n",
      "Epoch 4053/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 164376000.0000 - mae: 9003.1758 - val_loss: 485958336.0000 - val_mae: 12930.2334\n",
      "Epoch 4054/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 164029312.0000 - mae: 8975.0928 - val_loss: 485829024.0000 - val_mae: 12978.3525\n",
      "Epoch 4055/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 163453264.0000 - mae: 8970.0400 - val_loss: 486152192.0000 - val_mae: 12959.7266\n",
      "Epoch 4056/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 163509536.0000 - mae: 8968.9160 - val_loss: 486286528.0000 - val_mae: 12987.0156\n",
      "Epoch 4057/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 163489920.0000 - mae: 8971.7354 - val_loss: 486170720.0000 - val_mae: 12981.9004\n",
      "Epoch 4058/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 163769328.0000 - mae: 8999.2910 - val_loss: 486169888.0000 - val_mae: 12978.6562\n",
      "Epoch 4059/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 163577952.0000 - mae: 8973.5400 - val_loss: 490035456.0000 - val_mae: 13163.2559\n",
      "Epoch 4060/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 164564608.0000 - mae: 9000.9541 - val_loss: 486361984.0000 - val_mae: 12985.5400\n",
      "Epoch 4061/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 163169968.0000 - mae: 8957.6699 - val_loss: 487023072.0000 - val_mae: 13018.0156\n",
      "Epoch 4062/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 163271888.0000 - mae: 8974.4180 - val_loss: 486185920.0000 - val_mae: 12973.2910\n",
      "Epoch 4063/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 164747216.0000 - mae: 8982.7188 - val_loss: 486386656.0000 - val_mae: 12977.9551\n",
      "Epoch 4064/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 163744960.0000 - mae: 8979.3652 - val_loss: 486802688.0000 - val_mae: 12991.7334\n",
      "Epoch 4065/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 163534032.0000 - mae: 8998.4883 - val_loss: 486524480.0000 - val_mae: 12962.9609\n",
      "Epoch 4066/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 165181520.0000 - mae: 9059.9062 - val_loss: 491328800.0000 - val_mae: 13193.1816\n",
      "Epoch 4067/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 162834416.0000 - mae: 8959.6064 - val_loss: 486885984.0000 - val_mae: 12955.4893\n",
      "Epoch 4068/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 164988384.0000 - mae: 9055.3770 - val_loss: 494000384.0000 - val_mae: 13304.8223\n",
      "Epoch 4069/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 165199024.0000 - mae: 9009.0215 - val_loss: 487705984.0000 - val_mae: 13049.4482\n",
      "Epoch 4070/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 163439024.0000 - mae: 8996.4062 - val_loss: 487060192.0000 - val_mae: 12963.3721\n",
      "Epoch 4071/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 163048272.0000 - mae: 8957.9512 - val_loss: 487225568.0000 - val_mae: 13008.7480\n",
      "Epoch 4072/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 163132592.0000 - mae: 8966.8379 - val_loss: 487088672.0000 - val_mae: 12966.3271\n",
      "Epoch 4073/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 163399824.0000 - mae: 8978.8174 - val_loss: 487889312.0000 - val_mae: 13038.8174\n",
      "Epoch 4074/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 163239488.0000 - mae: 8964.0977 - val_loss: 487356704.0000 - val_mae: 12946.9414\n",
      "Epoch 4075/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 163159392.0000 - mae: 8976.6201 - val_loss: 488643520.0000 - val_mae: 13063.2871\n",
      "Epoch 4076/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 164553840.0000 - mae: 9031.8359 - val_loss: 491673536.0000 - val_mae: 13193.2461\n",
      "Epoch 4077/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 165037664.0000 - mae: 9054.9229 - val_loss: 487824032.0000 - val_mae: 13012.0967\n",
      "Epoch 4078/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 163303136.0000 - mae: 8999.7812 - val_loss: 489761504.0000 - val_mae: 12981.4072\n",
      "Epoch 4079/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 164129104.0000 - mae: 9008.9336 - val_loss: 487458944.0000 - val_mae: 13016.2676\n",
      "Epoch 4080/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 162892144.0000 - mae: 8952.0664 - val_loss: 487485056.0000 - val_mae: 12994.9707\n",
      "Epoch 4081/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 163154096.0000 - mae: 8993.7969 - val_loss: 487931072.0000 - val_mae: 12983.8477\n",
      "Epoch 4082/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 163482256.0000 - mae: 9013.0010 - val_loss: 496048608.0000 - val_mae: 13394.4258\n",
      "Epoch 4083/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 163899152.0000 - mae: 9061.1123 - val_loss: 487405312.0000 - val_mae: 12975.7646\n",
      "Epoch 4084/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 162384336.0000 - mae: 8951.0449 - val_loss: 487873312.0000 - val_mae: 13032.0615\n",
      "Epoch 4085/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 162699712.0000 - mae: 8946.5039 - val_loss: 487971808.0000 - val_mae: 13013.6270\n",
      "Epoch 4086/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 162652336.0000 - mae: 8950.6123 - val_loss: 487963328.0000 - val_mae: 13014.6748\n",
      "Epoch 4087/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 162436960.0000 - mae: 8948.1855 - val_loss: 487864352.0000 - val_mae: 13008.3896\n",
      "Epoch 4088/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 162216144.0000 - mae: 8942.4854 - val_loss: 487519424.0000 - val_mae: 13004.1504\n",
      "Epoch 4089/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 162620240.0000 - mae: 8967.6729 - val_loss: 489152992.0000 - val_mae: 12986.7002\n",
      "Epoch 4090/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 162872336.0000 - mae: 8974.6602 - val_loss: 488629312.0000 - val_mae: 13044.9463\n",
      "Epoch 4091/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 162366272.0000 - mae: 8933.9844 - val_loss: 489870976.0000 - val_mae: 13106.3086\n",
      "Epoch 4092/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 163189744.0000 - mae: 9002.6758 - val_loss: 488312160.0000 - val_mae: 12982.4453\n",
      "Epoch 4093/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 162249264.0000 - mae: 8949.1582 - val_loss: 488721696.0000 - val_mae: 13052.5439\n",
      "Epoch 4094/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 162419840.0000 - mae: 8951.1074 - val_loss: 488374976.0000 - val_mae: 13022.8594\n",
      "Epoch 4095/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 162443088.0000 - mae: 8949.8711 - val_loss: 488707136.0000 - val_mae: 13030.7207\n",
      "Epoch 4096/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 162473760.0000 - mae: 8972.1270 - val_loss: 488692320.0000 - val_mae: 12990.6318\n",
      "Epoch 4097/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 162843216.0000 - mae: 8985.3701 - val_loss: 489322560.0000 - val_mae: 13073.9639\n",
      "Epoch 4098/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 162582848.0000 - mae: 8960.7129 - val_loss: 488240544.0000 - val_mae: 12997.5098\n",
      "Epoch 4099/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 162262976.0000 - mae: 8973.9219 - val_loss: 488456128.0000 - val_mae: 12976.1064\n",
      "Epoch 4100/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 161811904.0000 - mae: 8946.9160 - val_loss: 490465568.0000 - val_mae: 13115.3896\n",
      "Epoch 4101/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 162580016.0000 - mae: 8961.9434 - val_loss: 490621472.0000 - val_mae: 13112.6855\n",
      "Epoch 4102/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 162919136.0000 - mae: 9023.3477 - val_loss: 488791360.0000 - val_mae: 12988.4082\n",
      "Epoch 4103/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 163494960.0000 - mae: 8992.5615 - val_loss: 488228512.0000 - val_mae: 12985.9756\n",
      "Epoch 4104/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 161595456.0000 - mae: 8945.0967 - val_loss: 489901280.0000 - val_mae: 13088.1514\n",
      "Epoch 4105/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 161762944.0000 - mae: 8958.8496 - val_loss: 488785984.0000 - val_mae: 12995.7861\n",
      "Epoch 4106/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 161984800.0000 - mae: 8956.7207 - val_loss: 488760896.0000 - val_mae: 13003.2490\n",
      "Epoch 4107/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 161971056.0000 - mae: 8946.3047 - val_loss: 489271712.0000 - val_mae: 12989.8730\n",
      "Epoch 4108/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 162228048.0000 - mae: 8927.5840 - val_loss: 488634432.0000 - val_mae: 13007.4961\n",
      "Epoch 4109/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 162388576.0000 - mae: 8975.2441 - val_loss: 489348480.0000 - val_mae: 13006.6348\n",
      "Epoch 4110/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 161691040.0000 - mae: 8955.1016 - val_loss: 489383648.0000 - val_mae: 13010.3750\n",
      "Epoch 4111/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 162556816.0000 - mae: 8977.9648 - val_loss: 489762496.0000 - val_mae: 13063.5850\n",
      "Epoch 4112/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 161811312.0000 - mae: 8940.6670 - val_loss: 489481920.0000 - val_mae: 13054.2627\n",
      "Epoch 4113/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 161555536.0000 - mae: 8943.1396 - val_loss: 489845024.0000 - val_mae: 13040.1602\n",
      "Epoch 4114/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 162377792.0000 - mae: 8952.7578 - val_loss: 492682272.0000 - val_mae: 13185.3340\n",
      "Epoch 4115/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 161979936.0000 - mae: 8960.6104 - val_loss: 489843424.0000 - val_mae: 13051.2695\n",
      "Epoch 4116/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 161391104.0000 - mae: 8929.4385 - val_loss: 489459968.0000 - val_mae: 13009.7393\n",
      "Epoch 4117/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 161349280.0000 - mae: 8929.3184 - val_loss: 489813248.0000 - val_mae: 13049.3125\n",
      "Epoch 4118/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 161632352.0000 - mae: 8951.8398 - val_loss: 489265184.0000 - val_mae: 13006.7070\n",
      "Epoch 4119/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 161489248.0000 - mae: 8937.4814 - val_loss: 489418048.0000 - val_mae: 13033.9863\n",
      "Epoch 4120/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 161438176.0000 - mae: 8946.5361 - val_loss: 489456256.0000 - val_mae: 13021.1162\n",
      "Epoch 4121/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 162076176.0000 - mae: 8928.1416 - val_loss: 492725120.0000 - val_mae: 13177.5244\n",
      "Epoch 4122/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 162017104.0000 - mae: 8952.8828 - val_loss: 489506464.0000 - val_mae: 13025.5098\n",
      "Epoch 4123/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 161068384.0000 - mae: 8927.3613 - val_loss: 490140160.0000 - val_mae: 13044.4160\n",
      "Epoch 4124/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 161178400.0000 - mae: 8925.5479 - val_loss: 489774464.0000 - val_mae: 13031.8018\n",
      "Epoch 4125/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 161199664.0000 - mae: 8930.8223 - val_loss: 490431584.0000 - val_mae: 13057.3896\n",
      "Epoch 4126/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 161486848.0000 - mae: 8952.2139 - val_loss: 489724864.0000 - val_mae: 13017.0625\n",
      "Epoch 4127/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 161491056.0000 - mae: 8941.5918 - val_loss: 489984992.0000 - val_mae: 13011.8955\n",
      "Epoch 4128/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 161187776.0000 - mae: 8936.0391 - val_loss: 490138464.0000 - val_mae: 13005.9492\n",
      "Epoch 4129/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 161336000.0000 - mae: 8928.5850 - val_loss: 490360768.0000 - val_mae: 13045.1748\n",
      "Epoch 4130/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 161051440.0000 - mae: 8931.5674 - val_loss: 489848320.0000 - val_mae: 13020.2695\n",
      "Epoch 4131/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 160740160.0000 - mae: 8920.1025 - val_loss: 491892576.0000 - val_mae: 13112.1924\n",
      "Epoch 4132/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 161567856.0000 - mae: 8941.5664 - val_loss: 490036032.0000 - val_mae: 13033.7139\n",
      "Epoch 4133/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 161360944.0000 - mae: 8960.0752 - val_loss: 490142560.0000 - val_mae: 13039.4248\n",
      "Epoch 4134/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 160816832.0000 - mae: 8931.7676 - val_loss: 490642592.0000 - val_mae: 13040.7334\n",
      "Epoch 4135/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 161035328.0000 - mae: 8935.5742 - val_loss: 494271968.0000 - val_mae: 13222.4795\n",
      "Epoch 4136/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 161691904.0000 - mae: 8984.4082 - val_loss: 490952704.0000 - val_mae: 13051.7510\n",
      "Epoch 4137/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 160816944.0000 - mae: 8926.0771 - val_loss: 490834496.0000 - val_mae: 13029.3730\n",
      "Epoch 4138/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 161492960.0000 - mae: 8954.8555 - val_loss: 491632256.0000 - val_mae: 13020.1709\n",
      "Epoch 4139/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 161977552.0000 - mae: 8947.0811 - val_loss: 490580256.0000 - val_mae: 13035.1016\n",
      "Epoch 4140/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 160324640.0000 - mae: 8901.7207 - val_loss: 491930272.0000 - val_mae: 13110.9023\n",
      "Epoch 4141/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 161591488.0000 - mae: 8950.6953 - val_loss: 491412864.0000 - val_mae: 13072.3770\n",
      "Epoch 4142/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 160466720.0000 - mae: 8925.3066 - val_loss: 491277248.0000 - val_mae: 13026.8438\n",
      "Epoch 4143/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 160621440.0000 - mae: 8921.6660 - val_loss: 491300576.0000 - val_mae: 13068.6299\n",
      "Epoch 4144/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 161001200.0000 - mae: 8934.4355 - val_loss: 491163520.0000 - val_mae: 13059.2842\n",
      "Epoch 4145/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 160621936.0000 - mae: 8953.3848 - val_loss: 491569120.0000 - val_mae: 13026.9707\n",
      "Epoch 4146/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 160600880.0000 - mae: 8922.5664 - val_loss: 491843328.0000 - val_mae: 13101.2441\n",
      "Epoch 4147/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 161005328.0000 - mae: 8927.7422 - val_loss: 491953280.0000 - val_mae: 13100.0283\n",
      "Epoch 4148/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 162679520.0000 - mae: 8996.9189 - val_loss: 492101536.0000 - val_mae: 13107.4209\n",
      "Epoch 4149/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 160742000.0000 - mae: 8935.0469 - val_loss: 494313344.0000 - val_mae: 13208.6973\n",
      "Epoch 4150/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 161473600.0000 - mae: 8982.4854 - val_loss: 491801792.0000 - val_mae: 13057.8877\n",
      "Epoch 4151/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 160193600.0000 - mae: 8911.2383 - val_loss: 491859456.0000 - val_mae: 13072.2637\n",
      "Epoch 4152/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 160264752.0000 - mae: 8925.7939 - val_loss: 491885792.0000 - val_mae: 13038.7734\n",
      "Epoch 4153/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 160476976.0000 - mae: 8919.9580 - val_loss: 492329536.0000 - val_mae: 13104.8691\n",
      "Epoch 4154/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 160265616.0000 - mae: 8928.5176 - val_loss: 492189216.0000 - val_mae: 13030.3984\n",
      "Epoch 4155/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 161554256.0000 - mae: 8977.7949 - val_loss: 491659008.0000 - val_mae: 13052.8174\n",
      "Epoch 4156/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 160457440.0000 - mae: 8909.4404 - val_loss: 492282976.0000 - val_mae: 13063.9385\n",
      "Epoch 4157/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 160154416.0000 - mae: 8911.3467 - val_loss: 492018752.0000 - val_mae: 13043.3477\n",
      "Epoch 4158/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 160415280.0000 - mae: 8928.1953 - val_loss: 491693632.0000 - val_mae: 13047.6094\n",
      "Epoch 4159/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 161181040.0000 - mae: 8974.5273 - val_loss: 495728576.0000 - val_mae: 13248.2588\n",
      "Epoch 4160/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 160755152.0000 - mae: 8929.8975 - val_loss: 492807776.0000 - val_mae: 13086.1074\n",
      "Epoch 4161/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 160175248.0000 - mae: 8918.4180 - val_loss: 492945920.0000 - val_mae: 13110.4131\n",
      "Epoch 4162/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 160332976.0000 - mae: 8932.2842 - val_loss: 491891360.0000 - val_mae: 13043.0713\n",
      "Epoch 4163/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 160108208.0000 - mae: 8926.9189 - val_loss: 492287872.0000 - val_mae: 13052.3438\n",
      "Epoch 4164/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 160030208.0000 - mae: 8947.1299 - val_loss: 494849472.0000 - val_mae: 13192.7686\n",
      "Epoch 4165/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 160022160.0000 - mae: 8915.7676 - val_loss: 492400384.0000 - val_mae: 13075.7773\n",
      "Epoch 4166/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 159628480.0000 - mae: 8904.0195 - val_loss: 492650880.0000 - val_mae: 13081.6143\n",
      "Epoch 4167/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 159849936.0000 - mae: 8910.9756 - val_loss: 492443136.0000 - val_mae: 13078.5537\n",
      "Epoch 4168/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 159551024.0000 - mae: 8893.2695 - val_loss: 492468800.0000 - val_mae: 13068.3369\n",
      "Epoch 4169/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 159743360.0000 - mae: 8904.9648 - val_loss: 492759232.0000 - val_mae: 13091.6670\n",
      "Epoch 4170/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 159569184.0000 - mae: 8911.4922 - val_loss: 492012000.0000 - val_mae: 13039.8428\n",
      "Epoch 4171/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 160396528.0000 - mae: 8968.3418 - val_loss: 493428832.0000 - val_mae: 13064.4854\n",
      "Epoch 4172/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 161725248.0000 - mae: 8994.7051 - val_loss: 492392384.0000 - val_mae: 13048.0342\n",
      "Epoch 4173/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 159993296.0000 - mae: 8903.9199 - val_loss: 493834720.0000 - val_mae: 13138.5586\n",
      "Epoch 4174/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 160541200.0000 - mae: 8928.2031 - val_loss: 494757536.0000 - val_mae: 13195.4941\n",
      "Epoch 4175/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 160183776.0000 - mae: 8931.5566 - val_loss: 492777120.0000 - val_mae: 13057.8018\n",
      "Epoch 4176/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 159696080.0000 - mae: 8902.8193 - val_loss: 493079424.0000 - val_mae: 13084.7529\n",
      "Epoch 4177/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 159464448.0000 - mae: 8890.9834 - val_loss: 494134368.0000 - val_mae: 13149.7090\n",
      "Epoch 4178/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 160295856.0000 - mae: 8948.2461 - val_loss: 494045600.0000 - val_mae: 13148.1748\n",
      "Epoch 4179/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 160024496.0000 - mae: 8923.9121 - val_loss: 494169696.0000 - val_mae: 13152.0088\n",
      "Epoch 4180/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 160328848.0000 - mae: 8971.5713 - val_loss: 493296480.0000 - val_mae: 13050.4863\n",
      "Epoch 4181/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 160886048.0000 - mae: 8975.5820 - val_loss: 492716576.0000 - val_mae: 13050.4658\n",
      "Epoch 4182/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 159577792.0000 - mae: 8928.0615 - val_loss: 493677600.0000 - val_mae: 13060.2715\n",
      "Epoch 4183/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 160699056.0000 - mae: 8978.4912 - val_loss: 494583936.0000 - val_mae: 13161.9600\n",
      "Epoch 4184/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 159525472.0000 - mae: 8898.7734 - val_loss: 493011456.0000 - val_mae: 13075.8604\n",
      "Epoch 4185/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 160257792.0000 - mae: 8950.0068 - val_loss: 492913760.0000 - val_mae: 13071.5068\n",
      "Epoch 4186/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 160119088.0000 - mae: 8927.2236 - val_loss: 493903488.0000 - val_mae: 13120.6182\n",
      "Epoch 4187/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 159254000.0000 - mae: 8956.0459 - val_loss: 493919008.0000 - val_mae: 13061.7920\n",
      "Epoch 4188/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 160300464.0000 - mae: 8939.3955 - val_loss: 493559776.0000 - val_mae: 13073.1123\n",
      "Epoch 4189/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 158878288.0000 - mae: 8896.3301 - val_loss: 494660992.0000 - val_mae: 13155.8174\n",
      "Epoch 4190/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 159058992.0000 - mae: 8895.0508 - val_loss: 493630560.0000 - val_mae: 13104.6865\n",
      "Epoch 4191/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 158861264.0000 - mae: 8894.0977 - val_loss: 493981408.0000 - val_mae: 13063.8174\n",
      "Epoch 4192/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 160796208.0000 - mae: 8955.0566 - val_loss: 494133536.0000 - val_mae: 13061.5518\n",
      "Epoch 4193/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 162010448.0000 - mae: 9006.7129 - val_loss: 493434176.0000 - val_mae: 13067.3887\n",
      "Epoch 4194/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 159039360.0000 - mae: 8898.9580 - val_loss: 493524800.0000 - val_mae: 13089.5244\n",
      "Epoch 4195/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 159053664.0000 - mae: 8887.4531 - val_loss: 493708064.0000 - val_mae: 13105.2002\n",
      "Epoch 4196/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 158733184.0000 - mae: 8910.2217 - val_loss: 493739136.0000 - val_mae: 13096.7373\n",
      "Epoch 4197/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 158816512.0000 - mae: 8895.0898 - val_loss: 494531200.0000 - val_mae: 13147.1504\n",
      "Epoch 4198/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 159148448.0000 - mae: 8917.1182 - val_loss: 495952736.0000 - val_mae: 13208.4404\n",
      "Epoch 4199/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 159159216.0000 - mae: 8956.0918 - val_loss: 493799328.0000 - val_mae: 13080.5820\n",
      "Epoch 4200/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 158716032.0000 - mae: 8899.4229 - val_loss: 493774528.0000 - val_mae: 13087.0752\n",
      "Epoch 4201/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 159392592.0000 - mae: 8915.6240 - val_loss: 494065600.0000 - val_mae: 13098.0469\n",
      "Epoch 4202/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 159017200.0000 - mae: 8887.9736 - val_loss: 494909504.0000 - val_mae: 13160.1709\n",
      "Epoch 4203/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 159093600.0000 - mae: 8909.9834 - val_loss: 494574496.0000 - val_mae: 13136.7012\n",
      "Epoch 4204/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 158699136.0000 - mae: 8889.8145 - val_loss: 493702688.0000 - val_mae: 13083.0518\n",
      "Epoch 4205/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 158387168.0000 - mae: 8873.6846 - val_loss: 494726784.0000 - val_mae: 13157.6113\n",
      "Epoch 4206/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 158915424.0000 - mae: 8889.2783 - val_loss: 493987360.0000 - val_mae: 13111.2529\n",
      "Epoch 4207/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 158562832.0000 - mae: 8880.7607 - val_loss: 494664704.0000 - val_mae: 13134.3545\n",
      "Epoch 4208/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 158650240.0000 - mae: 8923.0791 - val_loss: 494959936.0000 - val_mae: 13092.7432\n",
      "Epoch 4209/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 159608000.0000 - mae: 8913.4736 - val_loss: 493361120.0000 - val_mae: 13053.0039\n",
      "Epoch 4210/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 158999584.0000 - mae: 8894.4463 - val_loss: 494313856.0000 - val_mae: 13077.5967\n",
      "Epoch 4211/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 159354608.0000 - mae: 8946.3350 - val_loss: 493973952.0000 - val_mae: 13091.0762\n",
      "Epoch 4212/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 159661280.0000 - mae: 8929.8145 - val_loss: 494164832.0000 - val_mae: 13090.9961\n",
      "Epoch 4213/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 158198256.0000 - mae: 8881.0811 - val_loss: 494159360.0000 - val_mae: 13096.7070\n",
      "Epoch 4214/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 158056720.0000 - mae: 8886.1797 - val_loss: 496927360.0000 - val_mae: 13237.0850\n",
      "Epoch 4215/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 158368256.0000 - mae: 8910.7480 - val_loss: 494551680.0000 - val_mae: 13104.7510\n",
      "Epoch 4216/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 158092288.0000 - mae: 8886.9375 - val_loss: 497553792.0000 - val_mae: 13279.0342\n",
      "Epoch 4217/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 158424320.0000 - mae: 8935.7686 - val_loss: 496804384.0000 - val_mae: 13111.2734\n",
      "Epoch 4218/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 159025600.0000 - mae: 8891.9824 - val_loss: 493951840.0000 - val_mae: 13085.6309\n",
      "Epoch 4219/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 158350064.0000 - mae: 8888.1963 - val_loss: 494537184.0000 - val_mae: 13106.4756\n",
      "Epoch 4220/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 158201104.0000 - mae: 8888.8193 - val_loss: 494530208.0000 - val_mae: 13097.6504\n",
      "Epoch 4221/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 157944192.0000 - mae: 8871.3652 - val_loss: 494951360.0000 - val_mae: 13115.3877\n",
      "Epoch 4222/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 158005088.0000 - mae: 8883.2109 - val_loss: 495237632.0000 - val_mae: 13113.2178\n",
      "Epoch 4223/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 157942768.0000 - mae: 8893.4805 - val_loss: 495437376.0000 - val_mae: 13090.0869\n",
      "Epoch 4224/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 161160704.0000 - mae: 8993.5430 - val_loss: 495003168.0000 - val_mae: 13092.3789\n",
      "Epoch 4225/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 159802464.0000 - mae: 8950.2920 - val_loss: 495205120.0000 - val_mae: 13087.5439\n",
      "Epoch 4226/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 158053536.0000 - mae: 8891.9814 - val_loss: 495160416.0000 - val_mae: 13125.6309\n",
      "Epoch 4227/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 157948688.0000 - mae: 8866.7178 - val_loss: 494960800.0000 - val_mae: 13101.1816\n",
      "Epoch 4228/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 157798464.0000 - mae: 8883.4492 - val_loss: 495481312.0000 - val_mae: 13132.8604\n",
      "Epoch 4229/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 157789664.0000 - mae: 8871.6426 - val_loss: 495085312.0000 - val_mae: 13113.8516\n",
      "Epoch 4230/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 157964336.0000 - mae: 8873.6650 - val_loss: 495539104.0000 - val_mae: 13127.1230\n",
      "Epoch 4231/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 157926048.0000 - mae: 8889.9375 - val_loss: 495835328.0000 - val_mae: 13105.7617\n",
      "Epoch 4232/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 158335152.0000 - mae: 8892.7920 - val_loss: 495886240.0000 - val_mae: 13154.4102\n",
      "Epoch 4233/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 157376608.0000 - mae: 8853.0596 - val_loss: 495228032.0000 - val_mae: 13110.1367\n",
      "Epoch 4234/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 157960384.0000 - mae: 8886.5449 - val_loss: 496371936.0000 - val_mae: 13118.3584\n",
      "Epoch 4235/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 157781328.0000 - mae: 8877.4980 - val_loss: 495411104.0000 - val_mae: 13102.6172\n",
      "Epoch 4236/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 158072576.0000 - mae: 8873.3516 - val_loss: 495410496.0000 - val_mae: 13113.0293\n",
      "Epoch 4237/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 157886992.0000 - mae: 8872.1377 - val_loss: 496043008.0000 - val_mae: 13167.4629\n",
      "Epoch 4238/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 157513072.0000 - mae: 8872.4902 - val_loss: 496097696.0000 - val_mae: 13151.4209\n",
      "Epoch 4239/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 158045968.0000 - mae: 8927.0928 - val_loss: 496032512.0000 - val_mae: 13131.6807\n",
      "Epoch 4240/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 157426352.0000 - mae: 8872.3594 - val_loss: 496444448.0000 - val_mae: 13195.3340\n",
      "Epoch 4241/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 157488736.0000 - mae: 8868.0771 - val_loss: 496055840.0000 - val_mae: 13099.6201\n",
      "Epoch 4242/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 157698816.0000 - mae: 8887.3828 - val_loss: 495788224.0000 - val_mae: 13116.9590\n",
      "Epoch 4243/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 157170192.0000 - mae: 8860.2441 - val_loss: 495924768.0000 - val_mae: 13130.9082\n",
      "Epoch 4244/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 157760816.0000 - mae: 8868.1387 - val_loss: 495745728.0000 - val_mae: 13115.3193\n",
      "Epoch 4245/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 157036336.0000 - mae: 8859.2588 - val_loss: 496510048.0000 - val_mae: 13186.3193\n",
      "Epoch 4246/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 157238352.0000 - mae: 8884.5576 - val_loss: 496338848.0000 - val_mae: 13108.3281\n",
      "Epoch 4247/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 157272608.0000 - mae: 8886.4678 - val_loss: 495989056.0000 - val_mae: 13142.6230\n",
      "Epoch 4248/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 157618768.0000 - mae: 8859.7969 - val_loss: 496098720.0000 - val_mae: 13104.6562\n",
      "Epoch 4249/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 156992176.0000 - mae: 8861.3896 - val_loss: 496348608.0000 - val_mae: 13158.2021\n",
      "Epoch 4250/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 157204096.0000 - mae: 8848.7568 - val_loss: 497159744.0000 - val_mae: 13198.8652\n",
      "Epoch 4251/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 157088496.0000 - mae: 8852.1318 - val_loss: 496630976.0000 - val_mae: 13147.7227\n",
      "Epoch 4252/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 156905648.0000 - mae: 8861.0566 - val_loss: 496090272.0000 - val_mae: 13119.7725\n",
      "Epoch 4253/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 157062480.0000 - mae: 8863.0586 - val_loss: 496394976.0000 - val_mae: 13151.1445\n",
      "Epoch 4254/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 158093856.0000 - mae: 8863.2090 - val_loss: 498163904.0000 - val_mae: 13245.9043\n",
      "Epoch 4255/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 156579392.0000 - mae: 8864.1406 - val_loss: 496555872.0000 - val_mae: 13119.3223\n",
      "Epoch 4256/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 158605248.0000 - mae: 8898.8760 - val_loss: 496773120.0000 - val_mae: 13109.6807\n",
      "Epoch 4257/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 157846048.0000 - mae: 8904.2188 - val_loss: 497208384.0000 - val_mae: 13127.8164\n",
      "Epoch 4258/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 156786880.0000 - mae: 8846.2734 - val_loss: 497648800.0000 - val_mae: 13213.1016\n",
      "Epoch 4259/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 156808224.0000 - mae: 8870.0732 - val_loss: 496783552.0000 - val_mae: 13133.0742\n",
      "Epoch 4260/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 156913584.0000 - mae: 8873.1533 - val_loss: 497593664.0000 - val_mae: 13192.9961\n",
      "Epoch 4261/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 156999696.0000 - mae: 8863.2324 - val_loss: 496828352.0000 - val_mae: 13130.8389\n",
      "Epoch 4262/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 156734224.0000 - mae: 8875.7979 - val_loss: 496515264.0000 - val_mae: 13119.8936\n",
      "Epoch 4263/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 157044304.0000 - mae: 8869.2363 - val_loss: 497344416.0000 - val_mae: 13206.1719\n",
      "Epoch 4264/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 156928624.0000 - mae: 8838.6572 - val_loss: 497471712.0000 - val_mae: 13209.1123\n",
      "Epoch 4265/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 156948736.0000 - mae: 8875.9814 - val_loss: 496619712.0000 - val_mae: 13148.3125\n",
      "Epoch 4266/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 157060368.0000 - mae: 8910.4180 - val_loss: 497740256.0000 - val_mae: 13136.9795\n",
      "Epoch 4267/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 160739280.0000 - mae: 9040.8271 - val_loss: 497640512.0000 - val_mae: 13207.4951\n",
      "Epoch 4268/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 156467088.0000 - mae: 8853.2764 - val_loss: 497299776.0000 - val_mae: 13170.6572\n",
      "Epoch 4269/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 156368704.0000 - mae: 8851.9385 - val_loss: 496732320.0000 - val_mae: 13144.0312\n",
      "Epoch 4270/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 156303056.0000 - mae: 8839.1240 - val_loss: 497136352.0000 - val_mae: 13156.0410\n",
      "Epoch 4271/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 156531296.0000 - mae: 8849.8486 - val_loss: 497053792.0000 - val_mae: 13152.6445\n",
      "Epoch 4272/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 156400880.0000 - mae: 8859.7236 - val_loss: 496933344.0000 - val_mae: 13139.8945\n",
      "Epoch 4273/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 156327264.0000 - mae: 8847.0811 - val_loss: 497242816.0000 - val_mae: 13175.1826\n",
      "Epoch 4274/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 155887280.0000 - mae: 8850.8633 - val_loss: 497500992.0000 - val_mae: 13132.4580\n",
      "Epoch 4275/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 156445408.0000 - mae: 8865.2217 - val_loss: 497756160.0000 - val_mae: 13187.6377\n",
      "Epoch 4276/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 156683744.0000 - mae: 8861.0986 - val_loss: 499529824.0000 - val_mae: 13287.8369\n",
      "Epoch 4277/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 157044784.0000 - mae: 8853.6484 - val_loss: 498711968.0000 - val_mae: 13235.5908\n",
      "Epoch 4278/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 157176192.0000 - mae: 8875.5547 - val_loss: 497462624.0000 - val_mae: 13142.1523\n",
      "Epoch 4279/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 156475584.0000 - mae: 8863.6562 - val_loss: 497133472.0000 - val_mae: 13153.3955\n",
      "Epoch 4280/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 156099648.0000 - mae: 8849.5771 - val_loss: 497596512.0000 - val_mae: 13156.4551\n",
      "Epoch 4281/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 156568512.0000 - mae: 8854.3330 - val_loss: 497032512.0000 - val_mae: 13155.4336\n",
      "Epoch 4282/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 155913120.0000 - mae: 8850.3945 - val_loss: 497304416.0000 - val_mae: 13147.5195\n",
      "Epoch 4283/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 155895088.0000 - mae: 8841.9561 - val_loss: 498593920.0000 - val_mae: 13219.4160\n",
      "Epoch 4284/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 155839472.0000 - mae: 8856.6963 - val_loss: 497625056.0000 - val_mae: 13157.5068\n",
      "Epoch 4285/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 156422576.0000 - mae: 8869.2305 - val_loss: 498169280.0000 - val_mae: 13161.1055\n",
      "Epoch 4286/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 157924912.0000 - mae: 8916.7891 - val_loss: 499596704.0000 - val_mae: 13290.6631\n",
      "Epoch 4287/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 156230208.0000 - mae: 8844.7539 - val_loss: 498044256.0000 - val_mae: 13185.5762\n",
      "Epoch 4288/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 155710176.0000 - mae: 8852.6758 - val_loss: 497983904.0000 - val_mae: 13169.2412\n",
      "Epoch 4289/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 155438208.0000 - mae: 8825.3467 - val_loss: 498398240.0000 - val_mae: 13203.5850\n",
      "Epoch 4290/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 156015920.0000 - mae: 8849.9736 - val_loss: 498669376.0000 - val_mae: 13155.8945\n",
      "Epoch 4291/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 155467792.0000 - mae: 8863.3037 - val_loss: 500127104.0000 - val_mae: 13295.4023\n",
      "Epoch 4292/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 156129664.0000 - mae: 8870.1338 - val_loss: 498452640.0000 - val_mae: 13196.7627\n",
      "Epoch 4293/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 157016000.0000 - mae: 8865.5107 - val_loss: 498708960.0000 - val_mae: 13213.0908\n",
      "Epoch 4294/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 156193392.0000 - mae: 8865.7402 - val_loss: 498494752.0000 - val_mae: 13152.3975\n",
      "Epoch 4295/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 155974688.0000 - mae: 8848.2930 - val_loss: 498017024.0000 - val_mae: 13159.3535\n",
      "Epoch 4296/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 155638512.0000 - mae: 8837.6309 - val_loss: 498255648.0000 - val_mae: 13161.8301\n",
      "Epoch 4297/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 155744608.0000 - mae: 8835.8379 - val_loss: 498668000.0000 - val_mae: 13188.0625\n",
      "Epoch 4298/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 155512816.0000 - mae: 8835.3398 - val_loss: 498597728.0000 - val_mae: 13173.8652\n",
      "Epoch 4299/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 155380912.0000 - mae: 8824.1572 - val_loss: 498545600.0000 - val_mae: 13181.5947\n",
      "Epoch 4300/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 155597712.0000 - mae: 8853.5781 - val_loss: 499373600.0000 - val_mae: 13228.0137\n",
      "Epoch 4301/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 155589312.0000 - mae: 8837.8574 - val_loss: 498737024.0000 - val_mae: 13196.6318\n",
      "Epoch 4302/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 155453568.0000 - mae: 8840.4463 - val_loss: 498880064.0000 - val_mae: 13163.3486\n",
      "Epoch 4303/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 155698016.0000 - mae: 8862.8516 - val_loss: 499705184.0000 - val_mae: 13249.6445\n",
      "Epoch 4304/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 155797248.0000 - mae: 8840.2080 - val_loss: 499127584.0000 - val_mae: 13207.5469\n",
      "Epoch 4305/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 155343520.0000 - mae: 8822.3174 - val_loss: 498896160.0000 - val_mae: 13165.0557\n",
      "Epoch 4306/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 155394384.0000 - mae: 8835.2051 - val_loss: 498887840.0000 - val_mae: 13205.6094\n",
      "Epoch 4307/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 155509392.0000 - mae: 8832.8281 - val_loss: 498993056.0000 - val_mae: 13152.3301\n",
      "Epoch 4308/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 155102016.0000 - mae: 8830.8428 - val_loss: 499635072.0000 - val_mae: 13245.8594\n",
      "Epoch 4309/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 154962000.0000 - mae: 8823.6748 - val_loss: 498648064.0000 - val_mae: 13166.6055\n",
      "Epoch 4310/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 155199040.0000 - mae: 8845.1201 - val_loss: 498488640.0000 - val_mae: 13175.7422\n",
      "Epoch 4311/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 155278224.0000 - mae: 8807.5674 - val_loss: 499412224.0000 - val_mae: 13242.2979\n",
      "Epoch 4312/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 155165056.0000 - mae: 8826.4033 - val_loss: 498860160.0000 - val_mae: 13185.5859\n",
      "Epoch 4313/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 155112976.0000 - mae: 8847.7334 - val_loss: 499226304.0000 - val_mae: 13179.0654\n",
      "Epoch 4314/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 155567136.0000 - mae: 8840.2900 - val_loss: 499620544.0000 - val_mae: 13240.9492\n",
      "Epoch 4315/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 155205472.0000 - mae: 8834.1533 - val_loss: 499100480.0000 - val_mae: 13189.3994\n",
      "Epoch 4316/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 154895392.0000 - mae: 8824.6826 - val_loss: 498864000.0000 - val_mae: 13196.4277\n",
      "Epoch 4317/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 154689056.0000 - mae: 8819.2793 - val_loss: 499156576.0000 - val_mae: 13188.3926\n",
      "Epoch 4318/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 154819584.0000 - mae: 8821.0137 - val_loss: 500421088.0000 - val_mae: 13266.0283\n",
      "Epoch 4319/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 155276704.0000 - mae: 8826.4307 - val_loss: 499160128.0000 - val_mae: 13206.3516\n",
      "Epoch 4320/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 154612576.0000 - mae: 8809.0693 - val_loss: 499348736.0000 - val_mae: 13198.1523\n",
      "Epoch 4321/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 154987168.0000 - mae: 8821.3252 - val_loss: 503193984.0000 - val_mae: 13400.6670\n",
      "Epoch 4322/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 156038752.0000 - mae: 8844.4766 - val_loss: 500766336.0000 - val_mae: 13268.4844\n",
      "Epoch 4323/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 156461312.0000 - mae: 8874.1787 - val_loss: 499693664.0000 - val_mae: 13213.3643\n",
      "Epoch 4324/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 154683616.0000 - mae: 8824.3750 - val_loss: 500638144.0000 - val_mae: 13283.4463\n",
      "Epoch 4325/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 155136432.0000 - mae: 8847.7695 - val_loss: 501260320.0000 - val_mae: 13305.5352\n",
      "Epoch 4326/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 155225072.0000 - mae: 8837.2070 - val_loss: 499994368.0000 - val_mae: 13237.7021\n",
      "Epoch 4327/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 154826784.0000 - mae: 8845.3174 - val_loss: 500310240.0000 - val_mae: 13166.0215\n",
      "Epoch 4328/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 155512480.0000 - mae: 8838.0137 - val_loss: 499450240.0000 - val_mae: 13191.9658\n",
      "Epoch 4329/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 154674288.0000 - mae: 8811.6504 - val_loss: 499871840.0000 - val_mae: 13219.3467\n",
      "Epoch 4330/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 154326736.0000 - mae: 8822.9004 - val_loss: 500038528.0000 - val_mae: 13176.7969\n",
      "Epoch 4331/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 154616352.0000 - mae: 8814.5098 - val_loss: 499748032.0000 - val_mae: 13225.2939\n",
      "Epoch 4332/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 154766128.0000 - mae: 8832.1143 - val_loss: 499660416.0000 - val_mae: 13216.8389\n",
      "Epoch 4333/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 155288096.0000 - mae: 8843.4316 - val_loss: 499861568.0000 - val_mae: 13206.8027\n",
      "Epoch 4334/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 155063504.0000 - mae: 8840.5566 - val_loss: 499591456.0000 - val_mae: 13186.0488\n",
      "Epoch 4335/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 154171344.0000 - mae: 8807.4756 - val_loss: 500088768.0000 - val_mae: 13210.6123\n",
      "Epoch 4336/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 154343632.0000 - mae: 8821.6699 - val_loss: 499962176.0000 - val_mae: 13230.1602\n",
      "Epoch 4337/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 154183808.0000 - mae: 8815.5166 - val_loss: 500117184.0000 - val_mae: 13203.1729\n",
      "Epoch 4338/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 154575200.0000 - mae: 8828.5801 - val_loss: 500236672.0000 - val_mae: 13190.4043\n",
      "Epoch 4339/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 153921456.0000 - mae: 8804.1836 - val_loss: 500073440.0000 - val_mae: 13229.5244\n",
      "Epoch 4340/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 153990720.0000 - mae: 8815.2842 - val_loss: 500400192.0000 - val_mae: 13210.5010\n",
      "Epoch 4341/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 154135600.0000 - mae: 8821.5303 - val_loss: 500119744.0000 - val_mae: 13217.7314\n",
      "Epoch 4342/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 154284016.0000 - mae: 8805.1016 - val_loss: 500883520.0000 - val_mae: 13270.9834\n",
      "Epoch 4343/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 153808832.0000 - mae: 8807.2480 - val_loss: 499981248.0000 - val_mae: 13185.6504\n",
      "Epoch 4344/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 154486448.0000 - mae: 8819.9082 - val_loss: 500951424.0000 - val_mae: 13257.9697\n",
      "Epoch 4345/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 154448720.0000 - mae: 8824.0244 - val_loss: 499988608.0000 - val_mae: 13226.5234\n",
      "Epoch 4346/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 154087216.0000 - mae: 8820.8320 - val_loss: 500525024.0000 - val_mae: 13215.7861\n",
      "Epoch 4347/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 153758512.0000 - mae: 8799.4414 - val_loss: 500794944.0000 - val_mae: 13240.3994\n",
      "Epoch 4348/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 153942784.0000 - mae: 8807.6953 - val_loss: 500437984.0000 - val_mae: 13238.7715\n",
      "Epoch 4349/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 153948944.0000 - mae: 8808.5752 - val_loss: 501269120.0000 - val_mae: 13257.9893\n",
      "Epoch 4350/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 153956176.0000 - mae: 8810.0264 - val_loss: 500052416.0000 - val_mae: 13205.6299\n",
      "Epoch 4351/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 154994608.0000 - mae: 8861.9082 - val_loss: 500482016.0000 - val_mae: 13201.5410\n",
      "Epoch 4352/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 154105056.0000 - mae: 8824.3350 - val_loss: 501388288.0000 - val_mae: 13284.2393\n",
      "Epoch 4353/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 153768976.0000 - mae: 8810.0791 - val_loss: 501115680.0000 - val_mae: 13254.9951\n",
      "Epoch 4354/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 153575072.0000 - mae: 8814.0293 - val_loss: 501334304.0000 - val_mae: 13203.5137\n",
      "Epoch 4355/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 154594000.0000 - mae: 8809.5732 - val_loss: 500241792.0000 - val_mae: 13206.3184\n",
      "Epoch 4356/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 154406464.0000 - mae: 8826.2012 - val_loss: 501045920.0000 - val_mae: 13252.7979\n",
      "Epoch 4357/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 154934560.0000 - mae: 8838.6494 - val_loss: 502728608.0000 - val_mae: 13349.8115\n",
      "Epoch 4358/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 153582192.0000 - mae: 8794.5947 - val_loss: 500932992.0000 - val_mae: 13230.2822\n",
      "Epoch 4359/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 153810432.0000 - mae: 8822.9248 - val_loss: 501246816.0000 - val_mae: 13247.3350\n",
      "Epoch 4360/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 153856192.0000 - mae: 8812.4619 - val_loss: 501246496.0000 - val_mae: 13230.7939\n",
      "Epoch 4361/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 153344000.0000 - mae: 8807.6240 - val_loss: 501062336.0000 - val_mae: 13210.6729\n",
      "Epoch 4362/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 153776656.0000 - mae: 8832.4180 - val_loss: 502835040.0000 - val_mae: 13350.9287\n",
      "Epoch 4363/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 153179728.0000 - mae: 8801.5010 - val_loss: 501360288.0000 - val_mae: 13224.1113\n",
      "Epoch 4364/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 153237776.0000 - mae: 8795.0732 - val_loss: 500908512.0000 - val_mae: 13222.6758\n",
      "Epoch 4365/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 153228784.0000 - mae: 8784.9375 - val_loss: 501970016.0000 - val_mae: 13302.0186\n",
      "Epoch 4366/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 153835296.0000 - mae: 8824.9629 - val_loss: 501597664.0000 - val_mae: 13228.5508\n",
      "Epoch 4367/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 153248768.0000 - mae: 8814.4932 - val_loss: 501252864.0000 - val_mae: 13208.5596\n",
      "Epoch 4368/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 153581776.0000 - mae: 8836.1982 - val_loss: 501859296.0000 - val_mae: 13269.4033\n",
      "Epoch 4369/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 153886064.0000 - mae: 8831.2812 - val_loss: 502823680.0000 - val_mae: 13336.9678\n",
      "Epoch 4370/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 153637360.0000 - mae: 8818.5068 - val_loss: 502000288.0000 - val_mae: 13266.4277\n",
      "Epoch 4371/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 152989536.0000 - mae: 8780.7910 - val_loss: 501600576.0000 - val_mae: 13282.2695\n",
      "Epoch 4372/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 154462080.0000 - mae: 8879.1348 - val_loss: 505328736.0000 - val_mae: 13240.7646\n",
      "Epoch 4373/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 154907808.0000 - mae: 8878.8877 - val_loss: 501851680.0000 - val_mae: 13236.9355\n",
      "Epoch 4374/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 153815600.0000 - mae: 8823.4014 - val_loss: 501074400.0000 - val_mae: 13246.3975\n",
      "Epoch 4375/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 153306192.0000 - mae: 8809.2412 - val_loss: 502554496.0000 - val_mae: 13289.7695\n",
      "Epoch 4376/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 153371920.0000 - mae: 8827.0596 - val_loss: 502508704.0000 - val_mae: 13299.0039\n",
      "Epoch 4377/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 153229936.0000 - mae: 8793.6836 - val_loss: 501943648.0000 - val_mae: 13259.0723\n",
      "Epoch 4378/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 153351232.0000 - mae: 8804.4160 - val_loss: 502611680.0000 - val_mae: 13224.0049\n",
      "Epoch 4379/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 154052672.0000 - mae: 8803.0977 - val_loss: 501525472.0000 - val_mae: 13236.8672\n",
      "Epoch 4380/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 152773376.0000 - mae: 8793.2256 - val_loss: 501301920.0000 - val_mae: 13225.4590\n",
      "Epoch 4381/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 152832256.0000 - mae: 8778.4043 - val_loss: 501524512.0000 - val_mae: 13245.6260\n",
      "Epoch 4382/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 152941712.0000 - mae: 8799.3193 - val_loss: 501631904.0000 - val_mae: 13249.6660\n",
      "Epoch 4383/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 152670848.0000 - mae: 8762.2607 - val_loss: 502714432.0000 - val_mae: 13320.3320\n",
      "Epoch 4384/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 153550048.0000 - mae: 8822.6084 - val_loss: 502805696.0000 - val_mae: 13324.1885\n",
      "Epoch 4385/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 152720784.0000 - mae: 8794.0977 - val_loss: 502148128.0000 - val_mae: 13243.6768\n",
      "Epoch 4386/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 152648208.0000 - mae: 8777.6426 - val_loss: 501760544.0000 - val_mae: 13230.4736\n",
      "Epoch 4387/6000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 152718544.0000 - mae: 8788.9814 - val_loss: 501974496.0000 - val_mae: 13237.4893\n",
      "Epoch 4388/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 152424304.0000 - mae: 8778.3350 - val_loss: 502810272.0000 - val_mae: 13312.2881\n",
      "Epoch 4389/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 153146304.0000 - mae: 8825.5713 - val_loss: 502482016.0000 - val_mae: 13240.1953\n",
      "Epoch 4390/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 152834304.0000 - mae: 8787.4932 - val_loss: 502507936.0000 - val_mae: 13271.1260\n",
      "Epoch 4391/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 152415104.0000 - mae: 8787.5371 - val_loss: 502226368.0000 - val_mae: 13250.4395\n",
      "Epoch 4392/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 152478608.0000 - mae: 8771.3477 - val_loss: 503269472.0000 - val_mae: 13331.5654\n",
      "Epoch 4393/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 152854224.0000 - mae: 8787.8545 - val_loss: 502604640.0000 - val_mae: 13289.0469\n",
      "Epoch 4394/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 152621360.0000 - mae: 8790.0078 - val_loss: 501745728.0000 - val_mae: 13247.2217\n",
      "Epoch 4395/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 152895792.0000 - mae: 8815.6865 - val_loss: 503018592.0000 - val_mae: 13256.6201\n",
      "Epoch 4396/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 154024320.0000 - mae: 8855.1885 - val_loss: 502409120.0000 - val_mae: 13275.5264\n",
      "Epoch 4397/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 152499120.0000 - mae: 8777.9131 - val_loss: 502392544.0000 - val_mae: 13260.9482\n",
      "Epoch 4398/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 152255952.0000 - mae: 8780.8145 - val_loss: 503035584.0000 - val_mae: 13277.2783\n",
      "Epoch 4399/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 152154368.0000 - mae: 8773.9639 - val_loss: 503213728.0000 - val_mae: 13265.7988\n",
      "Epoch 4400/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 152230912.0000 - mae: 8773.4268 - val_loss: 503678464.0000 - val_mae: 13338.7490\n",
      "Epoch 4401/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 152554944.0000 - mae: 8777.1650 - val_loss: 503474400.0000 - val_mae: 13329.1973\n",
      "Epoch 4402/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 152689952.0000 - mae: 8798.0039 - val_loss: 504422880.0000 - val_mae: 13361.7002\n",
      "Epoch 4403/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 152784656.0000 - mae: 8791.2607 - val_loss: 504919904.0000 - val_mae: 13412.1426\n",
      "Epoch 4404/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 151970320.0000 - mae: 8779.2480 - val_loss: 502881568.0000 - val_mae: 13252.4414\n",
      "Epoch 4405/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 152094688.0000 - mae: 8778.5146 - val_loss: 503380896.0000 - val_mae: 13303.6025\n",
      "Epoch 4406/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 152342512.0000 - mae: 8769.6826 - val_loss: 502879136.0000 - val_mae: 13235.6924\n",
      "Epoch 4407/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 152441200.0000 - mae: 8797.8623 - val_loss: 503099968.0000 - val_mae: 13266.7871\n",
      "Epoch 4408/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 152552592.0000 - mae: 8823.0547 - val_loss: 505397088.0000 - val_mae: 13430.7412\n",
      "Epoch 4409/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 152506752.0000 - mae: 8783.8418 - val_loss: 503527776.0000 - val_mae: 13295.4346\n",
      "Epoch 4410/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 152594640.0000 - mae: 8765.7227 - val_loss: 507379552.0000 - val_mae: 13497.0117\n",
      "Epoch 4411/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 152500064.0000 - mae: 8826.3770 - val_loss: 503114112.0000 - val_mae: 13266.6621\n",
      "Epoch 4412/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 152242176.0000 - mae: 8790.7549 - val_loss: 502893824.0000 - val_mae: 13265.3672\n",
      "Epoch 4413/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 152044896.0000 - mae: 8771.4883 - val_loss: 505216064.0000 - val_mae: 13395.8682\n",
      "Epoch 4414/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 151999472.0000 - mae: 8784.3525 - val_loss: 503116256.0000 - val_mae: 13256.2529\n",
      "Epoch 4415/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 151876048.0000 - mae: 8765.6416 - val_loss: 503228704.0000 - val_mae: 13290.9600\n",
      "Epoch 4416/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 151717040.0000 - mae: 8766.4336 - val_loss: 503801248.0000 - val_mae: 13324.2305\n",
      "Epoch 4417/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 151726656.0000 - mae: 8764.2451 - val_loss: 504116256.0000 - val_mae: 13342.1953\n",
      "Epoch 4418/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 152299856.0000 - mae: 8847.1670 - val_loss: 503640128.0000 - val_mae: 13261.2949\n",
      "Epoch 4419/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 152201344.0000 - mae: 8780.8232 - val_loss: 503080512.0000 - val_mae: 13276.3818\n",
      "Epoch 4420/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 151737376.0000 - mae: 8795.3262 - val_loss: 504303872.0000 - val_mae: 13266.8828\n",
      "Epoch 4421/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 151766464.0000 - mae: 8761.6621 - val_loss: 503385440.0000 - val_mae: 13286.1250\n",
      "Epoch 4422/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 151804208.0000 - mae: 8771.4600 - val_loss: 503235936.0000 - val_mae: 13277.1562\n",
      "Epoch 4423/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 151499680.0000 - mae: 8774.5039 - val_loss: 503230624.0000 - val_mae: 13260.4277\n",
      "Epoch 4424/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 151970480.0000 - mae: 8793.5693 - val_loss: 503804032.0000 - val_mae: 13315.8955\n",
      "Epoch 4425/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 151656240.0000 - mae: 8772.0508 - val_loss: 505474336.0000 - val_mae: 13404.4844\n",
      "Epoch 4426/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 152093408.0000 - mae: 8790.0322 - val_loss: 503954080.0000 - val_mae: 13310.1367\n",
      "Epoch 4427/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 151362352.0000 - mae: 8760.4414 - val_loss: 504360064.0000 - val_mae: 13309.1904\n",
      "Epoch 4428/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 151334288.0000 - mae: 8760.5117 - val_loss: 503882784.0000 - val_mae: 13308.1855\n",
      "Epoch 4429/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 151340960.0000 - mae: 8760.8545 - val_loss: 504457792.0000 - val_mae: 13352.7559\n",
      "Epoch 4430/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 151330704.0000 - mae: 8796.7227 - val_loss: 504253408.0000 - val_mae: 13279.0537\n",
      "Epoch 4431/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 151942640.0000 - mae: 8777.5908 - val_loss: 503769760.0000 - val_mae: 13292.9160\n",
      "Epoch 4432/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 152527456.0000 - mae: 8829.6074 - val_loss: 504970240.0000 - val_mae: 13277.3936\n",
      "Epoch 4433/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 151751808.0000 - mae: 8803.7168 - val_loss: 504495264.0000 - val_mae: 13285.0254\n",
      "Epoch 4434/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 151152400.0000 - mae: 8755.9639 - val_loss: 504568288.0000 - val_mae: 13340.9590\n",
      "Epoch 4435/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 151110448.0000 - mae: 8769.5713 - val_loss: 504362240.0000 - val_mae: 13284.4814\n",
      "Epoch 4436/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 151761824.0000 - mae: 8762.8945 - val_loss: 503569472.0000 - val_mae: 13259.7559\n",
      "Epoch 4437/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 151899664.0000 - mae: 8787.7920 - val_loss: 504137280.0000 - val_mae: 13294.7939\n",
      "Epoch 4438/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 151383136.0000 - mae: 8769.4316 - val_loss: 504857184.0000 - val_mae: 13296.7998\n",
      "Epoch 4439/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 151636672.0000 - mae: 8752.5361 - val_loss: 504227968.0000 - val_mae: 13300.2666\n",
      "Epoch 4440/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 151324128.0000 - mae: 8773.7842 - val_loss: 504541600.0000 - val_mae: 13312.7422\n",
      "Epoch 4441/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 151199760.0000 - mae: 8756.2686 - val_loss: 507017728.0000 - val_mae: 13452.6416\n",
      "Epoch 4442/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 151572320.0000 - mae: 8776.4941 - val_loss: 504712992.0000 - val_mae: 13356.6953\n",
      "Epoch 4443/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 151545968.0000 - mae: 8780.8535 - val_loss: 504869824.0000 - val_mae: 13346.3027\n",
      "Epoch 4444/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 151406480.0000 - mae: 8791.2031 - val_loss: 504966816.0000 - val_mae: 13322.1445\n",
      "Epoch 4445/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 150827744.0000 - mae: 8747.5986 - val_loss: 504317504.0000 - val_mae: 13300.7461\n",
      "Epoch 4446/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 151281104.0000 - mae: 8755.6855 - val_loss: 504813280.0000 - val_mae: 13292.6973\n",
      "Epoch 4447/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 151691792.0000 - mae: 8759.1250 - val_loss: 504669248.0000 - val_mae: 13272.8184\n",
      "Epoch 4448/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 151004736.0000 - mae: 8764.1943 - val_loss: 504678048.0000 - val_mae: 13311.1602\n",
      "Epoch 4449/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 150757856.0000 - mae: 8746.3682 - val_loss: 504735424.0000 - val_mae: 13321.1934\n",
      "Epoch 4450/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 150559344.0000 - mae: 8743.9541 - val_loss: 505780416.0000 - val_mae: 13368.5586\n",
      "Epoch 4451/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 150616512.0000 - mae: 8762.5508 - val_loss: 504717664.0000 - val_mae: 13287.2178\n",
      "Epoch 4452/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 150742192.0000 - mae: 8752.4385 - val_loss: 504777856.0000 - val_mae: 13328.2744\n",
      "Epoch 4453/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 150907424.0000 - mae: 8751.9932 - val_loss: 505271968.0000 - val_mae: 13325.7734\n",
      "Epoch 4454/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 150883792.0000 - mae: 8753.6201 - val_loss: 505084192.0000 - val_mae: 13358.8018\n",
      "Epoch 4455/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 150897280.0000 - mae: 8758.9854 - val_loss: 506099840.0000 - val_mae: 13403.4883\n",
      "Epoch 4456/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 151041744.0000 - mae: 8764.6475 - val_loss: 504416544.0000 - val_mae: 13301.5977\n",
      "Epoch 4457/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 150180752.0000 - mae: 8731.3301 - val_loss: 505436736.0000 - val_mae: 13368.9688\n",
      "Epoch 4458/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 150839552.0000 - mae: 8739.5771 - val_loss: 505832960.0000 - val_mae: 13369.7480\n",
      "Epoch 4459/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 151479456.0000 - mae: 8792.8721 - val_loss: 505605728.0000 - val_mae: 13356.9912\n",
      "Epoch 4460/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 150776128.0000 - mae: 8751.8730 - val_loss: 505560960.0000 - val_mae: 13365.5137\n",
      "Epoch 4461/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 150458560.0000 - mae: 8771.5674 - val_loss: 505267008.0000 - val_mae: 13304.3936\n",
      "Epoch 4462/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 150652816.0000 - mae: 8762.4385 - val_loss: 505099392.0000 - val_mae: 13307.7812\n",
      "Epoch 4463/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 150952688.0000 - mae: 8759.7236 - val_loss: 505142400.0000 - val_mae: 13285.2529\n",
      "Epoch 4464/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 151041728.0000 - mae: 8759.9570 - val_loss: 505390112.0000 - val_mae: 13314.2188\n",
      "Epoch 4465/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 150162576.0000 - mae: 8770.7129 - val_loss: 505087936.0000 - val_mae: 13309.6406\n",
      "Epoch 4466/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 151205888.0000 - mae: 8785.5947 - val_loss: 506410048.0000 - val_mae: 13409.5088\n",
      "Epoch 4467/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 150316224.0000 - mae: 8736.4922 - val_loss: 505738048.0000 - val_mae: 13359.4307\n",
      "Epoch 4468/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 150171264.0000 - mae: 8754.0410 - val_loss: 505410304.0000 - val_mae: 13310.6924\n",
      "Epoch 4469/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 150558192.0000 - mae: 8746.8311 - val_loss: 505773408.0000 - val_mae: 13337.4189\n",
      "Epoch 4470/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 150341552.0000 - mae: 8775.0449 - val_loss: 505320288.0000 - val_mae: 13305.4902\n",
      "Epoch 4471/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 150107456.0000 - mae: 8747.7275 - val_loss: 505653312.0000 - val_mae: 13332.9609\n",
      "Epoch 4472/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 150331776.0000 - mae: 8742.5254 - val_loss: 508038720.0000 - val_mae: 13479.4688\n",
      "Epoch 4473/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 150839984.0000 - mae: 8794.0059 - val_loss: 505828640.0000 - val_mae: 13312.9805\n",
      "Epoch 4474/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 149983344.0000 - mae: 8749.5801 - val_loss: 505917888.0000 - val_mae: 13319.1016\n",
      "Epoch 4475/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 150397568.0000 - mae: 8754.1182 - val_loss: 506416832.0000 - val_mae: 13375.7051\n",
      "Epoch 4476/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 149894256.0000 - mae: 8732.8018 - val_loss: 506302784.0000 - val_mae: 13350.3037\n",
      "Epoch 4477/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 149705424.0000 - mae: 8724.0840 - val_loss: 505611360.0000 - val_mae: 13347.7275\n",
      "Epoch 4478/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 149791152.0000 - mae: 8725.3711 - val_loss: 505713344.0000 - val_mae: 13343.2607\n",
      "Epoch 4479/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 150509232.0000 - mae: 8762.2393 - val_loss: 505837472.0000 - val_mae: 13318.8164\n",
      "Epoch 4480/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 149663904.0000 - mae: 8745.3604 - val_loss: 506180896.0000 - val_mae: 13313.7305\n",
      "Epoch 4481/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 150302320.0000 - mae: 8749.2480 - val_loss: 507341184.0000 - val_mae: 13306.1904\n",
      "Epoch 4482/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 152754960.0000 - mae: 8888.3301 - val_loss: 506466048.0000 - val_mae: 13387.5342\n",
      "Epoch 4483/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 149848080.0000 - mae: 8718.9414 - val_loss: 507345408.0000 - val_mae: 13437.6123\n",
      "Epoch 4484/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 149929728.0000 - mae: 8750.9814 - val_loss: 505267456.0000 - val_mae: 13328.8018\n",
      "Epoch 4485/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 149479280.0000 - mae: 8738.2012 - val_loss: 506816544.0000 - val_mae: 13319.5537\n",
      "Epoch 4486/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 149594768.0000 - mae: 8735.4805 - val_loss: 506863360.0000 - val_mae: 13399.9805\n",
      "Epoch 4487/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 149568304.0000 - mae: 8724.0898 - val_loss: 506671232.0000 - val_mae: 13376.5039\n",
      "Epoch 4488/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 149573456.0000 - mae: 8727.5332 - val_loss: 506448448.0000 - val_mae: 13335.4697\n",
      "Epoch 4489/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 149550736.0000 - mae: 8742.7305 - val_loss: 506604864.0000 - val_mae: 13379.1006\n",
      "Epoch 4490/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 149426496.0000 - mae: 8713.1240 - val_loss: 506810112.0000 - val_mae: 13399.0869\n",
      "Epoch 4491/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 149330240.0000 - mae: 8728.8369 - val_loss: 506579488.0000 - val_mae: 13313.4844\n",
      "Epoch 4492/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 149389456.0000 - mae: 8720.3066 - val_loss: 507627168.0000 - val_mae: 13440.0342\n",
      "Epoch 4493/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 149327456.0000 - mae: 8729.7383 - val_loss: 506257056.0000 - val_mae: 13327.5156\n",
      "Epoch 4494/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 149477632.0000 - mae: 8733.7686 - val_loss: 508486720.0000 - val_mae: 13490.3828\n",
      "Epoch 4495/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 149717472.0000 - mae: 8751.7432 - val_loss: 507068448.0000 - val_mae: 13391.5352\n",
      "Epoch 4496/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 149448960.0000 - mae: 8736.0352 - val_loss: 506618816.0000 - val_mae: 13337.7031\n",
      "Epoch 4497/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 149404544.0000 - mae: 8720.0039 - val_loss: 506986976.0000 - val_mae: 13382.9697\n",
      "Epoch 4498/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 149136880.0000 - mae: 8724.8086 - val_loss: 506202720.0000 - val_mae: 13319.5615\n",
      "Epoch 4499/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 149431296.0000 - mae: 8716.0645 - val_loss: 506097088.0000 - val_mae: 13333.9326\n",
      "Epoch 4500/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 149528704.0000 - mae: 8731.1768 - val_loss: 507467712.0000 - val_mae: 13410.1367\n",
      "Epoch 4501/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 150264176.0000 - mae: 8741.2051 - val_loss: 506456736.0000 - val_mae: 13360.1865\n",
      "Epoch 4502/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 148953184.0000 - mae: 8741.6885 - val_loss: 507918048.0000 - val_mae: 13330.7236\n",
      "Epoch 4503/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 150573776.0000 - mae: 8792.5996 - val_loss: 506312640.0000 - val_mae: 13330.6016\n",
      "Epoch 4504/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 148898032.0000 - mae: 8712.7188 - val_loss: 506760064.0000 - val_mae: 13366.3584\n",
      "Epoch 4505/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 149000384.0000 - mae: 8706.7158 - val_loss: 506954752.0000 - val_mae: 13383.7988\n",
      "Epoch 4506/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 149900528.0000 - mae: 8735.4189 - val_loss: 508287584.0000 - val_mae: 13465.6621\n",
      "Epoch 4507/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 149006000.0000 - mae: 8731.4805 - val_loss: 507000928.0000 - val_mae: 13349.7275\n",
      "Epoch 4508/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 149063104.0000 - mae: 8718.7988 - val_loss: 508409312.0000 - val_mae: 13464.1465\n",
      "Epoch 4509/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 150355168.0000 - mae: 8785.8027 - val_loss: 508669728.0000 - val_mae: 13480.7891\n",
      "Epoch 4510/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 149659520.0000 - mae: 8723.5449 - val_loss: 508329984.0000 - val_mae: 13446.4258\n",
      "Epoch 4511/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 149230816.0000 - mae: 8724.3652 - val_loss: 507037280.0000 - val_mae: 13372.2090\n",
      "Epoch 4512/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 149335488.0000 - mae: 8731.3105 - val_loss: 507814368.0000 - val_mae: 13428.9180\n",
      "Epoch 4513/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 148825600.0000 - mae: 8716.8545 - val_loss: 507239264.0000 - val_mae: 13385.2314\n",
      "Epoch 4514/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 148631760.0000 - mae: 8700.5195 - val_loss: 506721536.0000 - val_mae: 13339.9551\n",
      "Epoch 4515/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 148482832.0000 - mae: 8708.6768 - val_loss: 507364960.0000 - val_mae: 13364.5205\n",
      "Epoch 4516/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 148954656.0000 - mae: 8721.9395 - val_loss: 507293760.0000 - val_mae: 13360.7539\n",
      "Epoch 4517/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 148522032.0000 - mae: 8698.8164 - val_loss: 508014912.0000 - val_mae: 13423.0908\n",
      "Epoch 4518/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 148944352.0000 - mae: 8705.3311 - val_loss: 507145024.0000 - val_mae: 13369.1631\n",
      "Epoch 4519/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 149808224.0000 - mae: 8759.6484 - val_loss: 506766112.0000 - val_mae: 13338.1426\n",
      "Epoch 4520/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 148642944.0000 - mae: 8731.5234 - val_loss: 508038208.0000 - val_mae: 13334.6914\n",
      "Epoch 4521/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 149396032.0000 - mae: 8750.0273 - val_loss: 507166176.0000 - val_mae: 13377.4131\n",
      "Epoch 4522/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 148768672.0000 - mae: 8731.6035 - val_loss: 507860480.0000 - val_mae: 13335.3438\n",
      "Epoch 4523/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 148696160.0000 - mae: 8728.9658 - val_loss: 507009856.0000 - val_mae: 13385.8467\n",
      "Epoch 4524/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 148363232.0000 - mae: 8699.8623 - val_loss: 507265792.0000 - val_mae: 13364.6748\n",
      "Epoch 4525/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 148531744.0000 - mae: 8710.1357 - val_loss: 507726272.0000 - val_mae: 13344.8174\n",
      "Epoch 4526/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 148426576.0000 - mae: 8709.8369 - val_loss: 507546432.0000 - val_mae: 13393.4043\n",
      "Epoch 4527/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 148499264.0000 - mae: 8707.7588 - val_loss: 507701632.0000 - val_mae: 13410.5342\n",
      "Epoch 4528/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 148605168.0000 - mae: 8696.9375 - val_loss: 508762208.0000 - val_mae: 13458.3848\n",
      "Epoch 4529/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 149144864.0000 - mae: 8747.9561 - val_loss: 506826848.0000 - val_mae: 13356.5137\n",
      "Epoch 4530/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 148452000.0000 - mae: 8712.7236 - val_loss: 507390688.0000 - val_mae: 13346.7275\n",
      "Epoch 4531/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 149055856.0000 - mae: 8735.0986 - val_loss: 507573120.0000 - val_mae: 13354.0928\n",
      "Epoch 4532/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 148368240.0000 - mae: 8723.0713 - val_loss: 507831360.0000 - val_mae: 13391.7480\n",
      "Epoch 4533/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 148690496.0000 - mae: 8703.0693 - val_loss: 508963168.0000 - val_mae: 13450.5811\n",
      "Epoch 4534/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 148692768.0000 - mae: 8711.4277 - val_loss: 508035712.0000 - val_mae: 13395.7090\n",
      "Epoch 4535/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 148039488.0000 - mae: 8699.5088 - val_loss: 508168640.0000 - val_mae: 13341.4746\n",
      "Epoch 4536/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 148599584.0000 - mae: 8722.9355 - val_loss: 507953216.0000 - val_mae: 13361.1465\n",
      "Epoch 4537/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 148326160.0000 - mae: 8703.1621 - val_loss: 508253312.0000 - val_mae: 13335.4893\n",
      "Epoch 4538/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 148850880.0000 - mae: 8727.7559 - val_loss: 508086208.0000 - val_mae: 13365.8281\n",
      "Epoch 4539/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 148104944.0000 - mae: 8697.5928 - val_loss: 508147136.0000 - val_mae: 13386.6826\n",
      "Epoch 4540/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 148364992.0000 - mae: 8707.7646 - val_loss: 508018368.0000 - val_mae: 13344.5342\n",
      "Epoch 4541/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 148022064.0000 - mae: 8704.6934 - val_loss: 508401984.0000 - val_mae: 13411.3184\n",
      "Epoch 4542/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 147997904.0000 - mae: 8697.3516 - val_loss: 509344992.0000 - val_mae: 13471.0195\n",
      "Epoch 4543/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 148343184.0000 - mae: 8712.2715 - val_loss: 508698080.0000 - val_mae: 13366.5664\n",
      "Epoch 4544/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 148345568.0000 - mae: 8719.5420 - val_loss: 507960384.0000 - val_mae: 13363.2129\n",
      "Epoch 4545/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 148924080.0000 - mae: 8728.3125 - val_loss: 509176704.0000 - val_mae: 13450.1260\n",
      "Epoch 4546/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 147868480.0000 - mae: 8699.7695 - val_loss: 509815488.0000 - val_mae: 13491.1816\n",
      "Epoch 4547/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 149381056.0000 - mae: 8746.9463 - val_loss: 508772544.0000 - val_mae: 13407.6523\n",
      "Epoch 4548/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 148154416.0000 - mae: 8737.6113 - val_loss: 509555648.0000 - val_mae: 13350.7461\n",
      "Epoch 4549/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 148467648.0000 - mae: 8723.0156 - val_loss: 509659200.0000 - val_mae: 13480.3125\n",
      "Epoch 4550/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 148715296.0000 - mae: 8740.0439 - val_loss: 509686752.0000 - val_mae: 13444.8770\n",
      "Epoch 4551/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 147584208.0000 - mae: 8693.7803 - val_loss: 508393824.0000 - val_mae: 13373.7070\n",
      "Epoch 4552/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 148123712.0000 - mae: 8698.6387 - val_loss: 508801824.0000 - val_mae: 13451.2949\n",
      "Epoch 4553/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 148217824.0000 - mae: 8709.6719 - val_loss: 508284768.0000 - val_mae: 13382.6172\n",
      "Epoch 4554/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 147737024.0000 - mae: 8686.1270 - val_loss: 508824832.0000 - val_mae: 13406.1934\n",
      "Epoch 4555/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 147679888.0000 - mae: 8723.2979 - val_loss: 508699200.0000 - val_mae: 13403.4248\n",
      "Epoch 4556/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 147486688.0000 - mae: 8682.9561 - val_loss: 508972096.0000 - val_mae: 13412.2812\n",
      "Epoch 4557/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 147569312.0000 - mae: 8674.7773 - val_loss: 509285664.0000 - val_mae: 13454.4756\n",
      "Epoch 4558/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 148025376.0000 - mae: 8710.8477 - val_loss: 508812416.0000 - val_mae: 13429.7920\n",
      "Epoch 4559/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 147544016.0000 - mae: 8678.2764 - val_loss: 508873440.0000 - val_mae: 13372.6074\n",
      "Epoch 4560/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 147262432.0000 - mae: 8674.7109 - val_loss: 508865824.0000 - val_mae: 13410.0762\n",
      "Epoch 4561/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 147372176.0000 - mae: 8681.2910 - val_loss: 509846304.0000 - val_mae: 13443.2285\n",
      "Epoch 4562/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 147208272.0000 - mae: 8680.0732 - val_loss: 508792064.0000 - val_mae: 13377.3428\n",
      "Epoch 4563/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 147171120.0000 - mae: 8690.0068 - val_loss: 511619520.0000 - val_mae: 13587.5283\n",
      "Epoch 4564/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 147182480.0000 - mae: 8682.8447 - val_loss: 509441664.0000 - val_mae: 13369.2686\n",
      "Epoch 4565/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 147499616.0000 - mae: 8669.9814 - val_loss: 508870016.0000 - val_mae: 13403.4160\n",
      "Epoch 4566/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 147162688.0000 - mae: 8667.3750 - val_loss: 508320256.0000 - val_mae: 13371.8223\n",
      "Epoch 4567/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 147599376.0000 - mae: 8701.1748 - val_loss: 509598208.0000 - val_mae: 13377.4297\n",
      "Epoch 4568/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 148394336.0000 - mae: 8704.0518 - val_loss: 508751520.0000 - val_mae: 13376.9453\n",
      "Epoch 4569/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 147268912.0000 - mae: 8677.8447 - val_loss: 508834912.0000 - val_mae: 13382.6914\n",
      "Epoch 4570/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 147197568.0000 - mae: 8707.1709 - val_loss: 510240896.0000 - val_mae: 13488.7734\n",
      "Epoch 4571/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 147344176.0000 - mae: 8682.2314 - val_loss: 509173504.0000 - val_mae: 13390.7949\n",
      "Epoch 4572/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 147659712.0000 - mae: 8681.8818 - val_loss: 510546336.0000 - val_mae: 13514.7930\n",
      "Epoch 4573/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 146962560.0000 - mae: 8677.5254 - val_loss: 508944608.0000 - val_mae: 13390.9385\n",
      "Epoch 4574/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 147362192.0000 - mae: 8682.8115 - val_loss: 509091808.0000 - val_mae: 13418.0342\n",
      "Epoch 4575/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 147345712.0000 - mae: 8710.6338 - val_loss: 509179168.0000 - val_mae: 13395.8818\n",
      "Epoch 4576/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 147094000.0000 - mae: 8682.2725 - val_loss: 509324992.0000 - val_mae: 13440.0439\n",
      "Epoch 4577/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 147032448.0000 - mae: 8675.5625 - val_loss: 509113664.0000 - val_mae: 13389.2793\n",
      "Epoch 4578/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 146851504.0000 - mae: 8675.7793 - val_loss: 509238208.0000 - val_mae: 13408.3857\n",
      "Epoch 4579/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 147461472.0000 - mae: 8693.8662 - val_loss: 509948672.0000 - val_mae: 13477.2207\n",
      "Epoch 4580/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 146997232.0000 - mae: 8686.4961 - val_loss: 509319296.0000 - val_mae: 13386.2471\n",
      "Epoch 4581/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 147361056.0000 - mae: 8691.8389 - val_loss: 509364704.0000 - val_mae: 13387.8857\n",
      "Epoch 4582/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 146990224.0000 - mae: 8680.2627 - val_loss: 509044448.0000 - val_mae: 13416.0293\n",
      "Epoch 4583/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 146711904.0000 - mae: 8670.4268 - val_loss: 510778592.0000 - val_mae: 13501.1631\n",
      "Epoch 4584/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 146854688.0000 - mae: 8679.8320 - val_loss: 509085568.0000 - val_mae: 13403.2861\n",
      "Epoch 4585/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 146879632.0000 - mae: 8680.3037 - val_loss: 509675232.0000 - val_mae: 13400.5820\n",
      "Epoch 4586/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 147828336.0000 - mae: 8702.1992 - val_loss: 509314976.0000 - val_mae: 13370.3271\n",
      "Epoch 4587/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 146618528.0000 - mae: 8658.5166 - val_loss: 509479008.0000 - val_mae: 13437.2393\n",
      "Epoch 4588/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 146583568.0000 - mae: 8689.1055 - val_loss: 510627040.0000 - val_mae: 13379.6699\n",
      "Epoch 4589/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 147344848.0000 - mae: 8697.3086 - val_loss: 510188192.0000 - val_mae: 13403.5264\n",
      "Epoch 4590/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 147755888.0000 - mae: 8712.7871 - val_loss: 510208512.0000 - val_mae: 13370.0215\n",
      "Epoch 4591/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 147880032.0000 - mae: 8730.5020 - val_loss: 510075968.0000 - val_mae: 13454.8652\n",
      "Epoch 4592/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 146605584.0000 - mae: 8654.2354 - val_loss: 509601280.0000 - val_mae: 13413.3301\n",
      "Epoch 4593/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 147051632.0000 - mae: 8682.0234 - val_loss: 510244288.0000 - val_mae: 13382.7090\n",
      "Epoch 4594/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 146344816.0000 - mae: 8644.3096 - val_loss: 510119840.0000 - val_mae: 13465.2783\n",
      "Epoch 4595/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 146765600.0000 - mae: 8688.9980 - val_loss: 509703104.0000 - val_mae: 13404.4951\n",
      "Epoch 4596/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 146615760.0000 - mae: 8663.8574 - val_loss: 511607104.0000 - val_mae: 13546.0537\n",
      "Epoch 4597/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 146412048.0000 - mae: 8672.6318 - val_loss: 509838688.0000 - val_mae: 13412.8125\n",
      "Epoch 4598/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 146503504.0000 - mae: 8654.7959 - val_loss: 509696800.0000 - val_mae: 13428.9551\n",
      "Epoch 4599/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 146834832.0000 - mae: 8688.5176 - val_loss: 512953440.0000 - val_mae: 13587.9854\n",
      "Epoch 4600/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 146751584.0000 - mae: 8682.1709 - val_loss: 510124128.0000 - val_mae: 13404.3994\n",
      "Epoch 4601/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 146328752.0000 - mae: 8659.1572 - val_loss: 512558048.0000 - val_mae: 13595.9941\n",
      "Epoch 4602/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 146601808.0000 - mae: 8699.3164 - val_loss: 510184800.0000 - val_mae: 13424.2695\n",
      "Epoch 4603/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 146727792.0000 - mae: 8681.0059 - val_loss: 510339264.0000 - val_mae: 13382.5596\n",
      "Epoch 4604/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 147398640.0000 - mae: 8718.3496 - val_loss: 510957376.0000 - val_mae: 13403.0264\n",
      "Epoch 4605/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 146828704.0000 - mae: 8679.7451 - val_loss: 511852256.0000 - val_mae: 13551.6250\n",
      "Epoch 4606/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 146537472.0000 - mae: 8676.5264 - val_loss: 511111296.0000 - val_mae: 13515.0107\n",
      "Epoch 4607/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 146576272.0000 - mae: 8685.8672 - val_loss: 510429728.0000 - val_mae: 13462.2119\n",
      "Epoch 4608/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 146612656.0000 - mae: 8679.9521 - val_loss: 511239712.0000 - val_mae: 13516.0801\n",
      "Epoch 4609/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 146335536.0000 - mae: 8676.4062 - val_loss: 510555424.0000 - val_mae: 13397.3281\n",
      "Epoch 4610/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 147422720.0000 - mae: 8705.4512 - val_loss: 510325728.0000 - val_mae: 13477.0205\n",
      "Epoch 4611/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 146112208.0000 - mae: 8669.7334 - val_loss: 511186656.0000 - val_mae: 13401.9434\n",
      "Epoch 4612/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 145836032.0000 - mae: 8664.5645 - val_loss: 513622720.0000 - val_mae: 13621.3516\n",
      "Epoch 4613/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 147232480.0000 - mae: 8729.2354 - val_loss: 510407744.0000 - val_mae: 13464.1729\n",
      "Epoch 4614/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 146263104.0000 - mae: 8660.5049 - val_loss: 510253856.0000 - val_mae: 13425.2119\n",
      "Epoch 4615/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 146324304.0000 - mae: 8670.8613 - val_loss: 512561568.0000 - val_mae: 13574.1504\n",
      "Epoch 4616/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 148098000.0000 - mae: 8731.8311 - val_loss: 516512512.0000 - val_mae: 13735.9766\n",
      "Epoch 4617/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 147282432.0000 - mae: 8704.0518 - val_loss: 510328704.0000 - val_mae: 13424.9648\n",
      "Epoch 4618/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 145965952.0000 - mae: 8670.1074 - val_loss: 510893728.0000 - val_mae: 13400.9395\n",
      "Epoch 4619/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 146620624.0000 - mae: 8685.0244 - val_loss: 510466752.0000 - val_mae: 13429.6367\n",
      "Epoch 4620/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 146247360.0000 - mae: 8664.9756 - val_loss: 510179552.0000 - val_mae: 13409.5840\n",
      "Epoch 4621/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 145710752.0000 - mae: 8647.1885 - val_loss: 510184640.0000 - val_mae: 13416.3184\n",
      "Epoch 4622/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 145877472.0000 - mae: 8640.9062 - val_loss: 512454432.0000 - val_mae: 13551.9131\n",
      "Epoch 4623/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 145625120.0000 - mae: 8645.6357 - val_loss: 510492448.0000 - val_mae: 13427.1162\n",
      "Epoch 4624/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 146371536.0000 - mae: 8663.6631 - val_loss: 510226336.0000 - val_mae: 13423.0020\n",
      "Epoch 4625/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 145710496.0000 - mae: 8642.3711 - val_loss: 510505920.0000 - val_mae: 13465.8320\n",
      "Epoch 4626/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 146055536.0000 - mae: 8673.3213 - val_loss: 511137920.0000 - val_mae: 13440.6787\n",
      "Epoch 4627/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 145484096.0000 - mae: 8643.6445 - val_loss: 510806080.0000 - val_mae: 13455.4736\n",
      "Epoch 4628/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 145563456.0000 - mae: 8654.8047 - val_loss: 511910656.0000 - val_mae: 13537.8594\n",
      "Epoch 4629/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 145748368.0000 - mae: 8652.9316 - val_loss: 511487456.0000 - val_mae: 13487.0322\n",
      "Epoch 4630/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 145960816.0000 - mae: 8657.4668 - val_loss: 510876256.0000 - val_mae: 13452.1816\n",
      "Epoch 4631/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 145295440.0000 - mae: 8622.4355 - val_loss: 512138688.0000 - val_mae: 13538.7676\n",
      "Epoch 4632/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 146470080.0000 - mae: 8681.2109 - val_loss: 510807648.0000 - val_mae: 13440.9443\n",
      "Epoch 4633/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 145597312.0000 - mae: 8652.8467 - val_loss: 511419552.0000 - val_mae: 13471.3623\n",
      "Epoch 4634/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 145511040.0000 - mae: 8646.5703 - val_loss: 511408864.0000 - val_mae: 13500.6250\n",
      "Epoch 4635/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 145246240.0000 - mae: 8649.7256 - val_loss: 511270528.0000 - val_mae: 13438.1104\n",
      "Epoch 4636/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 145656624.0000 - mae: 8645.7705 - val_loss: 511435552.0000 - val_mae: 13471.0264\n",
      "Epoch 4637/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 145615072.0000 - mae: 8657.1777 - val_loss: 511922656.0000 - val_mae: 13414.3525\n",
      "Epoch 4638/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 146617552.0000 - mae: 8700.8545 - val_loss: 511533024.0000 - val_mae: 13448.7354\n",
      "Epoch 4639/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 145286336.0000 - mae: 8637.4863 - val_loss: 511434720.0000 - val_mae: 13475.7363\n",
      "Epoch 4640/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 145018736.0000 - mae: 8630.0645 - val_loss: 512131040.0000 - val_mae: 13506.8838\n",
      "Epoch 4641/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 145881872.0000 - mae: 8651.5029 - val_loss: 511348384.0000 - val_mae: 13425.8350\n",
      "Epoch 4642/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 145857008.0000 - mae: 8664.9561 - val_loss: 511191840.0000 - val_mae: 13458.0361\n",
      "Epoch 4643/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 146120032.0000 - mae: 8682.5469 - val_loss: 513043232.0000 - val_mae: 13564.8271\n",
      "Epoch 4644/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 146770800.0000 - mae: 8693.8271 - val_loss: 511460864.0000 - val_mae: 13473.9199\n",
      "Epoch 4645/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 146214432.0000 - mae: 8703.3398 - val_loss: 513217216.0000 - val_mae: 13579.1729\n",
      "Epoch 4646/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 145487136.0000 - mae: 8643.7979 - val_loss: 512372224.0000 - val_mae: 13516.8799\n",
      "Epoch 4647/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 145043568.0000 - mae: 8637.5244 - val_loss: 512135744.0000 - val_mae: 13506.7715\n",
      "Epoch 4648/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 145498752.0000 - mae: 8655.2949 - val_loss: 511538048.0000 - val_mae: 13425.6514\n",
      "Epoch 4649/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 145369760.0000 - mae: 8648.5781 - val_loss: 511577952.0000 - val_mae: 13466.4541\n",
      "Epoch 4650/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 144804176.0000 - mae: 8637.2490 - val_loss: 511922688.0000 - val_mae: 13464.3184\n",
      "Epoch 4651/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 145033600.0000 - mae: 8640.1406 - val_loss: 511374944.0000 - val_mae: 13444.0410\n",
      "Epoch 4652/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 144885568.0000 - mae: 8639.5820 - val_loss: 512035264.0000 - val_mae: 13476.9854\n",
      "Epoch 4653/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 144809952.0000 - mae: 8624.8047 - val_loss: 511523744.0000 - val_mae: 13446.9766\n",
      "Epoch 4654/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 144731984.0000 - mae: 8628.6416 - val_loss: 512702720.0000 - val_mae: 13533.5352\n",
      "Epoch 4655/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 144847760.0000 - mae: 8633.1934 - val_loss: 512576928.0000 - val_mae: 13506.1729\n",
      "Epoch 4656/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 145352576.0000 - mae: 8634.1191 - val_loss: 512289056.0000 - val_mae: 13519.4482\n",
      "Epoch 4657/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 145110656.0000 - mae: 8643.4756 - val_loss: 512462688.0000 - val_mae: 13438.4072\n",
      "Epoch 4658/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 145055808.0000 - mae: 8653.6230 - val_loss: 512049120.0000 - val_mae: 13450.4883\n",
      "Epoch 4659/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 145371264.0000 - mae: 8652.6152 - val_loss: 512268992.0000 - val_mae: 13460.4902\n",
      "Epoch 4660/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 145418368.0000 - mae: 8655.8350 - val_loss: 512891392.0000 - val_mae: 13427.3252\n",
      "Epoch 4661/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 145227120.0000 - mae: 8631.5859 - val_loss: 512128544.0000 - val_mae: 13466.4404\n",
      "Epoch 4662/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 144652416.0000 - mae: 8625.6953 - val_loss: 512500064.0000 - val_mae: 13485.1270\n",
      "Epoch 4663/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 144817264.0000 - mae: 8648.0586 - val_loss: 514207584.0000 - val_mae: 13600.1221\n",
      "Epoch 4664/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 144945952.0000 - mae: 8647.1113 - val_loss: 512751840.0000 - val_mae: 13532.6299\n",
      "Epoch 4665/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 144769024.0000 - mae: 8631.0752 - val_loss: 512796672.0000 - val_mae: 13532.8926\n",
      "Epoch 4666/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 144545920.0000 - mae: 8626.2656 - val_loss: 512274688.0000 - val_mae: 13489.7617\n",
      "Epoch 4667/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 144687264.0000 - mae: 8621.4688 - val_loss: 511986048.0000 - val_mae: 13452.7207\n",
      "Epoch 4668/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 144418736.0000 - mae: 8616.3271 - val_loss: 512879232.0000 - val_mae: 13536.0010\n",
      "Epoch 4669/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 144181568.0000 - mae: 8597.1934 - val_loss: 512315904.0000 - val_mae: 13488.8740\n",
      "Epoch 4670/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 144896736.0000 - mae: 8631.5879 - val_loss: 512658624.0000 - val_mae: 13523.9834\n",
      "Epoch 4671/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 144272848.0000 - mae: 8626.2217 - val_loss: 512563328.0000 - val_mae: 13474.3545\n",
      "Epoch 4672/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 144522208.0000 - mae: 8629.1914 - val_loss: 513037504.0000 - val_mae: 13523.8545\n",
      "Epoch 4673/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 144437808.0000 - mae: 8614.1533 - val_loss: 514723072.0000 - val_mae: 13624.1377\n",
      "Epoch 4674/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 144924288.0000 - mae: 8652.1289 - val_loss: 512751232.0000 - val_mae: 13471.6143\n",
      "Epoch 4675/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 144268176.0000 - mae: 8621.6172 - val_loss: 512768864.0000 - val_mae: 13522.3838\n",
      "Epoch 4676/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 144729696.0000 - mae: 8620.0947 - val_loss: 514106240.0000 - val_mae: 13584.3877\n",
      "Epoch 4677/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 144810784.0000 - mae: 8664.6328 - val_loss: 514057568.0000 - val_mae: 13578.6396\n",
      "Epoch 4678/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 144439504.0000 - mae: 8625.9277 - val_loss: 512965888.0000 - val_mae: 13512.1279\n",
      "Epoch 4679/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 145016544.0000 - mae: 8647.8438 - val_loss: 512560256.0000 - val_mae: 13453.2422\n",
      "Epoch 4680/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 144242032.0000 - mae: 8614.2090 - val_loss: 512962560.0000 - val_mae: 13471.7139\n",
      "Epoch 4681/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 144778656.0000 - mae: 8665.1250 - val_loss: 516788768.0000 - val_mae: 13482.7236\n",
      "Epoch 4682/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 149198160.0000 - mae: 8840.0293 - val_loss: 512825536.0000 - val_mae: 13469.4092\n",
      "Epoch 4683/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 144593968.0000 - mae: 8611.5713 - val_loss: 513574624.0000 - val_mae: 13538.4814\n",
      "Epoch 4684/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 144222544.0000 - mae: 8608.5713 - val_loss: 513491808.0000 - val_mae: 13556.1055\n",
      "Epoch 4685/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 143843808.0000 - mae: 8612.2549 - val_loss: 513155040.0000 - val_mae: 13496.1533\n",
      "Epoch 4686/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 144529024.0000 - mae: 8633.7812 - val_loss: 513734752.0000 - val_mae: 13466.6611\n",
      "Epoch 4687/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 143907056.0000 - mae: 8608.0283 - val_loss: 515173664.0000 - val_mae: 13645.4336\n",
      "Epoch 4688/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 145049568.0000 - mae: 8659.4746 - val_loss: 513733888.0000 - val_mae: 13549.5488\n",
      "Epoch 4689/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 144510576.0000 - mae: 8626.6045 - val_loss: 513802464.0000 - val_mae: 13555.6123\n",
      "Epoch 4690/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 144850336.0000 - mae: 8640.2676 - val_loss: 514031744.0000 - val_mae: 13562.8379\n",
      "Epoch 4691/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 144888128.0000 - mae: 8646.0918 - val_loss: 514926912.0000 - val_mae: 13611.1680\n",
      "Epoch 4692/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 144331504.0000 - mae: 8650.5928 - val_loss: 514869728.0000 - val_mae: 13636.5244\n",
      "Epoch 4693/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 144545744.0000 - mae: 8635.0283 - val_loss: 514045152.0000 - val_mae: 13544.2773\n",
      "Epoch 4694/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 144251968.0000 - mae: 8630.3652 - val_loss: 514560224.0000 - val_mae: 13581.0215\n",
      "Epoch 4695/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 144526368.0000 - mae: 8618.3799 - val_loss: 514270656.0000 - val_mae: 13583.1055\n",
      "Epoch 4696/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 144040624.0000 - mae: 8607.5430 - val_loss: 514197824.0000 - val_mae: 13556.6787\n",
      "Epoch 4697/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 143729568.0000 - mae: 8609.8887 - val_loss: 513552672.0000 - val_mae: 13528.8770\n",
      "Epoch 4698/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 143824544.0000 - mae: 8609.4990 - val_loss: 513532192.0000 - val_mae: 13515.7080\n",
      "Epoch 4699/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 143627200.0000 - mae: 8618.2178 - val_loss: 515688352.0000 - val_mae: 13641.5244\n",
      "Epoch 4700/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 144356496.0000 - mae: 8648.8379 - val_loss: 513864512.0000 - val_mae: 13525.7334\n",
      "Epoch 4701/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 144254896.0000 - mae: 8616.5791 - val_loss: 515563552.0000 - val_mae: 13636.9502\n",
      "Epoch 4702/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 143635072.0000 - mae: 8621.7559 - val_loss: 514019392.0000 - val_mae: 13505.3975\n",
      "Epoch 4703/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 143609376.0000 - mae: 8620.8311 - val_loss: 516015840.0000 - val_mae: 13663.4961\n",
      "Epoch 4704/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 144857632.0000 - mae: 8666.4824 - val_loss: 515212320.0000 - val_mae: 13604.7998\n",
      "Epoch 4705/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 144648448.0000 - mae: 8650.7031 - val_loss: 515737824.0000 - val_mae: 13641.5098\n",
      "Epoch 4706/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 144321552.0000 - mae: 8662.7510 - val_loss: 514391744.0000 - val_mae: 13469.6396\n",
      "Epoch 4707/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 144472560.0000 - mae: 8631.2480 - val_loss: 514586240.0000 - val_mae: 13465.5459\n",
      "Epoch 4708/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 143741024.0000 - mae: 8607.8652 - val_loss: 514424320.0000 - val_mae: 13566.7285\n",
      "Epoch 4709/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 143384432.0000 - mae: 8601.5488 - val_loss: 514090720.0000 - val_mae: 13513.7090\n",
      "Epoch 4710/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 143412032.0000 - mae: 8593.6230 - val_loss: 513709792.0000 - val_mae: 13491.2334\n",
      "Epoch 4711/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 143939168.0000 - mae: 8617.4004 - val_loss: 514091584.0000 - val_mae: 13499.9004\n",
      "Epoch 4712/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 143438768.0000 - mae: 8611.0674 - val_loss: 513972736.0000 - val_mae: 13487.8730\n",
      "Epoch 4713/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 143409280.0000 - mae: 8615.7627 - val_loss: 513766624.0000 - val_mae: 13489.8145\n",
      "Epoch 4714/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 143557584.0000 - mae: 8605.2822 - val_loss: 514254368.0000 - val_mae: 13528.9902\n",
      "Epoch 4715/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 143616736.0000 - mae: 8602.4932 - val_loss: 513898944.0000 - val_mae: 13504.1572\n",
      "Epoch 4716/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 143433824.0000 - mae: 8589.1855 - val_loss: 514334464.0000 - val_mae: 13538.5742\n",
      "Epoch 4717/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 143150880.0000 - mae: 8593.4355 - val_loss: 514469472.0000 - val_mae: 13547.3486\n",
      "Epoch 4718/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 143383632.0000 - mae: 8607.6855 - val_loss: 514485920.0000 - val_mae: 13498.3516\n",
      "Epoch 4719/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 143463568.0000 - mae: 8626.8008 - val_loss: 514319904.0000 - val_mae: 13551.6416\n",
      "Epoch 4720/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 143054560.0000 - mae: 8575.1504 - val_loss: 514666944.0000 - val_mae: 13568.3828\n",
      "Epoch 4721/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 145047744.0000 - mae: 8668.3857 - val_loss: 514557248.0000 - val_mae: 13547.2422\n",
      "Epoch 4722/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 144716416.0000 - mae: 8650.1992 - val_loss: 517636704.0000 - val_mae: 13719.4238\n",
      "Epoch 4723/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 144498160.0000 - mae: 8650.6270 - val_loss: 515585664.0000 - val_mae: 13634.7334\n",
      "Epoch 4724/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 143270496.0000 - mae: 8619.5215 - val_loss: 514547744.0000 - val_mae: 13506.5342\n",
      "Epoch 4725/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 143836416.0000 - mae: 8619.9531 - val_loss: 513900064.0000 - val_mae: 13514.0928\n",
      "Epoch 4726/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 143918352.0000 - mae: 8622.1084 - val_loss: 514388608.0000 - val_mae: 13510.4883\n",
      "Epoch 4727/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 142933216.0000 - mae: 8586.7227 - val_loss: 514668608.0000 - val_mae: 13550.8496\n",
      "Epoch 4728/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 142965744.0000 - mae: 8586.9141 - val_loss: 514313312.0000 - val_mae: 13511.6855\n",
      "Epoch 4729/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 143065632.0000 - mae: 8597.1582 - val_loss: 514675712.0000 - val_mae: 13521.9756\n",
      "Epoch 4730/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 143577888.0000 - mae: 8627.0664 - val_loss: 514767936.0000 - val_mae: 13549.7236\n",
      "Epoch 4731/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 143314992.0000 - mae: 8599.8398 - val_loss: 515673888.0000 - val_mae: 13622.4463\n",
      "Epoch 4732/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 144404720.0000 - mae: 8641.1299 - val_loss: 515657728.0000 - val_mae: 13603.3018\n",
      "Epoch 4733/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 143497456.0000 - mae: 8656.6660 - val_loss: 514821248.0000 - val_mae: 13504.3584\n",
      "Epoch 4734/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 142895648.0000 - mae: 8581.6475 - val_loss: 514284320.0000 - val_mae: 13532.7715\n",
      "Epoch 4735/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 143013856.0000 - mae: 8598.4590 - val_loss: 514910688.0000 - val_mae: 13552.5146\n",
      "Epoch 4736/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 142726960.0000 - mae: 8585.9561 - val_loss: 515244352.0000 - val_mae: 13573.3975\n",
      "Epoch 4737/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 142820704.0000 - mae: 8584.0967 - val_loss: 515839680.0000 - val_mae: 13598.4658\n",
      "Epoch 4738/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 143407856.0000 - mae: 8605.0479 - val_loss: 515639584.0000 - val_mae: 13583.5596\n",
      "Epoch 4739/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 143172176.0000 - mae: 8620.9023 - val_loss: 515333440.0000 - val_mae: 13553.7744\n",
      "Epoch 4740/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 142518352.0000 - mae: 8562.3193 - val_loss: 517470592.0000 - val_mae: 13687.0967\n",
      "Epoch 4741/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 142805872.0000 - mae: 8590.7080 - val_loss: 515073536.0000 - val_mae: 13531.2305\n",
      "Epoch 4742/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 143332384.0000 - mae: 8624.3086 - val_loss: 516623872.0000 - val_mae: 13646.7686\n",
      "Epoch 4743/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 142956784.0000 - mae: 8613.3828 - val_loss: 515404672.0000 - val_mae: 13518.9746\n",
      "Epoch 4744/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 142491968.0000 - mae: 8587.9355 - val_loss: 515319936.0000 - val_mae: 13514.3496\n",
      "Epoch 4745/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 142776224.0000 - mae: 8582.8184 - val_loss: 515321760.0000 - val_mae: 13542.0391\n",
      "Epoch 4746/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 142525440.0000 - mae: 8584.7998 - val_loss: 515855392.0000 - val_mae: 13589.5449\n",
      "Epoch 4747/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 142961952.0000 - mae: 8583.4355 - val_loss: 516172288.0000 - val_mae: 13610.3076\n",
      "Epoch 4748/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 142508096.0000 - mae: 8574.1328 - val_loss: 515268224.0000 - val_mae: 13540.7725\n",
      "Epoch 4749/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 142990304.0000 - mae: 8609.2539 - val_loss: 515901024.0000 - val_mae: 13515.7783\n",
      "Epoch 4750/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 142474352.0000 - mae: 8580.1904 - val_loss: 517063040.0000 - val_mae: 13653.4297\n",
      "Epoch 4751/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 142691120.0000 - mae: 8582.6572 - val_loss: 515742784.0000 - val_mae: 13555.9561\n",
      "Epoch 4752/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 142504128.0000 - mae: 8582.4307 - val_loss: 515337696.0000 - val_mae: 13544.0957\n",
      "Epoch 4753/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 142355456.0000 - mae: 8560.4609 - val_loss: 516435872.0000 - val_mae: 13616.1455\n",
      "Epoch 4754/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 142431600.0000 - mae: 8576.3301 - val_loss: 516017600.0000 - val_mae: 13585.0674\n",
      "Epoch 4755/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 142281408.0000 - mae: 8569.2461 - val_loss: 517431072.0000 - val_mae: 13689.3750\n",
      "Epoch 4756/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 143618128.0000 - mae: 8691.4209 - val_loss: 517035392.0000 - val_mae: 13533.0469\n",
      "Epoch 4757/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 142490064.0000 - mae: 8596.2949 - val_loss: 515974048.0000 - val_mae: 13542.9502\n",
      "Epoch 4758/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 142168384.0000 - mae: 8575.2305 - val_loss: 516927392.0000 - val_mae: 13662.6475\n",
      "Epoch 4759/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 142390112.0000 - mae: 8577.2646 - val_loss: 515899552.0000 - val_mae: 13571.2666\n",
      "Epoch 4760/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 142526256.0000 - mae: 8579.6748 - val_loss: 516061760.0000 - val_mae: 13590.0352\n",
      "Epoch 4761/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 142463824.0000 - mae: 8584.1367 - val_loss: 515949760.0000 - val_mae: 13584.3301\n",
      "Epoch 4762/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 142029728.0000 - mae: 8566.7939 - val_loss: 516482048.0000 - val_mae: 13607.1904\n",
      "Epoch 4763/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 142319760.0000 - mae: 8576.4912 - val_loss: 516324224.0000 - val_mae: 13599.5469\n",
      "Epoch 4764/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 142063952.0000 - mae: 8565.7422 - val_loss: 516833952.0000 - val_mae: 13626.3164\n",
      "Epoch 4765/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 142483312.0000 - mae: 8577.3838 - val_loss: 516962912.0000 - val_mae: 13639.1523\n",
      "Epoch 4766/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 142924320.0000 - mae: 8618.1533 - val_loss: 518030816.0000 - val_mae: 13690.4160\n",
      "Epoch 4767/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 142212064.0000 - mae: 8602.7764 - val_loss: 516674688.0000 - val_mae: 13612.2539\n",
      "Epoch 4768/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 142738048.0000 - mae: 8598.4990 - val_loss: 516003296.0000 - val_mae: 13559.7441\n",
      "Epoch 4769/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 142123184.0000 - mae: 8579.7568 - val_loss: 518137376.0000 - val_mae: 13695.5439\n",
      "Epoch 4770/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 141950080.0000 - mae: 8564.5518 - val_loss: 516531872.0000 - val_mae: 13558.7734\n",
      "Epoch 4771/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 142352144.0000 - mae: 8597.6611 - val_loss: 517299200.0000 - val_mae: 13656.8721\n",
      "Epoch 4772/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 141894272.0000 - mae: 8568.9082 - val_loss: 516182336.0000 - val_mae: 13543.7422\n",
      "Epoch 4773/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 141870688.0000 - mae: 8575.2646 - val_loss: 516395200.0000 - val_mae: 13586.4580\n",
      "Epoch 4774/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 141837616.0000 - mae: 8583.4639 - val_loss: 516738464.0000 - val_mae: 13542.1650\n",
      "Epoch 4775/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 142214464.0000 - mae: 8578.1201 - val_loss: 517575040.0000 - val_mae: 13685.4785\n",
      "Epoch 4776/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 142675296.0000 - mae: 8602.8408 - val_loss: 516750496.0000 - val_mae: 13597.8115\n",
      "Epoch 4777/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 142656496.0000 - mae: 8603.4297 - val_loss: 516908032.0000 - val_mae: 13631.6396\n",
      "Epoch 4778/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 142437520.0000 - mae: 8609.9756 - val_loss: 517458656.0000 - val_mae: 13647.9277\n",
      "Epoch 4779/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 142060576.0000 - mae: 8595.5986 - val_loss: 520298080.0000 - val_mae: 13806.7002\n",
      "Epoch 4780/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 142517136.0000 - mae: 8614.2441 - val_loss: 516624768.0000 - val_mae: 13573.4912\n",
      "Epoch 4781/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 141648672.0000 - mae: 8590.8389 - val_loss: 517435232.0000 - val_mae: 13535.4512\n",
      "Epoch 4782/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 141868448.0000 - mae: 8573.2861 - val_loss: 516738400.0000 - val_mae: 13566.1006\n",
      "Epoch 4783/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 141698256.0000 - mae: 8565.5723 - val_loss: 517525024.0000 - val_mae: 13643.1143\n",
      "Epoch 4784/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 141938592.0000 - mae: 8562.7490 - val_loss: 517460480.0000 - val_mae: 13610.4785\n",
      "Epoch 4785/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 142104304.0000 - mae: 8568.0322 - val_loss: 517178272.0000 - val_mae: 13608.4297\n",
      "Epoch 4786/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 141945216.0000 - mae: 8573.9326 - val_loss: 517161152.0000 - val_mae: 13584.8115\n",
      "Epoch 4787/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 141692912.0000 - mae: 8556.8291 - val_loss: 516771328.0000 - val_mae: 13559.3301\n",
      "Epoch 4788/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 141492944.0000 - mae: 8565.1689 - val_loss: 517000480.0000 - val_mae: 13603.3623\n",
      "Epoch 4789/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 141510032.0000 - mae: 8571.0537 - val_loss: 518175456.0000 - val_mae: 13679.4258\n",
      "Epoch 4790/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 141576944.0000 - mae: 8550.3848 - val_loss: 517051360.0000 - val_mae: 13609.9629\n",
      "Epoch 4791/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 141534080.0000 - mae: 8566.1143 - val_loss: 517307296.0000 - val_mae: 13620.3086\n",
      "Epoch 4792/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 142482768.0000 - mae: 8630.6113 - val_loss: 518156704.0000 - val_mae: 13519.6748\n",
      "Epoch 4793/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 141618512.0000 - mae: 8590.7422 - val_loss: 517307296.0000 - val_mae: 13590.8975\n",
      "Epoch 4794/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 140991536.0000 - mae: 8566.8545 - val_loss: 519745280.0000 - val_mae: 13764.5537\n",
      "Epoch 4795/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 142024976.0000 - mae: 8608.1104 - val_loss: 517225632.0000 - val_mae: 13607.9443\n",
      "Epoch 4796/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 141099408.0000 - mae: 8553.6182 - val_loss: 517176736.0000 - val_mae: 13586.4688\n",
      "Epoch 4797/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 141267968.0000 - mae: 8564.7910 - val_loss: 516992384.0000 - val_mae: 13575.3584\n",
      "Epoch 4798/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 141578928.0000 - mae: 8568.9150 - val_loss: 517750752.0000 - val_mae: 13618.1357\n",
      "Epoch 4799/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 142084208.0000 - mae: 8583.9229 - val_loss: 517895072.0000 - val_mae: 13663.1582\n",
      "Epoch 4800/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 141645280.0000 - mae: 8577.5391 - val_loss: 517564736.0000 - val_mae: 13615.0361\n",
      "Epoch 4801/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 141133888.0000 - mae: 8548.2256 - val_loss: 517738752.0000 - val_mae: 13588.4307\n",
      "Epoch 4802/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 141309408.0000 - mae: 8557.7930 - val_loss: 517404512.0000 - val_mae: 13632.0869\n",
      "Epoch 4803/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 141253296.0000 - mae: 8552.3730 - val_loss: 517645760.0000 - val_mae: 13585.4531\n",
      "Epoch 4804/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 141271872.0000 - mae: 8562.3672 - val_loss: 517967360.0000 - val_mae: 13647.8779\n",
      "Epoch 4805/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 142110048.0000 - mae: 8609.2412 - val_loss: 517696768.0000 - val_mae: 13628.4307\n",
      "Epoch 4806/6000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 142826080.0000 - mae: 8637.0928 - val_loss: 517260640.0000 - val_mae: 13562.7920\n",
      "Epoch 4807/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 143002096.0000 - mae: 8651.2344 - val_loss: 519565760.0000 - val_mae: 13565.3877\n",
      "Epoch 4808/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 141387200.0000 - mae: 8580.0449 - val_loss: 517382176.0000 - val_mae: 13568.4395\n",
      "Epoch 4809/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 141754304.0000 - mae: 8573.2852 - val_loss: 518862880.0000 - val_mae: 13561.0166\n",
      "Epoch 4810/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 141097488.0000 - mae: 8553.6982 - val_loss: 517889792.0000 - val_mae: 13626.2051\n",
      "Epoch 4811/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 140781456.0000 - mae: 8552.2012 - val_loss: 517863200.0000 - val_mae: 13618.1104\n",
      "Epoch 4812/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 140740608.0000 - mae: 8548.9688 - val_loss: 517809920.0000 - val_mae: 13580.0303\n",
      "Epoch 4813/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 140780288.0000 - mae: 8533.2568 - val_loss: 518192352.0000 - val_mae: 13660.7227\n",
      "Epoch 4814/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 140933184.0000 - mae: 8568.8213 - val_loss: 517900000.0000 - val_mae: 13595.8750\n",
      "Epoch 4815/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 141203568.0000 - mae: 8559.9775 - val_loss: 520831808.0000 - val_mae: 13796.8096\n",
      "Epoch 4816/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 141349152.0000 - mae: 8563.2949 - val_loss: 518388768.0000 - val_mae: 13652.1670\n",
      "Epoch 4817/6000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 140896480.0000 - mae: 8548.3574 - val_loss: 518072224.0000 - val_mae: 13624.6572\n",
      "Epoch 4818/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 140381312.0000 - mae: 8546.5430 - val_loss: 519061312.0000 - val_mae: 13575.1318\n",
      "Epoch 4819/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 140702960.0000 - mae: 8567.3857 - val_loss: 522674528.0000 - val_mae: 13878.7529\n",
      "Epoch 4820/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 141063168.0000 - mae: 8568.3975 - val_loss: 518333472.0000 - val_mae: 13607.5703\n",
      "Epoch 4821/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 140738032.0000 - mae: 8549.1768 - val_loss: 517699584.0000 - val_mae: 13627.0752\n",
      "Epoch 4822/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 140642352.0000 - mae: 8540.2129 - val_loss: 518379104.0000 - val_mae: 13641.2324\n",
      "Epoch 4823/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 140893600.0000 - mae: 8545.7334 - val_loss: 517929248.0000 - val_mae: 13635.5547\n",
      "Epoch 4824/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 140755904.0000 - mae: 8542.9287 - val_loss: 518926400.0000 - val_mae: 13677.9258\n",
      "Epoch 4825/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 140883056.0000 - mae: 8565.4102 - val_loss: 518628256.0000 - val_mae: 13584.0410\n",
      "Epoch 4826/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 140419296.0000 - mae: 8545.1387 - val_loss: 518897472.0000 - val_mae: 13681.1982\n",
      "Epoch 4827/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 140693840.0000 - mae: 8603.4736 - val_loss: 522982624.0000 - val_mae: 13607.0244\n",
      "Epoch 4828/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 141103888.0000 - mae: 8621.7178 - val_loss: 519910464.0000 - val_mae: 13752.4932\n",
      "Epoch 4829/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 140434112.0000 - mae: 8548.1719 - val_loss: 518397824.0000 - val_mae: 13634.3887\n",
      "Epoch 4830/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 140638880.0000 - mae: 8529.3301 - val_loss: 519345984.0000 - val_mae: 13685.4502\n",
      "Epoch 4831/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 140535296.0000 - mae: 8523.9551 - val_loss: 517863840.0000 - val_mae: 13617.2031\n",
      "Epoch 4832/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 140413408.0000 - mae: 8549.0293 - val_loss: 518650528.0000 - val_mae: 13590.2930\n",
      "Epoch 4833/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 141000992.0000 - mae: 8548.6729 - val_loss: 518261984.0000 - val_mae: 13570.8213\n",
      "Epoch 4834/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 140438784.0000 - mae: 8540.0830 - val_loss: 518831584.0000 - val_mae: 13661.8750\n",
      "Epoch 4835/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 140945952.0000 - mae: 8521.5635 - val_loss: 521453504.0000 - val_mae: 13810.8652\n",
      "Epoch 4836/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 141105120.0000 - mae: 8561.9932 - val_loss: 518373664.0000 - val_mae: 13630.8721\n",
      "Epoch 4837/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 140420384.0000 - mae: 8556.2773 - val_loss: 518808512.0000 - val_mae: 13605.6348\n",
      "Epoch 4838/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 140632144.0000 - mae: 8552.9111 - val_loss: 519237888.0000 - val_mae: 13671.3379\n",
      "Epoch 4839/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 140655808.0000 - mae: 8532.1523 - val_loss: 519530336.0000 - val_mae: 13691.0039\n",
      "Epoch 4840/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 140255200.0000 - mae: 8528.6426 - val_loss: 518709536.0000 - val_mae: 13616.1416\n",
      "Epoch 4841/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 140102832.0000 - mae: 8528.7266 - val_loss: 518838048.0000 - val_mae: 13630.5000\n",
      "Epoch 4842/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 140574448.0000 - mae: 8553.7461 - val_loss: 523143872.0000 - val_mae: 13870.7188\n",
      "Epoch 4843/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 140892032.0000 - mae: 8559.3682 - val_loss: 519113312.0000 - val_mae: 13667.3398\n",
      "Epoch 4844/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 140086288.0000 - mae: 8533.3096 - val_loss: 519164608.0000 - val_mae: 13605.4443\n",
      "Epoch 4845/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 140047568.0000 - mae: 8519.9707 - val_loss: 519379040.0000 - val_mae: 13679.5703\n",
      "Epoch 4846/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 140165440.0000 - mae: 8540.1826 - val_loss: 519011680.0000 - val_mae: 13618.6113\n",
      "Epoch 4847/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 140048992.0000 - mae: 8524.2695 - val_loss: 519044192.0000 - val_mae: 13614.9375\n",
      "Epoch 4848/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 140457712.0000 - mae: 8543.1621 - val_loss: 518938752.0000 - val_mae: 13639.5771\n",
      "Epoch 4849/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 140188304.0000 - mae: 8552.4863 - val_loss: 521992864.0000 - val_mae: 13806.0928\n",
      "Epoch 4850/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 140494976.0000 - mae: 8545.3750 - val_loss: 519859872.0000 - val_mae: 13700.1904\n",
      "Epoch 4851/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 141047424.0000 - mae: 8560.0625 - val_loss: 521626496.0000 - val_mae: 13804.2207\n",
      "Epoch 4852/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 140526800.0000 - mae: 8575.6445 - val_loss: 519378784.0000 - val_mae: 13635.4541\n",
      "Epoch 4853/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 139760784.0000 - mae: 8524.9375 - val_loss: 519891424.0000 - val_mae: 13715.8789\n",
      "Epoch 4854/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 140127312.0000 - mae: 8549.4395 - val_loss: 519262944.0000 - val_mae: 13628.9736\n",
      "Epoch 4855/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 139858272.0000 - mae: 8528.5010 - val_loss: 519964256.0000 - val_mae: 13721.5234\n",
      "Epoch 4856/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 139701760.0000 - mae: 8526.1875 - val_loss: 519657312.0000 - val_mae: 13622.3145\n",
      "Epoch 4857/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 139982432.0000 - mae: 8517.1055 - val_loss: 519219392.0000 - val_mae: 13618.1211\n",
      "Epoch 4858/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 139846704.0000 - mae: 8528.1914 - val_loss: 519061632.0000 - val_mae: 13605.6123\n",
      "Epoch 4859/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 139868752.0000 - mae: 8538.0234 - val_loss: 519673344.0000 - val_mae: 13611.3955\n",
      "Epoch 4860/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 140293856.0000 - mae: 8559.9424 - val_loss: 519491616.0000 - val_mae: 13635.1982\n",
      "Epoch 4861/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 139624336.0000 - mae: 8505.5146 - val_loss: 520326688.0000 - val_mae: 13733.4609\n",
      "Epoch 4862/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 139782688.0000 - mae: 8538.2939 - val_loss: 519398976.0000 - val_mae: 13659.8281\n",
      "Epoch 4863/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 139756064.0000 - mae: 8520.8086 - val_loss: 521343616.0000 - val_mae: 13781.7119\n",
      "Epoch 4864/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 140078544.0000 - mae: 8525.6787 - val_loss: 519635424.0000 - val_mae: 13686.8379\n",
      "Epoch 4865/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 139566256.0000 - mae: 8531.0371 - val_loss: 519511008.0000 - val_mae: 13637.2031\n",
      "Epoch 4866/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 140227424.0000 - mae: 8576.0488 - val_loss: 519627392.0000 - val_mae: 13653.3330\n",
      "Epoch 4867/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 140278688.0000 - mae: 8539.9580 - val_loss: 519060192.0000 - val_mae: 13663.8945\n",
      "Epoch 4868/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 139575680.0000 - mae: 8528.8643 - val_loss: 520961824.0000 - val_mae: 13759.2822\n",
      "Epoch 4869/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 139639744.0000 - mae: 8514.0010 - val_loss: 519405568.0000 - val_mae: 13685.7979\n",
      "Epoch 4870/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 139394112.0000 - mae: 8517.7334 - val_loss: 519598016.0000 - val_mae: 13632.1777\n",
      "Epoch 4871/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 139618480.0000 - mae: 8529.4004 - val_loss: 519597376.0000 - val_mae: 13666.1074\n",
      "Epoch 4872/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 139433616.0000 - mae: 8513.9814 - val_loss: 519615520.0000 - val_mae: 13644.3379\n",
      "Epoch 4873/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 140177536.0000 - mae: 8534.4121 - val_loss: 520168800.0000 - val_mae: 13726.0000\n",
      "Epoch 4874/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 139888048.0000 - mae: 8517.7930 - val_loss: 520281056.0000 - val_mae: 13693.2383\n",
      "Epoch 4875/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 139586496.0000 - mae: 8542.6465 - val_loss: 519719456.0000 - val_mae: 13625.8994\n",
      "Epoch 4876/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 139028480.0000 - mae: 8513.7998 - val_loss: 519949504.0000 - val_mae: 13709.5967\n",
      "Epoch 4877/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 139911344.0000 - mae: 8528.2871 - val_loss: 520850016.0000 - val_mae: 13746.8125\n",
      "Epoch 4878/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 139582944.0000 - mae: 8551.8984 - val_loss: 519720224.0000 - val_mae: 13637.3096\n",
      "Epoch 4879/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 139609440.0000 - mae: 8532.4189 - val_loss: 524557440.0000 - val_mae: 13922.9434\n",
      "Epoch 4880/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 139849664.0000 - mae: 8577.0459 - val_loss: 520041216.0000 - val_mae: 13637.3779\n",
      "Epoch 4881/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 139447024.0000 - mae: 8528.5439 - val_loss: 519927264.0000 - val_mae: 13663.7393\n",
      "Epoch 4882/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 139109456.0000 - mae: 8506.2549 - val_loss: 519781408.0000 - val_mae: 13662.7207\n",
      "Epoch 4883/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 139212112.0000 - mae: 8540.1299 - val_loss: 521649792.0000 - val_mae: 13622.8389\n",
      "Epoch 4884/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 140129584.0000 - mae: 8560.1982 - val_loss: 519871296.0000 - val_mae: 13682.6367\n",
      "Epoch 4885/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 139114336.0000 - mae: 8521.6152 - val_loss: 520454688.0000 - val_mae: 13711.7979\n",
      "Epoch 4886/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 139236000.0000 - mae: 8512.7520 - val_loss: 520690688.0000 - val_mae: 13705.5469\n",
      "Epoch 4887/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 139330128.0000 - mae: 8498.9209 - val_loss: 520335136.0000 - val_mae: 13689.6396\n",
      "Epoch 4888/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 138948416.0000 - mae: 8509.8525 - val_loss: 520257728.0000 - val_mae: 13655.8682\n",
      "Epoch 4889/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 140526080.0000 - mae: 8580.5420 - val_loss: 520872032.0000 - val_mae: 13736.3906\n",
      "Epoch 4890/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 139250192.0000 - mae: 8485.8477 - val_loss: 523015712.0000 - val_mae: 13836.1914\n",
      "Epoch 4891/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 139207056.0000 - mae: 8559.4209 - val_loss: 520414528.0000 - val_mae: 13627.4229\n",
      "Epoch 4892/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 139500096.0000 - mae: 8519.5566 - val_loss: 520324672.0000 - val_mae: 13652.0352\n",
      "Epoch 4893/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 140378000.0000 - mae: 8587.7559 - val_loss: 520555552.0000 - val_mae: 13649.8135\n",
      "Epoch 4894/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 139673248.0000 - mae: 8534.7266 - val_loss: 520556640.0000 - val_mae: 13709.8232\n",
      "Epoch 4895/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 139234880.0000 - mae: 8514.3252 - val_loss: 520588256.0000 - val_mae: 13711.3496\n",
      "Epoch 4896/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 139292048.0000 - mae: 8511.3223 - val_loss: 520816096.0000 - val_mae: 13742.4180\n",
      "Epoch 4897/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 139093440.0000 - mae: 8508.3730 - val_loss: 520572992.0000 - val_mae: 13718.1328\n",
      "Epoch 4898/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 138905152.0000 - mae: 8510.1777 - val_loss: 520542144.0000 - val_mae: 13697.2139\n",
      "Epoch 4899/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 139207920.0000 - mae: 8522.4082 - val_loss: 520491552.0000 - val_mae: 13687.6162\n",
      "Epoch 4900/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 139095824.0000 - mae: 8509.4883 - val_loss: 520887552.0000 - val_mae: 13651.5645\n",
      "Epoch 4901/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 138617904.0000 - mae: 8497.4736 - val_loss: 520759968.0000 - val_mae: 13711.5586\n",
      "Epoch 4902/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 139008544.0000 - mae: 8502.1279 - val_loss: 520727264.0000 - val_mae: 13732.1621\n",
      "Epoch 4903/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 139967568.0000 - mae: 8531.6328 - val_loss: 520373024.0000 - val_mae: 13664.2227\n",
      "Epoch 4904/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 139208384.0000 - mae: 8526.5234 - val_loss: 520663488.0000 - val_mae: 13662.8721\n",
      "Epoch 4905/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 139530624.0000 - mae: 8536.8525 - val_loss: 522045024.0000 - val_mae: 13637.6396\n",
      "Epoch 4906/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 139069312.0000 - mae: 8515.8789 - val_loss: 520507936.0000 - val_mae: 13681.3242\n",
      "Epoch 4907/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 139949136.0000 - mae: 8581.1260 - val_loss: 520292960.0000 - val_mae: 13682.4531\n",
      "Epoch 4908/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 138805600.0000 - mae: 8507.4053 - val_loss: 522178144.0000 - val_mae: 13816.0869\n",
      "Epoch 4909/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 139614208.0000 - mae: 8527.7012 - val_loss: 520938048.0000 - val_mae: 13734.8018\n",
      "Epoch 4910/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 138876912.0000 - mae: 8494.5410 - val_loss: 520686464.0000 - val_mae: 13721.8047\n",
      "Epoch 4911/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 138744272.0000 - mae: 8516.6699 - val_loss: 520928672.0000 - val_mae: 13656.4961\n",
      "Epoch 4912/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 138322704.0000 - mae: 8492.9180 - val_loss: 520977280.0000 - val_mae: 13714.5850\n",
      "Epoch 4913/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 138831264.0000 - mae: 8491.9482 - val_loss: 520623232.0000 - val_mae: 13662.0586\n",
      "Epoch 4914/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 138502160.0000 - mae: 8506.6016 - val_loss: 520886784.0000 - val_mae: 13703.0166\n",
      "Epoch 4915/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 138706880.0000 - mae: 8498.8389 - val_loss: 521099200.0000 - val_mae: 13747.4961\n",
      "Epoch 4916/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 139020416.0000 - mae: 8508.6582 - val_loss: 520641952.0000 - val_mae: 13701.6064\n",
      "Epoch 4917/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 138748640.0000 - mae: 8520.6631 - val_loss: 520714688.0000 - val_mae: 13706.2969\n",
      "Epoch 4918/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 138414080.0000 - mae: 8479.5869 - val_loss: 520573696.0000 - val_mae: 13664.6230\n",
      "Epoch 4919/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 138796400.0000 - mae: 8522.3574 - val_loss: 521225696.0000 - val_mae: 13696.8320\n",
      "Epoch 4920/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 138691824.0000 - mae: 8491.9814 - val_loss: 520921824.0000 - val_mae: 13736.5156\n",
      "Epoch 4921/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 139074352.0000 - mae: 8516.8604 - val_loss: 522708704.0000 - val_mae: 13833.0293\n",
      "Epoch 4922/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 138279616.0000 - mae: 8515.2617 - val_loss: 521040960.0000 - val_mae: 13649.1475\n",
      "Epoch 4923/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 138592976.0000 - mae: 8504.9521 - val_loss: 521241248.0000 - val_mae: 13707.9277\n",
      "Epoch 4924/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 138206416.0000 - mae: 8478.4639 - val_loss: 521181952.0000 - val_mae: 13742.0322\n",
      "Epoch 4925/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 138036208.0000 - mae: 8490.8311 - val_loss: 521013664.0000 - val_mae: 13672.6318\n",
      "Epoch 4926/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 138488272.0000 - mae: 8513.2207 - val_loss: 521477856.0000 - val_mae: 13756.6582\n",
      "Epoch 4927/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 138382416.0000 - mae: 8498.3799 - val_loss: 521002656.0000 - val_mae: 13715.6514\n",
      "Epoch 4928/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 138289360.0000 - mae: 8495.4258 - val_loss: 521356064.0000 - val_mae: 13736.1279\n",
      "Epoch 4929/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 138135136.0000 - mae: 8505.7959 - val_loss: 521747936.0000 - val_mae: 13664.3184\n",
      "Epoch 4930/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 138899040.0000 - mae: 8517.1025 - val_loss: 522233408.0000 - val_mae: 13801.5215\n",
      "Epoch 4931/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 138273936.0000 - mae: 8482.1270 - val_loss: 523079200.0000 - val_mae: 13849.9561\n",
      "Epoch 4932/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 140505024.0000 - mae: 8612.8896 - val_loss: 521129472.0000 - val_mae: 13718.1729\n",
      "Epoch 4933/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 138382128.0000 - mae: 8520.9082 - val_loss: 521368352.0000 - val_mae: 13682.7637\n",
      "Epoch 4934/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 138460768.0000 - mae: 8501.3438 - val_loss: 522091776.0000 - val_mae: 13800.6348\n",
      "Epoch 4935/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 138463968.0000 - mae: 8488.0537 - val_loss: 521251104.0000 - val_mae: 13739.7227\n",
      "Epoch 4936/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 138186240.0000 - mae: 8539.6611 - val_loss: 521757408.0000 - val_mae: 13652.3584\n",
      "Epoch 4937/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 138839872.0000 - mae: 8534.6221 - val_loss: 522122688.0000 - val_mae: 13660.2412\n",
      "Epoch 4938/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 139001520.0000 - mae: 8509.1016 - val_loss: 521283904.0000 - val_mae: 13741.3418\n",
      "Epoch 4939/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 137933600.0000 - mae: 8476.5996 - val_loss: 521589568.0000 - val_mae: 13685.7227\n",
      "Epoch 4940/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 137983680.0000 - mae: 8472.6396 - val_loss: 521355936.0000 - val_mae: 13734.2832\n",
      "Epoch 4941/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 138720576.0000 - mae: 8529.7236 - val_loss: 521199968.0000 - val_mae: 13687.7949\n",
      "Epoch 4942/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 138170576.0000 - mae: 8503.8613 - val_loss: 521073888.0000 - val_mae: 13644.1836\n",
      "Epoch 4943/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 138136960.0000 - mae: 8500.2490 - val_loss: 521966560.0000 - val_mae: 13711.8975\n",
      "Epoch 4944/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 137894032.0000 - mae: 8463.9092 - val_loss: 521983616.0000 - val_mae: 13762.6211\n",
      "Epoch 4945/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 138518720.0000 - mae: 8496.1299 - val_loss: 522116160.0000 - val_mae: 13766.8955\n",
      "Epoch 4946/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 139301360.0000 - mae: 8550.1650 - val_loss: 521348800.0000 - val_mae: 13702.2744\n",
      "Epoch 4947/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 137728912.0000 - mae: 8488.5381 - val_loss: 521932352.0000 - val_mae: 13745.4023\n",
      "Epoch 4948/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 138957696.0000 - mae: 8520.3682 - val_loss: 521379296.0000 - val_mae: 13686.1660\n",
      "Epoch 4949/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 137757680.0000 - mae: 8487.2471 - val_loss: 521733216.0000 - val_mae: 13708.1924\n",
      "Epoch 4950/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 137944624.0000 - mae: 8487.0381 - val_loss: 522617952.0000 - val_mae: 13797.4297\n",
      "Epoch 4951/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 137755040.0000 - mae: 8469.5039 - val_loss: 521458848.0000 - val_mae: 13712.1807\n",
      "Epoch 4952/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 137965024.0000 - mae: 8487.1104 - val_loss: 521406720.0000 - val_mae: 13701.4795\n",
      "Epoch 4953/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 137498192.0000 - mae: 8480.1055 - val_loss: 521730336.0000 - val_mae: 13724.2021\n",
      "Epoch 4954/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 137386224.0000 - mae: 8461.8096 - val_loss: 522019008.0000 - val_mae: 13745.3789\n",
      "Epoch 4955/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 137513696.0000 - mae: 8477.5137 - val_loss: 521723104.0000 - val_mae: 13716.0645\n",
      "Epoch 4956/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 138060896.0000 - mae: 8517.9385 - val_loss: 522702720.0000 - val_mae: 13664.8877\n",
      "Epoch 4957/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 138330448.0000 - mae: 8497.3838 - val_loss: 521425472.0000 - val_mae: 13722.4863\n",
      "Epoch 4958/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 137609312.0000 - mae: 8463.0068 - val_loss: 522450944.0000 - val_mae: 13792.5117\n",
      "Epoch 4959/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 138043792.0000 - mae: 8488.2852 - val_loss: 523158112.0000 - val_mae: 13835.1533\n",
      "Epoch 4960/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 137386400.0000 - mae: 8475.7295 - val_loss: 521712704.0000 - val_mae: 13701.9707\n",
      "Epoch 4961/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 137949776.0000 - mae: 8479.8135 - val_loss: 521605344.0000 - val_mae: 13738.3730\n",
      "Epoch 4962/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 137531200.0000 - mae: 8480.5068 - val_loss: 522170720.0000 - val_mae: 13713.8779\n",
      "Epoch 4963/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 137362640.0000 - mae: 8463.2979 - val_loss: 521575520.0000 - val_mae: 13731.5244\n",
      "Epoch 4964/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 137288016.0000 - mae: 8458.0586 - val_loss: 521531552.0000 - val_mae: 13690.3350\n",
      "Epoch 4965/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 137094512.0000 - mae: 8463.9248 - val_loss: 523018848.0000 - val_mae: 13826.2314\n",
      "Epoch 4966/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 138104192.0000 - mae: 8496.2178 - val_loss: 523414048.0000 - val_mae: 13859.4590\n",
      "Epoch 4967/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 138231008.0000 - mae: 8513.0449 - val_loss: 522259872.0000 - val_mae: 13763.6709\n",
      "Epoch 4968/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 137281248.0000 - mae: 8499.9766 - val_loss: 522336256.0000 - val_mae: 13697.3340\n",
      "Epoch 4969/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 137341312.0000 - mae: 8453.4346 - val_loss: 522271648.0000 - val_mae: 13763.5303\n",
      "Epoch 4970/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 137569680.0000 - mae: 8476.0537 - val_loss: 522610272.0000 - val_mae: 13799.2627\n",
      "Epoch 4971/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 137645808.0000 - mae: 8491.9453 - val_loss: 522292768.0000 - val_mae: 13762.5693\n",
      "Epoch 4972/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 137281552.0000 - mae: 8467.8408 - val_loss: 521831584.0000 - val_mae: 13748.8936\n",
      "Epoch 4973/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 137181216.0000 - mae: 8445.0488 - val_loss: 523918432.0000 - val_mae: 13875.8789\n",
      "Epoch 4974/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 137453728.0000 - mae: 8485.9756 - val_loss: 522425696.0000 - val_mae: 13710.9258\n",
      "Epoch 4975/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 137107920.0000 - mae: 8452.3857 - val_loss: 522847424.0000 - val_mae: 13808.0605\n",
      "Epoch 4976/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 137289072.0000 - mae: 8495.3301 - val_loss: 522457856.0000 - val_mae: 13691.5518\n",
      "Epoch 4977/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 137077248.0000 - mae: 8460.6426 - val_loss: 523069600.0000 - val_mae: 13809.1221\n",
      "Epoch 4978/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 137420592.0000 - mae: 8466.9746 - val_loss: 522155328.0000 - val_mae: 13774.1533\n",
      "Epoch 4979/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 137292080.0000 - mae: 8462.2480 - val_loss: 522843392.0000 - val_mae: 13798.8369\n",
      "Epoch 4980/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 137917136.0000 - mae: 8491.0693 - val_loss: 522255200.0000 - val_mae: 13748.0205\n",
      "Epoch 4981/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 136948128.0000 - mae: 8455.3369 - val_loss: 522589376.0000 - val_mae: 13791.2793\n",
      "Epoch 4982/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 137442240.0000 - mae: 8472.5391 - val_loss: 522311040.0000 - val_mae: 13736.2002\n",
      "Epoch 4983/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 137374912.0000 - mae: 8471.5605 - val_loss: 522548544.0000 - val_mae: 13770.3389\n",
      "Epoch 4984/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 137876016.0000 - mae: 8500.0752 - val_loss: 522869184.0000 - val_mae: 13805.1523\n",
      "Epoch 4985/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 136911664.0000 - mae: 8476.9082 - val_loss: 522941568.0000 - val_mae: 13708.6904\n",
      "Epoch 4986/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 137189776.0000 - mae: 8472.5137 - val_loss: 522578752.0000 - val_mae: 13752.6562\n",
      "Epoch 4987/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 136762528.0000 - mae: 8451.4961 - val_loss: 522366432.0000 - val_mae: 13688.8320\n",
      "Epoch 4988/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 137622144.0000 - mae: 8506.9609 - val_loss: 522994720.0000 - val_mae: 13794.3330\n",
      "Epoch 4989/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 137656560.0000 - mae: 8471.8271 - val_loss: 522426944.0000 - val_mae: 13693.4023\n",
      "Epoch 4990/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 137161616.0000 - mae: 8460.4229 - val_loss: 522132800.0000 - val_mae: 13710.4805\n",
      "Epoch 4991/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 137259264.0000 - mae: 8508.6748 - val_loss: 525086656.0000 - val_mae: 13913.7217\n",
      "Epoch 4992/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 138308368.0000 - mae: 8534.2129 - val_loss: 524385696.0000 - val_mae: 13882.0254\n",
      "Epoch 4993/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 137039760.0000 - mae: 8497.8213 - val_loss: 522547840.0000 - val_mae: 13702.0098\n",
      "Epoch 4994/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 137063568.0000 - mae: 8459.8369 - val_loss: 521892480.0000 - val_mae: 13722.6328\n",
      "Epoch 4995/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 136698848.0000 - mae: 8469.1846 - val_loss: 523330400.0000 - val_mae: 13821.8574\n",
      "Epoch 4996/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 136881728.0000 - mae: 8470.6221 - val_loss: 522381792.0000 - val_mae: 13730.3857\n",
      "Epoch 4997/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 137249536.0000 - mae: 8445.5654 - val_loss: 522567136.0000 - val_mae: 13786.2441\n",
      "Epoch 4998/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 136481344.0000 - mae: 8462.5518 - val_loss: 522365824.0000 - val_mae: 13735.5049\n",
      "Epoch 4999/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 136804688.0000 - mae: 8449.2012 - val_loss: 522709472.0000 - val_mae: 13732.4600\n",
      "Epoch 5000/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 137587152.0000 - mae: 8474.5146 - val_loss: 522232704.0000 - val_mae: 13725.8145\n",
      "Epoch 5001/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 136966048.0000 - mae: 8471.4785 - val_loss: 522899680.0000 - val_mae: 13729.3682\n",
      "Epoch 5002/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 137508416.0000 - mae: 8494.9287 - val_loss: 522234880.0000 - val_mae: 13759.9121\n",
      "Epoch 5003/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 137224944.0000 - mae: 8507.1973 - val_loss: 522168160.0000 - val_mae: 13711.5400\n",
      "Epoch 5004/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 136677136.0000 - mae: 8446.9912 - val_loss: 523216704.0000 - val_mae: 13802.4863\n",
      "Epoch 5005/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 136917856.0000 - mae: 8471.1582 - val_loss: 522606560.0000 - val_mae: 13733.0762\n",
      "Epoch 5006/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 136985216.0000 - mae: 8490.9990 - val_loss: 522739232.0000 - val_mae: 13725.7051\n",
      "Epoch 5007/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 136653552.0000 - mae: 8461.8086 - val_loss: 523002624.0000 - val_mae: 13718.7012\n",
      "Epoch 5008/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 137560256.0000 - mae: 8502.4023 - val_loss: 522646240.0000 - val_mae: 13777.5664\n",
      "Epoch 5009/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 136383440.0000 - mae: 8442.3721 - val_loss: 522718272.0000 - val_mae: 13773.4932\n",
      "Epoch 5010/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 136691472.0000 - mae: 8455.2158 - val_loss: 522280736.0000 - val_mae: 13716.6152\n",
      "Epoch 5011/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 136564912.0000 - mae: 8507.2139 - val_loss: 524705536.0000 - val_mae: 13708.1455\n",
      "Epoch 5012/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 137368448.0000 - mae: 8493.9453 - val_loss: 522714144.0000 - val_mae: 13780.6396\n",
      "Epoch 5013/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 136801408.0000 - mae: 8455.4043 - val_loss: 522673216.0000 - val_mae: 13748.1367\n",
      "Epoch 5014/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 136837856.0000 - mae: 8455.9854 - val_loss: 522682752.0000 - val_mae: 13731.7461\n",
      "Epoch 5015/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 136763136.0000 - mae: 8466.3340 - val_loss: 522918528.0000 - val_mae: 13764.7764\n",
      "Epoch 5016/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 136111520.0000 - mae: 8446.3672 - val_loss: 522768096.0000 - val_mae: 13727.5410\n",
      "Epoch 5017/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 137260032.0000 - mae: 8491.9678 - val_loss: 524179136.0000 - val_mae: 13870.1445\n",
      "Epoch 5018/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 136450624.0000 - mae: 8466.1406 - val_loss: 524549952.0000 - val_mae: 13886.8740\n",
      "Epoch 5019/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 136601696.0000 - mae: 8478.4277 - val_loss: 523105888.0000 - val_mae: 13751.9385\n",
      "Epoch 5020/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 136588672.0000 - mae: 8459.3633 - val_loss: 522434304.0000 - val_mae: 13737.2988\n",
      "Epoch 5021/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 136252032.0000 - mae: 8433.4004 - val_loss: 523096608.0000 - val_mae: 13812.2119\n",
      "Epoch 5022/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 136073840.0000 - mae: 8437.1104 - val_loss: 522564224.0000 - val_mae: 13727.9990\n",
      "Epoch 5023/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 136193104.0000 - mae: 8432.8936 - val_loss: 523048256.0000 - val_mae: 13788.6367\n",
      "Epoch 5024/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 136470352.0000 - mae: 8459.1680 - val_loss: 523034432.0000 - val_mae: 13783.8115\n",
      "Epoch 5025/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 136641440.0000 - mae: 8465.2891 - val_loss: 522349536.0000 - val_mae: 13745.4102\n",
      "Epoch 5026/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 136539568.0000 - mae: 8449.8545 - val_loss: 522573248.0000 - val_mae: 13726.6377\n",
      "Epoch 5027/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 136121376.0000 - mae: 8453.9766 - val_loss: 522987488.0000 - val_mae: 13772.4092\n",
      "Epoch 5028/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 136532480.0000 - mae: 8473.5088 - val_loss: 522916704.0000 - val_mae: 13758.2158\n",
      "Epoch 5029/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 137091824.0000 - mae: 8492.7891 - val_loss: 522965888.0000 - val_mae: 13792.5693\n",
      "Epoch 5030/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 135812256.0000 - mae: 8416.1279 - val_loss: 525455904.0000 - val_mae: 13914.9463\n",
      "Epoch 5031/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 136226784.0000 - mae: 8483.0059 - val_loss: 523627776.0000 - val_mae: 13732.7168\n",
      "Epoch 5032/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 136270464.0000 - mae: 8445.2559 - val_loss: 522621696.0000 - val_mae: 13775.6455\n",
      "Epoch 5033/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 136022144.0000 - mae: 8443.7363 - val_loss: 522476864.0000 - val_mae: 13746.4404\n",
      "Epoch 5034/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 135870560.0000 - mae: 8430.9814 - val_loss: 522900672.0000 - val_mae: 13780.3447\n",
      "Epoch 5035/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 136460752.0000 - mae: 8447.2695 - val_loss: 522454368.0000 - val_mae: 13762.1670\n",
      "Epoch 5036/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 135865760.0000 - mae: 8438.1582 - val_loss: 523199040.0000 - val_mae: 13799.1064\n",
      "Epoch 5037/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 136279072.0000 - mae: 8467.1709 - val_loss: 523243936.0000 - val_mae: 13778.0908\n",
      "Epoch 5038/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 136772736.0000 - mae: 8519.1377 - val_loss: 526693440.0000 - val_mae: 13993.5010\n",
      "Epoch 5039/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 136329024.0000 - mae: 8469.0186 - val_loss: 522661632.0000 - val_mae: 13765.8828\n",
      "Epoch 5040/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 136101920.0000 - mae: 8441.3682 - val_loss: 524042912.0000 - val_mae: 13865.5361\n",
      "Epoch 5041/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 136273680.0000 - mae: 8465.0215 - val_loss: 524619168.0000 - val_mae: 13895.2217\n",
      "Epoch 5042/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 135734272.0000 - mae: 8453.2168 - val_loss: 522873184.0000 - val_mae: 13749.2012\n",
      "Epoch 5043/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 135632240.0000 - mae: 8413.2979 - val_loss: 522907968.0000 - val_mae: 13790.1445\n",
      "Epoch 5044/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 136047120.0000 - mae: 8448.3037 - val_loss: 523326016.0000 - val_mae: 13835.1875\n",
      "Epoch 5045/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 135862112.0000 - mae: 8444.3496 - val_loss: 522482976.0000 - val_mae: 13751.8389\n",
      "Epoch 5046/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 135980112.0000 - mae: 8452.3203 - val_loss: 523991968.0000 - val_mae: 13688.9121\n",
      "Epoch 5047/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 136849072.0000 - mae: 8451.3955 - val_loss: 525451776.0000 - val_mae: 13934.8799\n",
      "Epoch 5048/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 135880080.0000 - mae: 8444.4854 - val_loss: 522487968.0000 - val_mae: 13777.9502\n",
      "Epoch 5049/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 135732720.0000 - mae: 8432.8252 - val_loss: 522855872.0000 - val_mae: 13786.8389\n",
      "Epoch 5050/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 135449632.0000 - mae: 8430.3770 - val_loss: 522906880.0000 - val_mae: 13797.1982\n",
      "Epoch 5051/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 135744112.0000 - mae: 8465.8291 - val_loss: 523680288.0000 - val_mae: 13729.4053\n",
      "Epoch 5052/6000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 137060112.0000 - mae: 8510.4756 - val_loss: 523139200.0000 - val_mae: 13737.1748\n",
      "Epoch 5053/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 136353488.0000 - mae: 8468.5713 - val_loss: 522424224.0000 - val_mae: 13749.9746\n",
      "Epoch 5054/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 135721856.0000 - mae: 8423.0439 - val_loss: 522963264.0000 - val_mae: 13808.6533\n",
      "Epoch 5055/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 135624672.0000 - mae: 8444.3975 - val_loss: 522583552.0000 - val_mae: 13787.9395\n",
      "Epoch 5056/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 135656640.0000 - mae: 8432.1299 - val_loss: 522485056.0000 - val_mae: 13791.5312\n",
      "Epoch 5057/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 135586048.0000 - mae: 8436.7158 - val_loss: 522493184.0000 - val_mae: 13778.3066\n",
      "Epoch 5058/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 135762912.0000 - mae: 8436.0361 - val_loss: 522897888.0000 - val_mae: 13790.8604\n",
      "Epoch 5059/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 135547312.0000 - mae: 8435.1523 - val_loss: 522341600.0000 - val_mae: 13763.6621\n",
      "Epoch 5060/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 135536448.0000 - mae: 8432.8906 - val_loss: 522917760.0000 - val_mae: 13810.2832\n",
      "Epoch 5061/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 136125440.0000 - mae: 8462.4326 - val_loss: 523025440.0000 - val_mae: 13823.0645\n",
      "Epoch 5062/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 135982864.0000 - mae: 8447.0371 - val_loss: 522766336.0000 - val_mae: 13816.3115\n",
      "Epoch 5063/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 135733536.0000 - mae: 8462.0449 - val_loss: 522932480.0000 - val_mae: 13785.0557\n",
      "Epoch 5064/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 135295920.0000 - mae: 8428.8018 - val_loss: 522830624.0000 - val_mae: 13808.3418\n",
      "Epoch 5065/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 135878992.0000 - mae: 8446.5293 - val_loss: 523303808.0000 - val_mae: 13755.2275\n",
      "Epoch 5066/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 135495456.0000 - mae: 8443.5049 - val_loss: 522432352.0000 - val_mae: 13785.3486\n",
      "Epoch 5067/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 135628752.0000 - mae: 8433.4443 - val_loss: 523181152.0000 - val_mae: 13815.3066\n",
      "Epoch 5068/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 135328416.0000 - mae: 8418.6729 - val_loss: 522602432.0000 - val_mae: 13755.5762\n",
      "Epoch 5069/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 134972960.0000 - mae: 8439.5820 - val_loss: 523381888.0000 - val_mae: 13850.0488\n",
      "Epoch 5070/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 134926112.0000 - mae: 8414.9014 - val_loss: 522330656.0000 - val_mae: 13753.8350\n",
      "Epoch 5071/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 135153424.0000 - mae: 8414.0322 - val_loss: 522716960.0000 - val_mae: 13791.6445\n",
      "Epoch 5072/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 135744816.0000 - mae: 8449.6982 - val_loss: 522717280.0000 - val_mae: 13818.4805\n",
      "Epoch 5073/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 135614464.0000 - mae: 8453.9502 - val_loss: 522987488.0000 - val_mae: 13761.0459\n",
      "Epoch 5074/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 135268464.0000 - mae: 8432.8721 - val_loss: 523073952.0000 - val_mae: 13779.9375\n",
      "Epoch 5075/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 134723760.0000 - mae: 8406.9102 - val_loss: 525365152.0000 - val_mae: 13954.2432\n",
      "Epoch 5076/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 135920640.0000 - mae: 8444.6689 - val_loss: 522658176.0000 - val_mae: 13804.6230\n",
      "Epoch 5077/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 135439360.0000 - mae: 8431.8457 - val_loss: 523667392.0000 - val_mae: 13872.3789\n",
      "Epoch 5078/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 135200544.0000 - mae: 8441.3936 - val_loss: 522633440.0000 - val_mae: 13786.4580\n",
      "Epoch 5079/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 135360896.0000 - mae: 8428.9629 - val_loss: 523778112.0000 - val_mae: 13745.6377\n",
      "Epoch 5080/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 135949696.0000 - mae: 8458.8975 - val_loss: 522502496.0000 - val_mae: 13778.2070\n",
      "Epoch 5081/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 135409248.0000 - mae: 8420.8945 - val_loss: 522834912.0000 - val_mae: 13778.2354\n",
      "Epoch 5082/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 135209984.0000 - mae: 8432.0986 - val_loss: 522713984.0000 - val_mae: 13805.5439\n",
      "Epoch 5083/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 135308960.0000 - mae: 8438.5049 - val_loss: 523152896.0000 - val_mae: 13829.3887\n",
      "Epoch 5084/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 134807264.0000 - mae: 8423.0459 - val_loss: 522582848.0000 - val_mae: 13769.1572\n",
      "Epoch 5085/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 134802976.0000 - mae: 8408.5986 - val_loss: 524228608.0000 - val_mae: 13897.5049\n",
      "Epoch 5086/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 134717680.0000 - mae: 8434.5762 - val_loss: 522616864.0000 - val_mae: 13789.8926\n",
      "Epoch 5087/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 134846832.0000 - mae: 8411.5771 - val_loss: 523220768.0000 - val_mae: 13837.9131\n",
      "Epoch 5088/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 134963952.0000 - mae: 8414.7539 - val_loss: 522615648.0000 - val_mae: 13792.2129\n",
      "Epoch 5089/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 135969312.0000 - mae: 8422.6592 - val_loss: 522331168.0000 - val_mae: 13791.9678\n",
      "Epoch 5090/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 134949008.0000 - mae: 8455.7266 - val_loss: 523268160.0000 - val_mae: 13763.1504\n",
      "Epoch 5091/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 134971280.0000 - mae: 8419.2109 - val_loss: 522645824.0000 - val_mae: 13796.4082\n",
      "Epoch 5092/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 134756320.0000 - mae: 8402.3340 - val_loss: 523272128.0000 - val_mae: 13851.9375\n",
      "Epoch 5093/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 134860848.0000 - mae: 8417.9893 - val_loss: 522631200.0000 - val_mae: 13786.9053\n",
      "Epoch 5094/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 135032208.0000 - mae: 8431.2920 - val_loss: 523685248.0000 - val_mae: 13762.5703\n",
      "Epoch 5095/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 135433040.0000 - mae: 8433.3262 - val_loss: 523079520.0000 - val_mae: 13762.7480\n",
      "Epoch 5096/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 134844432.0000 - mae: 8419.6035 - val_loss: 523443008.0000 - val_mae: 13867.2324\n",
      "Epoch 5097/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 134809728.0000 - mae: 8416.6270 - val_loss: 523286784.0000 - val_mae: 13838.0264\n",
      "Epoch 5098/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 134387008.0000 - mae: 8390.6309 - val_loss: 522661536.0000 - val_mae: 13766.4053\n",
      "Epoch 5099/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 135181264.0000 - mae: 8411.5283 - val_loss: 523613472.0000 - val_mae: 13762.4385\n",
      "Epoch 5100/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 135494240.0000 - mae: 8443.3066 - val_loss: 522937024.0000 - val_mae: 13779.3936\n",
      "Epoch 5101/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 134506576.0000 - mae: 8404.7969 - val_loss: 523540000.0000 - val_mae: 13870.2227\n",
      "Epoch 5102/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 134542976.0000 - mae: 8417.4609 - val_loss: 522876512.0000 - val_mae: 13787.4541\n",
      "Epoch 5103/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 135198464.0000 - mae: 8430.6318 - val_loss: 522903808.0000 - val_mae: 13808.2510\n",
      "Epoch 5104/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 134791312.0000 - mae: 8421.0332 - val_loss: 522777216.0000 - val_mae: 13783.9736\n",
      "Epoch 5105/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 134556400.0000 - mae: 8418.5361 - val_loss: 523020800.0000 - val_mae: 13843.1484\n",
      "Epoch 5106/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 134618256.0000 - mae: 8404.3809 - val_loss: 524401920.0000 - val_mae: 13921.4551\n",
      "Epoch 5107/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 134794672.0000 - mae: 8432.6133 - val_loss: 523063360.0000 - val_mae: 13820.0713\n",
      "Epoch 5108/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 134547808.0000 - mae: 8428.8193 - val_loss: 524052512.0000 - val_mae: 13753.4941\n",
      "Epoch 5109/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 135179808.0000 - mae: 8466.1748 - val_loss: 522700608.0000 - val_mae: 13800.1357\n",
      "Epoch 5110/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 135522432.0000 - mae: 8465.2061 - val_loss: 523338720.0000 - val_mae: 13847.1064\n",
      "Epoch 5111/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 134105432.0000 - mae: 8423.6650 - val_loss: 523736416.0000 - val_mae: 13773.0391\n",
      "Epoch 5112/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 134339920.0000 - mae: 8391.5791 - val_loss: 522688928.0000 - val_mae: 13832.1201\n",
      "Epoch 5113/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 134693296.0000 - mae: 8418.9053 - val_loss: 523254880.0000 - val_mae: 13817.2090\n",
      "Epoch 5114/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 134170824.0000 - mae: 8398.2539 - val_loss: 523074368.0000 - val_mae: 13829.9189\n",
      "Epoch 5115/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 134313328.0000 - mae: 8398.9443 - val_loss: 522873120.0000 - val_mae: 13781.8887\n",
      "Epoch 5116/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 134750016.0000 - mae: 8414.0918 - val_loss: 523059136.0000 - val_mae: 13806.3691\n",
      "Epoch 5117/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 134774320.0000 - mae: 8415.8623 - val_loss: 523060832.0000 - val_mae: 13792.3516\n",
      "Epoch 5118/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 134472384.0000 - mae: 8413.9346 - val_loss: 523019008.0000 - val_mae: 13789.5439\n",
      "Epoch 5119/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 134563344.0000 - mae: 8412.9600 - val_loss: 522764512.0000 - val_mae: 13785.2676\n",
      "Epoch 5120/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 134906160.0000 - mae: 8427.4961 - val_loss: 524173536.0000 - val_mae: 13743.7217\n",
      "Epoch 5121/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 135490400.0000 - mae: 8449.6973 - val_loss: 523051648.0000 - val_mae: 13802.6396\n",
      "Epoch 5122/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 134292048.0000 - mae: 8420.4707 - val_loss: 522769568.0000 - val_mae: 13804.9551\n",
      "Epoch 5123/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 134593328.0000 - mae: 8419.0234 - val_loss: 523315168.0000 - val_mae: 13777.3496\n",
      "Epoch 5124/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 134515648.0000 - mae: 8407.1533 - val_loss: 523113088.0000 - val_mae: 13826.0742\n",
      "Epoch 5125/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 134151816.0000 - mae: 8405.9268 - val_loss: 523842688.0000 - val_mae: 13770.8301\n",
      "Epoch 5126/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 134503616.0000 - mae: 8404.6855 - val_loss: 523672832.0000 - val_mae: 13893.4180\n",
      "Epoch 5127/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 133608920.0000 - mae: 8376.7988 - val_loss: 523122368.0000 - val_mae: 13819.1377\n",
      "Epoch 5128/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 134351344.0000 - mae: 8400.5312 - val_loss: 523321856.0000 - val_mae: 13776.8994\n",
      "Epoch 5129/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 134316432.0000 - mae: 8402.4209 - val_loss: 522964736.0000 - val_mae: 13789.7725\n",
      "Epoch 5130/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 134011096.0000 - mae: 8398.6348 - val_loss: 523151328.0000 - val_mae: 13812.5361\n",
      "Epoch 5131/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 134119288.0000 - mae: 8401.0215 - val_loss: 523024128.0000 - val_mae: 13817.1182\n",
      "Epoch 5132/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 133787576.0000 - mae: 8378.2158 - val_loss: 524575136.0000 - val_mae: 13934.3623\n",
      "Epoch 5133/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 134309744.0000 - mae: 8429.0430 - val_loss: 523248160.0000 - val_mae: 13847.3955\n",
      "Epoch 5134/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 133962464.0000 - mae: 8386.4707 - val_loss: 523805056.0000 - val_mae: 13876.8184\n",
      "Epoch 5135/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 133667992.0000 - mae: 8378.5986 - val_loss: 523253856.0000 - val_mae: 13814.7871\n",
      "Epoch 5136/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 133930664.0000 - mae: 8400.4980 - val_loss: 522879616.0000 - val_mae: 13805.9707\n",
      "Epoch 5137/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 134046488.0000 - mae: 8390.1582 - val_loss: 523098528.0000 - val_mae: 13835.9326\n",
      "Epoch 5138/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 133798048.0000 - mae: 8388.9600 - val_loss: 523252224.0000 - val_mae: 13821.1826\n",
      "Epoch 5139/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 133971736.0000 - mae: 8379.7744 - val_loss: 523297344.0000 - val_mae: 13794.5898\n",
      "Epoch 5140/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 133991616.0000 - mae: 8420.3721 - val_loss: 522623264.0000 - val_mae: 13839.5234\n",
      "Epoch 5141/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 133553624.0000 - mae: 8389.6992 - val_loss: 523158016.0000 - val_mae: 13803.3623\n",
      "Epoch 5142/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 133946736.0000 - mae: 8385.7959 - val_loss: 524019040.0000 - val_mae: 13905.7568\n",
      "Epoch 5143/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 134078880.0000 - mae: 8398.2939 - val_loss: 523682624.0000 - val_mae: 13890.6748\n",
      "Epoch 5144/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 133627024.0000 - mae: 8382.4199 - val_loss: 522844352.0000 - val_mae: 13825.4502\n",
      "Epoch 5145/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 134397472.0000 - mae: 8434.1523 - val_loss: 523114144.0000 - val_mae: 13767.6318\n",
      "Epoch 5146/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 134131712.0000 - mae: 8400.8398 - val_loss: 522682048.0000 - val_mae: 13804.2461\n",
      "Epoch 5147/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 133390584.0000 - mae: 8369.3281 - val_loss: 522869248.0000 - val_mae: 13854.2285\n",
      "Epoch 5148/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 133608576.0000 - mae: 8382.1318 - val_loss: 522589024.0000 - val_mae: 13820.4482\n",
      "Epoch 5149/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 133550112.0000 - mae: 8390.4082 - val_loss: 523105248.0000 - val_mae: 13853.0166\n",
      "Epoch 5150/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 133467464.0000 - mae: 8369.6123 - val_loss: 523729504.0000 - val_mae: 13889.6729\n",
      "Epoch 5151/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 133625584.0000 - mae: 8400.9961 - val_loss: 523540352.0000 - val_mae: 13805.0107\n",
      "Epoch 5152/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 133821504.0000 - mae: 8408.4961 - val_loss: 523629152.0000 - val_mae: 13788.1982\n",
      "Epoch 5153/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 134836576.0000 - mae: 8430.8252 - val_loss: 522856032.0000 - val_mae: 13776.3594\n",
      "Epoch 5154/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 133654920.0000 - mae: 8389.8643 - val_loss: 522867008.0000 - val_mae: 13827.9004\n",
      "Epoch 5155/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 133807440.0000 - mae: 8390.4482 - val_loss: 523897312.0000 - val_mae: 13912.5615\n",
      "Epoch 5156/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 133598936.0000 - mae: 8390.3633 - val_loss: 522699040.0000 - val_mae: 13835.2773\n",
      "Epoch 5157/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 133426008.0000 - mae: 8366.7129 - val_loss: 524251648.0000 - val_mae: 13924.8682\n",
      "Epoch 5158/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 133315656.0000 - mae: 8392.4805 - val_loss: 522851616.0000 - val_mae: 13801.8584\n",
      "Epoch 5159/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 133292680.0000 - mae: 8378.2607 - val_loss: 523062240.0000 - val_mae: 13814.4531\n",
      "Epoch 5160/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 133183536.0000 - mae: 8374.7012 - val_loss: 524390912.0000 - val_mae: 13940.1074\n",
      "Epoch 5161/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 134019656.0000 - mae: 8391.1660 - val_loss: 523794464.0000 - val_mae: 13904.8818\n",
      "Epoch 5162/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 133857280.0000 - mae: 8394.8213 - val_loss: 524441056.0000 - val_mae: 13954.8223\n",
      "Epoch 5163/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 133964568.0000 - mae: 8410.3643 - val_loss: 523194528.0000 - val_mae: 13861.7695\n",
      "Epoch 5164/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 133343016.0000 - mae: 8359.4004 - val_loss: 522685152.0000 - val_mae: 13850.8545\n",
      "Epoch 5165/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 133535064.0000 - mae: 8372.8857 - val_loss: 524261088.0000 - val_mae: 13933.6484\n",
      "Epoch 5166/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 133867328.0000 - mae: 8395.0791 - val_loss: 523700672.0000 - val_mae: 13885.1934\n",
      "Epoch 5167/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 133941160.0000 - mae: 8418.1230 - val_loss: 523321536.0000 - val_mae: 13876.7988\n",
      "Epoch 5168/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 133992216.0000 - mae: 8411.8164 - val_loss: 523939008.0000 - val_mae: 13931.9785\n",
      "Epoch 5169/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 133430088.0000 - mae: 8381.9131 - val_loss: 523648384.0000 - val_mae: 13898.2764\n",
      "Epoch 5170/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 133432480.0000 - mae: 8391.9355 - val_loss: 523126912.0000 - val_mae: 13866.1826\n",
      "Epoch 5171/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 133166496.0000 - mae: 8376.8301 - val_loss: 522965344.0000 - val_mae: 13834.1602\n",
      "Epoch 5172/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 133442664.0000 - mae: 8378.9668 - val_loss: 523349472.0000 - val_mae: 13908.4297\n",
      "Epoch 5173/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 132849544.0000 - mae: 8376.1201 - val_loss: 522772512.0000 - val_mae: 13815.0293\n",
      "Epoch 5174/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 133148520.0000 - mae: 8371.1406 - val_loss: 523149056.0000 - val_mae: 13815.1406\n",
      "Epoch 5175/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 133187616.0000 - mae: 8372.3184 - val_loss: 523356608.0000 - val_mae: 13805.6426\n",
      "Epoch 5176/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 132715520.0000 - mae: 8362.1875 - val_loss: 523998528.0000 - val_mae: 13915.3945\n",
      "Epoch 5177/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 134264592.0000 - mae: 8417.5400 - val_loss: 523599840.0000 - val_mae: 13916.1162\n",
      "Epoch 5178/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 133223888.0000 - mae: 8402.3701 - val_loss: 522813472.0000 - val_mae: 13855.5811\n",
      "Epoch 5179/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 133054752.0000 - mae: 8382.3330 - val_loss: 525411552.0000 - val_mae: 13989.2695\n",
      "Epoch 5180/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 132845496.0000 - mae: 8375.4668 - val_loss: 523327840.0000 - val_mae: 13810.6602\n",
      "Epoch 5181/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 133115160.0000 - mae: 8378.6250 - val_loss: 522828288.0000 - val_mae: 13849.9600\n",
      "Epoch 5182/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 133226152.0000 - mae: 8387.4336 - val_loss: 523391328.0000 - val_mae: 13861.2881\n",
      "Epoch 5183/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 132910104.0000 - mae: 8357.4443 - val_loss: 523082880.0000 - val_mae: 13880.2012\n",
      "Epoch 5184/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 132811920.0000 - mae: 8370.7158 - val_loss: 522877824.0000 - val_mae: 13852.2920\n",
      "Epoch 5185/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 132918400.0000 - mae: 8393.1748 - val_loss: 523496256.0000 - val_mae: 13792.8496\n",
      "Epoch 5186/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 133244040.0000 - mae: 8381.3574 - val_loss: 522626464.0000 - val_mae: 13820.7676\n",
      "Epoch 5187/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 133057288.0000 - mae: 8357.5996 - val_loss: 522907584.0000 - val_mae: 13829.5713\n",
      "Epoch 5188/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 133109536.0000 - mae: 8391.0996 - val_loss: 522630784.0000 - val_mae: 13829.5439\n",
      "Epoch 5189/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 132858968.0000 - mae: 8366.5039 - val_loss: 523158688.0000 - val_mae: 13819.7510\n",
      "Epoch 5190/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 133031216.0000 - mae: 8372.5098 - val_loss: 523382720.0000 - val_mae: 13850.2588\n",
      "Epoch 5191/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 132718832.0000 - mae: 8349.3408 - val_loss: 522631264.0000 - val_mae: 13849.9512\n",
      "Epoch 5192/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 132711296.0000 - mae: 8363.7168 - val_loss: 523076896.0000 - val_mae: 13835.6074\n",
      "Epoch 5193/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 133910152.0000 - mae: 8423.8525 - val_loss: 524236576.0000 - val_mae: 13779.8428\n",
      "Epoch 5194/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 132757184.0000 - mae: 8379.5869 - val_loss: 523356992.0000 - val_mae: 13886.5400\n",
      "Epoch 5195/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 132714920.0000 - mae: 8354.7383 - val_loss: 523039008.0000 - val_mae: 13884.9736\n",
      "Epoch 5196/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 132636080.0000 - mae: 8365.4258 - val_loss: 523125376.0000 - val_mae: 13846.8291\n",
      "Epoch 5197/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 132743280.0000 - mae: 8376.8047 - val_loss: 523012352.0000 - val_mae: 13825.0312\n",
      "Epoch 5198/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 132914360.0000 - mae: 8375.2305 - val_loss: 523039328.0000 - val_mae: 13895.0068\n",
      "Epoch 5199/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 132631448.0000 - mae: 8359.1953 - val_loss: 522877472.0000 - val_mae: 13872.7637\n",
      "Epoch 5200/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 132782016.0000 - mae: 8375.7539 - val_loss: 523135808.0000 - val_mae: 13887.5146\n",
      "Epoch 5201/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 132107080.0000 - mae: 8351.6162 - val_loss: 522643008.0000 - val_mae: 13814.3271\n",
      "Epoch 5202/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 133079032.0000 - mae: 8374.6523 - val_loss: 523608992.0000 - val_mae: 13896.0723\n",
      "Epoch 5203/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 132571440.0000 - mae: 8355.8984 - val_loss: 524268512.0000 - val_mae: 13957.8389\n",
      "Epoch 5204/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 132571704.0000 - mae: 8364.7471 - val_loss: 522564096.0000 - val_mae: 13840.3770\n",
      "Epoch 5205/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 132830272.0000 - mae: 8369.8564 - val_loss: 523326080.0000 - val_mae: 13842.0869\n",
      "Epoch 5206/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 132495656.0000 - mae: 8372.2939 - val_loss: 523070944.0000 - val_mae: 13856.3594\n",
      "Epoch 5207/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 132334896.0000 - mae: 8349.9453 - val_loss: 522631424.0000 - val_mae: 13817.6963\n",
      "Epoch 5208/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 132341560.0000 - mae: 8358.9180 - val_loss: 523572256.0000 - val_mae: 13911.3672\n",
      "Epoch 5209/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 132318368.0000 - mae: 8367.9893 - val_loss: 523752096.0000 - val_mae: 13806.4355\n",
      "Epoch 5210/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 132911368.0000 - mae: 8387.2686 - val_loss: 523162848.0000 - val_mae: 13837.1533\n",
      "Epoch 5211/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 132065048.0000 - mae: 8357.5449 - val_loss: 523557568.0000 - val_mae: 13905.7812\n",
      "Epoch 5212/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 132127728.0000 - mae: 8341.0947 - val_loss: 523117888.0000 - val_mae: 13836.2939\n",
      "Epoch 5213/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 132781176.0000 - mae: 8403.4150 - val_loss: 524535392.0000 - val_mae: 13784.9287\n",
      "Epoch 5214/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 132719136.0000 - mae: 8365.2178 - val_loss: 523169472.0000 - val_mae: 13875.7930\n",
      "Epoch 5215/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 132163368.0000 - mae: 8346.5605 - val_loss: 523518496.0000 - val_mae: 13905.1680\n",
      "Epoch 5216/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 132356312.0000 - mae: 8369.6328 - val_loss: 523674304.0000 - val_mae: 13838.2832\n",
      "Epoch 5217/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 132377640.0000 - mae: 8348.2305 - val_loss: 523631200.0000 - val_mae: 13928.5615\n",
      "Epoch 5218/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 131680952.0000 - mae: 8367.0850 - val_loss: 525867520.0000 - val_mae: 13801.1270\n",
      "Epoch 5219/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 132594808.0000 - mae: 8409.9150 - val_loss: 525070624.0000 - val_mae: 13992.3516\n",
      "Epoch 5220/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 132200040.0000 - mae: 8346.8604 - val_loss: 523535648.0000 - val_mae: 13828.8486\n",
      "Epoch 5221/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 132349336.0000 - mae: 8370.0117 - val_loss: 523916128.0000 - val_mae: 13930.3584\n",
      "Epoch 5222/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 131951160.0000 - mae: 8332.6699 - val_loss: 523395200.0000 - val_mae: 13885.1230\n",
      "Epoch 5223/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 131755776.0000 - mae: 8342.8867 - val_loss: 522920512.0000 - val_mae: 13832.5654\n",
      "Epoch 5224/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 133395416.0000 - mae: 8425.3730 - val_loss: 523143104.0000 - val_mae: 13874.7109\n",
      "Epoch 5225/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 132353304.0000 - mae: 8347.0166 - val_loss: 523957344.0000 - val_mae: 13894.1719\n",
      "Epoch 5226/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 132145040.0000 - mae: 8342.4258 - val_loss: 523013568.0000 - val_mae: 13820.7617\n",
      "Epoch 5227/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 131956744.0000 - mae: 8351.8428 - val_loss: 522862112.0000 - val_mae: 13855.1729\n",
      "Epoch 5228/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 132022256.0000 - mae: 8341.4443 - val_loss: 524084064.0000 - val_mae: 13949.7441\n",
      "Epoch 5229/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 132548128.0000 - mae: 8375.7764 - val_loss: 523175680.0000 - val_mae: 13878.1074\n",
      "Epoch 5230/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 131720608.0000 - mae: 8359.7490 - val_loss: 522920128.0000 - val_mae: 13842.4482\n",
      "Epoch 5231/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 131921056.0000 - mae: 8345.7314 - val_loss: 523265696.0000 - val_mae: 13841.0010\n",
      "Epoch 5232/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 131659136.0000 - mae: 8331.3271 - val_loss: 523925056.0000 - val_mae: 13937.9492\n",
      "Epoch 5233/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 132906256.0000 - mae: 8357.1182 - val_loss: 523279008.0000 - val_mae: 13877.7363\n",
      "Epoch 5234/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 131910408.0000 - mae: 8360.6416 - val_loss: 524102944.0000 - val_mae: 13822.8525\n",
      "Epoch 5235/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 132187032.0000 - mae: 8337.6553 - val_loss: 523266080.0000 - val_mae: 13872.5098\n",
      "Epoch 5236/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 131573040.0000 - mae: 8325.3086 - val_loss: 522976416.0000 - val_mae: 13866.7119\n",
      "Epoch 5237/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 131599184.0000 - mae: 8350.3906 - val_loss: 522950592.0000 - val_mae: 13826.1328\n",
      "Epoch 5238/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 131771024.0000 - mae: 8348.8545 - val_loss: 523484960.0000 - val_mae: 13908.1807\n",
      "Epoch 5239/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 131815360.0000 - mae: 8343.6250 - val_loss: 524026016.0000 - val_mae: 13929.7666\n",
      "Epoch 5240/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 131816904.0000 - mae: 8360.6680 - val_loss: 523448576.0000 - val_mae: 13857.2412\n",
      "Epoch 5241/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 131852096.0000 - mae: 8337.3252 - val_loss: 523349600.0000 - val_mae: 13874.9355\n",
      "Epoch 5242/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 132515656.0000 - mae: 8405.0996 - val_loss: 527506240.0000 - val_mae: 13806.1455\n",
      "Epoch 5243/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 133749128.0000 - mae: 8422.9336 - val_loss: 523438336.0000 - val_mae: 13839.5596\n",
      "Epoch 5244/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 132632880.0000 - mae: 8371.6426 - val_loss: 523378112.0000 - val_mae: 13893.0918\n",
      "Epoch 5245/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 131999432.0000 - mae: 8352.3770 - val_loss: 524041856.0000 - val_mae: 13913.5195\n",
      "Epoch 5246/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 131453128.0000 - mae: 8335.0361 - val_loss: 523526624.0000 - val_mae: 13905.8848\n",
      "Epoch 5247/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 131730488.0000 - mae: 8333.2256 - val_loss: 522926368.0000 - val_mae: 13870.2080\n",
      "Epoch 5248/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 131670960.0000 - mae: 8331.0625 - val_loss: 523143296.0000 - val_mae: 13839.7783\n",
      "Epoch 5249/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 132221832.0000 - mae: 8350.4961 - val_loss: 523354496.0000 - val_mae: 13897.4531\n",
      "Epoch 5250/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 131502368.0000 - mae: 8332.0088 - val_loss: 523769184.0000 - val_mae: 13875.2363\n",
      "Epoch 5251/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 131758720.0000 - mae: 8348.5840 - val_loss: 523443584.0000 - val_mae: 13905.4434\n",
      "Epoch 5252/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 131581560.0000 - mae: 8342.4160 - val_loss: 524165248.0000 - val_mae: 13951.0645\n",
      "Epoch 5253/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 132272984.0000 - mae: 8359.0098 - val_loss: 523978208.0000 - val_mae: 13930.9434\n",
      "Epoch 5254/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 131917304.0000 - mae: 8346.6221 - val_loss: 525162112.0000 - val_mae: 13989.4482\n",
      "Epoch 5255/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 131313512.0000 - mae: 8333.6084 - val_loss: 523571616.0000 - val_mae: 13841.9756\n",
      "Epoch 5256/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 132159056.0000 - mae: 8352.4551 - val_loss: 523235296.0000 - val_mae: 13891.9336\n",
      "Epoch 5257/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 131415976.0000 - mae: 8321.8887 - val_loss: 523697536.0000 - val_mae: 13933.5205\n",
      "Epoch 5258/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 131813576.0000 - mae: 8411.2314 - val_loss: 523938784.0000 - val_mae: 13808.9590\n",
      "Epoch 5259/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 131823480.0000 - mae: 8342.2910 - val_loss: 524131072.0000 - val_mae: 13956.3066\n",
      "Epoch 5260/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 131657328.0000 - mae: 8345.5859 - val_loss: 524059648.0000 - val_mae: 13913.1172\n",
      "Epoch 5261/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 131320072.0000 - mae: 8332.9453 - val_loss: 523898752.0000 - val_mae: 13914.7510\n",
      "Epoch 5262/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 131535168.0000 - mae: 8341.0342 - val_loss: 523312448.0000 - val_mae: 13838.8418\n",
      "Epoch 5263/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 131401928.0000 - mae: 8330.3623 - val_loss: 523283328.0000 - val_mae: 13876.1416\n",
      "Epoch 5264/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 131054704.0000 - mae: 8310.5977 - val_loss: 523445088.0000 - val_mae: 13901.2305\n",
      "Epoch 5265/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 131420376.0000 - mae: 8326.4756 - val_loss: 522834816.0000 - val_mae: 13866.0215\n",
      "Epoch 5266/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 131290688.0000 - mae: 8350.8867 - val_loss: 523271520.0000 - val_mae: 13881.1123\n",
      "Epoch 5267/6000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 131452064.0000 - mae: 8325.6621 - val_loss: 523565056.0000 - val_mae: 13924.5898\n",
      "Epoch 5268/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 131028072.0000 - mae: 8318.9199 - val_loss: 523607424.0000 - val_mae: 13864.6465\n",
      "Epoch 5269/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 131428488.0000 - mae: 8374.3672 - val_loss: 523552704.0000 - val_mae: 13903.2275\n",
      "Epoch 5270/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 131561312.0000 - mae: 8328.8535 - val_loss: 524802848.0000 - val_mae: 13978.1650\n",
      "Epoch 5271/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 131668968.0000 - mae: 8342.4238 - val_loss: 523398080.0000 - val_mae: 13906.3857\n",
      "Epoch 5272/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 131779360.0000 - mae: 8353.3857 - val_loss: 523344128.0000 - val_mae: 13868.8438\n",
      "Epoch 5273/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 131477496.0000 - mae: 8353.0195 - val_loss: 523461216.0000 - val_mae: 13857.5947\n",
      "Epoch 5274/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 131147728.0000 - mae: 8336.2705 - val_loss: 523275552.0000 - val_mae: 13869.8896\n",
      "Epoch 5275/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 131033816.0000 - mae: 8312.0664 - val_loss: 524347392.0000 - val_mae: 13949.4551\n",
      "Epoch 5276/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 130800328.0000 - mae: 8321.9355 - val_loss: 523190272.0000 - val_mae: 13817.9531\n",
      "Epoch 5277/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 131343544.0000 - mae: 8333.9277 - val_loss: 523156672.0000 - val_mae: 13872.6348\n",
      "Epoch 5278/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 131224552.0000 - mae: 8344.5127 - val_loss: 525378784.0000 - val_mae: 14014.2812\n",
      "Epoch 5279/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 130875400.0000 - mae: 8333.0029 - val_loss: 523298528.0000 - val_mae: 13855.1201\n",
      "Epoch 5280/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 131061456.0000 - mae: 8320.6641 - val_loss: 523458368.0000 - val_mae: 13879.1377\n",
      "Epoch 5281/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 130709912.0000 - mae: 8319.2773 - val_loss: 523031872.0000 - val_mae: 13860.8232\n",
      "Epoch 5282/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 131048840.0000 - mae: 8319.3311 - val_loss: 523966336.0000 - val_mae: 13955.4160\n",
      "Epoch 5283/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 131084800.0000 - mae: 8317.9854 - val_loss: 524031872.0000 - val_mae: 13942.4629\n",
      "Epoch 5284/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 131151768.0000 - mae: 8347.3623 - val_loss: 523970720.0000 - val_mae: 13954.8467\n",
      "Epoch 5285/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 130763144.0000 - mae: 8323.0723 - val_loss: 522971136.0000 - val_mae: 13844.8584\n",
      "Epoch 5286/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 130735264.0000 - mae: 8314.0498 - val_loss: 522928448.0000 - val_mae: 13876.3994\n",
      "Epoch 5287/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 130623176.0000 - mae: 8305.8701 - val_loss: 523952544.0000 - val_mae: 13931.8535\n",
      "Epoch 5288/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 130723384.0000 - mae: 8310.8682 - val_loss: 523720800.0000 - val_mae: 13921.6348\n",
      "Epoch 5289/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 130810800.0000 - mae: 8315.1621 - val_loss: 523356256.0000 - val_mae: 13875.5117\n",
      "Epoch 5290/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 130658144.0000 - mae: 8315.2637 - val_loss: 524103648.0000 - val_mae: 13956.8926\n",
      "Epoch 5291/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 130661624.0000 - mae: 8310.6602 - val_loss: 524599136.0000 - val_mae: 13971.8281\n",
      "Epoch 5292/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 131287192.0000 - mae: 8358.0039 - val_loss: 522768896.0000 - val_mae: 13861.0547\n",
      "Epoch 5293/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 130591912.0000 - mae: 8312.9668 - val_loss: 523656128.0000 - val_mae: 13930.5928\n",
      "Epoch 5294/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 130467696.0000 - mae: 8310.1396 - val_loss: 523077600.0000 - val_mae: 13869.6416\n",
      "Epoch 5295/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 130552672.0000 - mae: 8307.9482 - val_loss: 522859488.0000 - val_mae: 13871.2188\n",
      "Epoch 5296/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 130534968.0000 - mae: 8305.9453 - val_loss: 523362688.0000 - val_mae: 13887.1982\n",
      "Epoch 5297/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 130472632.0000 - mae: 8304.0508 - val_loss: 524670816.0000 - val_mae: 13981.2812\n",
      "Epoch 5298/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 130931128.0000 - mae: 8331.9639 - val_loss: 523537792.0000 - val_mae: 13900.2119\n",
      "Epoch 5299/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 130460008.0000 - mae: 8298.7656 - val_loss: 523459680.0000 - val_mae: 13857.3789\n",
      "Epoch 5300/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 130444056.0000 - mae: 8303.3418 - val_loss: 523840288.0000 - val_mae: 13947.4932\n",
      "Epoch 5301/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 130956832.0000 - mae: 8350.4668 - val_loss: 525195392.0000 - val_mae: 14008.5293\n",
      "Epoch 5302/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 130449112.0000 - mae: 8307.0146 - val_loss: 524348576.0000 - val_mae: 13961.6777\n",
      "Epoch 5303/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 131734880.0000 - mae: 8356.2080 - val_loss: 522972320.0000 - val_mae: 13882.4229\n",
      "Epoch 5304/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 131168168.0000 - mae: 8340.6611 - val_loss: 523230144.0000 - val_mae: 13870.2393\n",
      "Epoch 5305/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 130278816.0000 - mae: 8292.6826 - val_loss: 523376896.0000 - val_mae: 13887.1748\n",
      "Epoch 5306/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 130406352.0000 - mae: 8304.8164 - val_loss: 523167616.0000 - val_mae: 13882.3545\n",
      "Epoch 5307/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 130312592.0000 - mae: 8294.6084 - val_loss: 524488608.0000 - val_mae: 13988.4551\n",
      "Epoch 5308/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 130330736.0000 - mae: 8316.1328 - val_loss: 523429920.0000 - val_mae: 13880.7939\n",
      "Epoch 5309/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 131057120.0000 - mae: 8332.5723 - val_loss: 523354912.0000 - val_mae: 13863.9287\n",
      "Epoch 5310/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 130458856.0000 - mae: 8316.2061 - val_loss: 523495456.0000 - val_mae: 13906.4287\n",
      "Epoch 5311/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 130870344.0000 - mae: 8328.6611 - val_loss: 523647552.0000 - val_mae: 13859.6426\n",
      "Epoch 5312/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 130520416.0000 - mae: 8307.2236 - val_loss: 522948864.0000 - val_mae: 13869.1426\n",
      "Epoch 5313/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 130638824.0000 - mae: 8347.8457 - val_loss: 524914016.0000 - val_mae: 14004.9004\n",
      "Epoch 5314/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 130772544.0000 - mae: 8328.5723 - val_loss: 523009760.0000 - val_mae: 13871.3389\n",
      "Epoch 5315/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 130607784.0000 - mae: 8305.9355 - val_loss: 523607776.0000 - val_mae: 13859.9531\n",
      "Epoch 5316/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 130785328.0000 - mae: 8333.0762 - val_loss: 523219936.0000 - val_mae: 13912.0547\n",
      "Epoch 5317/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 130039696.0000 - mae: 8294.6699 - val_loss: 523415200.0000 - val_mae: 13904.5625\n",
      "Epoch 5318/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 129960328.0000 - mae: 8298.8770 - val_loss: 523074720.0000 - val_mae: 13861.0967\n",
      "Epoch 5319/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 130549288.0000 - mae: 8324.5674 - val_loss: 524020128.0000 - val_mae: 13846.5967\n",
      "Epoch 5320/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 130911000.0000 - mae: 8333.1836 - val_loss: 523145440.0000 - val_mae: 13836.6104\n",
      "Epoch 5321/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 130212488.0000 - mae: 8316.2012 - val_loss: 523312928.0000 - val_mae: 13886.2676\n",
      "Epoch 5322/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 130348384.0000 - mae: 8326.4189 - val_loss: 523599488.0000 - val_mae: 13851.2168\n",
      "Epoch 5323/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 129892312.0000 - mae: 8282.4268 - val_loss: 524231040.0000 - val_mae: 13955.9990\n",
      "Epoch 5324/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 130273768.0000 - mae: 8294.2393 - val_loss: 523075968.0000 - val_mae: 13875.1807\n",
      "Epoch 5325/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 130063976.0000 - mae: 8296.2441 - val_loss: 523390528.0000 - val_mae: 13875.3086\n",
      "Epoch 5326/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 129880728.0000 - mae: 8298.0498 - val_loss: 523683424.0000 - val_mae: 13886.3857\n",
      "Epoch 5327/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 129971408.0000 - mae: 8297.5996 - val_loss: 523506912.0000 - val_mae: 13891.0771\n",
      "Epoch 5328/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 130001896.0000 - mae: 8285.7393 - val_loss: 523906208.0000 - val_mae: 13943.5361\n",
      "Epoch 5329/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 129858672.0000 - mae: 8291.0898 - val_loss: 524388832.0000 - val_mae: 13976.1650\n",
      "Epoch 5330/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 130406832.0000 - mae: 8326.1348 - val_loss: 523166592.0000 - val_mae: 13872.1523\n",
      "Epoch 5331/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 129796888.0000 - mae: 8283.1094 - val_loss: 524076352.0000 - val_mae: 13969.2012\n",
      "Epoch 5332/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 130084144.0000 - mae: 8296.7871 - val_loss: 523463968.0000 - val_mae: 13918.6523\n",
      "Epoch 5333/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 130094576.0000 - mae: 8314.5264 - val_loss: 524614528.0000 - val_mae: 13988.8418\n",
      "Epoch 5334/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 129796960.0000 - mae: 8301.2881 - val_loss: 523218208.0000 - val_mae: 13874.5625\n",
      "Epoch 5335/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 129898808.0000 - mae: 8280.0039 - val_loss: 523821632.0000 - val_mae: 13949.2383\n",
      "Epoch 5336/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 129705664.0000 - mae: 8301.0371 - val_loss: 522926176.0000 - val_mae: 13861.5195\n",
      "Epoch 5337/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 130551840.0000 - mae: 8316.8926 - val_loss: 523090912.0000 - val_mae: 13881.0166\n",
      "Epoch 5338/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 129906808.0000 - mae: 8307.0928 - val_loss: 523140288.0000 - val_mae: 13892.6016\n",
      "Epoch 5339/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 129685496.0000 - mae: 8280.3740 - val_loss: 523662912.0000 - val_mae: 13914.3623\n",
      "Epoch 5340/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 130281296.0000 - mae: 8294.2334 - val_loss: 523630496.0000 - val_mae: 13942.9434\n",
      "Epoch 5341/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 130188808.0000 - mae: 8327.9531 - val_loss: 523648480.0000 - val_mae: 13934.5342\n",
      "Epoch 5342/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 129817120.0000 - mae: 8265.3516 - val_loss: 523521152.0000 - val_mae: 13894.5654\n",
      "Epoch 5343/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 129833440.0000 - mae: 8306.5791 - val_loss: 523688032.0000 - val_mae: 13885.0547\n",
      "Epoch 5344/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 129887872.0000 - mae: 8310.5010 - val_loss: 524903136.0000 - val_mae: 14000.7354\n",
      "Epoch 5345/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 129875792.0000 - mae: 8293.3672 - val_loss: 523436800.0000 - val_mae: 13908.0020\n",
      "Epoch 5346/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 129802224.0000 - mae: 8280.7334 - val_loss: 523486240.0000 - val_mae: 13912.5801\n",
      "Epoch 5347/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 130157024.0000 - mae: 8346.7256 - val_loss: 523555040.0000 - val_mae: 13860.7207\n",
      "Epoch 5348/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 129694656.0000 - mae: 8280.1377 - val_loss: 524071264.0000 - val_mae: 13959.7871\n",
      "Epoch 5349/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 129991592.0000 - mae: 8327.2285 - val_loss: 523713632.0000 - val_mae: 13903.5693\n",
      "Epoch 5350/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 129194056.0000 - mae: 8282.8477 - val_loss: 523426560.0000 - val_mae: 13868.5400\n",
      "Epoch 5351/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 129702328.0000 - mae: 8292.5713 - val_loss: 524653440.0000 - val_mae: 13986.5449\n",
      "Epoch 5352/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 129399520.0000 - mae: 8280.6748 - val_loss: 524457632.0000 - val_mae: 13986.2793\n",
      "Epoch 5353/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 130940944.0000 - mae: 8385.8662 - val_loss: 527066144.0000 - val_mae: 13839.9678\n",
      "Epoch 5354/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 129467448.0000 - mae: 8306.6143 - val_loss: 524069664.0000 - val_mae: 13959.8486\n",
      "Epoch 5355/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 129410672.0000 - mae: 8288.2197 - val_loss: 527366240.0000 - val_mae: 14096.8369\n",
      "Epoch 5356/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 129929120.0000 - mae: 8313.4121 - val_loss: 523376224.0000 - val_mae: 13864.3271\n",
      "Epoch 5357/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 129431256.0000 - mae: 8279.7393 - val_loss: 524268000.0000 - val_mae: 13964.1143\n",
      "Epoch 5358/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 130355624.0000 - mae: 8348.5391 - val_loss: 523385216.0000 - val_mae: 13843.8496\n",
      "Epoch 5359/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 129716376.0000 - mae: 8289.0752 - val_loss: 523411808.0000 - val_mae: 13919.0693\n",
      "Epoch 5360/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 129229640.0000 - mae: 8283.1436 - val_loss: 523260256.0000 - val_mae: 13890.7725\n",
      "Epoch 5361/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 129012016.0000 - mae: 8271.5088 - val_loss: 525202368.0000 - val_mae: 14030.4326\n",
      "Epoch 5362/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 129517136.0000 - mae: 8336.8320 - val_loss: 524341024.0000 - val_mae: 13855.6377\n",
      "Epoch 5363/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 129600944.0000 - mae: 8279.2744 - val_loss: 523001600.0000 - val_mae: 13892.2178\n",
      "Epoch 5364/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 129072160.0000 - mae: 8267.9893 - val_loss: 523098400.0000 - val_mae: 13878.6631\n",
      "Epoch 5365/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 129513864.0000 - mae: 8285.4912 - val_loss: 523623808.0000 - val_mae: 13942.1826\n",
      "Epoch 5366/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 129222584.0000 - mae: 8264.7568 - val_loss: 523506976.0000 - val_mae: 13906.4912\n",
      "Epoch 5367/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 129221368.0000 - mae: 8277.9004 - val_loss: 522784096.0000 - val_mae: 13895.9375\n",
      "Epoch 5368/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 129299728.0000 - mae: 8286.9131 - val_loss: 526090112.0000 - val_mae: 14067.9248\n",
      "Epoch 5369/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 129388064.0000 - mae: 8290.8945 - val_loss: 524197952.0000 - val_mae: 13881.0254\n",
      "Epoch 5370/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 129548624.0000 - mae: 8297.1777 - val_loss: 523609440.0000 - val_mae: 13852.8027\n",
      "Epoch 5371/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 129433472.0000 - mae: 8270.3428 - val_loss: 523375328.0000 - val_mae: 13924.5996\n",
      "Epoch 5372/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 129430912.0000 - mae: 8313.6904 - val_loss: 523683328.0000 - val_mae: 13881.4355\n",
      "Epoch 5373/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 129346928.0000 - mae: 8285.0791 - val_loss: 523315072.0000 - val_mae: 13881.1855\n",
      "Epoch 5374/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 128651176.0000 - mae: 8246.7510 - val_loss: 523764704.0000 - val_mae: 13967.5371\n",
      "Epoch 5375/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 128916336.0000 - mae: 8279.8301 - val_loss: 523772512.0000 - val_mae: 13876.1152\n",
      "Epoch 5376/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 128893000.0000 - mae: 8261.0518 - val_loss: 523772768.0000 - val_mae: 13969.5410\n",
      "Epoch 5377/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 128842872.0000 - mae: 8261.5488 - val_loss: 523488032.0000 - val_mae: 13905.1465\n",
      "Epoch 5378/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 128956352.0000 - mae: 8277.8398 - val_loss: 523115680.0000 - val_mae: 13912.2559\n",
      "Epoch 5379/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 128983912.0000 - mae: 8259.7627 - val_loss: 523626624.0000 - val_mae: 13936.3027\n",
      "Epoch 5380/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 128942240.0000 - mae: 8254.4453 - val_loss: 523309152.0000 - val_mae: 13938.5059\n",
      "Epoch 5381/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 128895008.0000 - mae: 8267.8721 - val_loss: 523864512.0000 - val_mae: 13948.5020\n",
      "Epoch 5382/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 129061744.0000 - mae: 8280.0078 - val_loss: 524283648.0000 - val_mae: 13982.7373\n",
      "Epoch 5383/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 128871856.0000 - mae: 8267.5566 - val_loss: 523647552.0000 - val_mae: 13847.4609\n",
      "Epoch 5384/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 129452808.0000 - mae: 8309.0264 - val_loss: 524130144.0000 - val_mae: 13859.4951\n",
      "Epoch 5385/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 129536368.0000 - mae: 8305.1621 - val_loss: 524392320.0000 - val_mae: 13873.2695\n",
      "Epoch 5386/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 129112488.0000 - mae: 8280.1240 - val_loss: 523570528.0000 - val_mae: 13876.1807\n",
      "Epoch 5387/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 129006872.0000 - mae: 8273.0811 - val_loss: 523705888.0000 - val_mae: 13894.1562\n",
      "Epoch 5388/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 128636400.0000 - mae: 8245.8984 - val_loss: 523713184.0000 - val_mae: 13962.7842\n",
      "Epoch 5389/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 128870248.0000 - mae: 8266.9775 - val_loss: 523164128.0000 - val_mae: 13906.8555\n",
      "Epoch 5390/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 128317696.0000 - mae: 8243.6533 - val_loss: 525249376.0000 - val_mae: 14025.6475\n",
      "Epoch 5391/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 128913560.0000 - mae: 8268.1904 - val_loss: 523152064.0000 - val_mae: 13876.2969\n",
      "Epoch 5392/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 129074104.0000 - mae: 8273.8750 - val_loss: 523566816.0000 - val_mae: 13891.9590\n",
      "Epoch 5393/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 129397952.0000 - mae: 8278.3965 - val_loss: 523357888.0000 - val_mae: 13920.5762\n",
      "Epoch 5394/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 128600832.0000 - mae: 8260.0254 - val_loss: 523427712.0000 - val_mae: 13916.9307\n",
      "Epoch 5395/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 128546584.0000 - mae: 8255.7246 - val_loss: 524387776.0000 - val_mae: 13980.3369\n",
      "Epoch 5396/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 129272048.0000 - mae: 8298.3086 - val_loss: 523792000.0000 - val_mae: 13966.0820\n",
      "Epoch 5397/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 128628664.0000 - mae: 8280.7725 - val_loss: 523614752.0000 - val_mae: 13895.7324\n",
      "Epoch 5398/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 128916216.0000 - mae: 8301.8125 - val_loss: 523913792.0000 - val_mae: 13973.8525\n",
      "Epoch 5399/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 128578280.0000 - mae: 8252.2822 - val_loss: 523911936.0000 - val_mae: 13979.6777\n",
      "Epoch 5400/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 128822328.0000 - mae: 8272.7266 - val_loss: 524791456.0000 - val_mae: 14005.4492\n",
      "Epoch 5401/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 128669584.0000 - mae: 8243.2266 - val_loss: 523775136.0000 - val_mae: 13966.7871\n",
      "Epoch 5402/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 128951480.0000 - mae: 8271.2861 - val_loss: 523106304.0000 - val_mae: 13905.3818\n",
      "Epoch 5403/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 129523992.0000 - mae: 8302.4072 - val_loss: 523995744.0000 - val_mae: 13960.4629\n",
      "Epoch 5404/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 129292432.0000 - mae: 8283.6152 - val_loss: 523943392.0000 - val_mae: 13970.9531\n",
      "Epoch 5405/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 128282216.0000 - mae: 8244.5410 - val_loss: 523441312.0000 - val_mae: 13911.7441\n",
      "Epoch 5406/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 128264888.0000 - mae: 8265.9932 - val_loss: 523541504.0000 - val_mae: 13880.0400\n",
      "Epoch 5407/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 128556592.0000 - mae: 8255.1396 - val_loss: 523720224.0000 - val_mae: 13964.0020\n",
      "Epoch 5408/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 128935840.0000 - mae: 8279.9961 - val_loss: 523353952.0000 - val_mae: 13963.9756\n",
      "Epoch 5409/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 128332408.0000 - mae: 8247.4795 - val_loss: 523569856.0000 - val_mae: 13948.5879\n",
      "Epoch 5410/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 128280896.0000 - mae: 8250.7129 - val_loss: 523293216.0000 - val_mae: 13910.4814\n",
      "Epoch 5411/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 128800720.0000 - mae: 8272.2090 - val_loss: 523733312.0000 - val_mae: 13969.0303\n",
      "Epoch 5412/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 128481464.0000 - mae: 8249.7930 - val_loss: 524161120.0000 - val_mae: 13979.7480\n",
      "Epoch 5413/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 128815504.0000 - mae: 8263.6055 - val_loss: 523309536.0000 - val_mae: 13924.4834\n",
      "Epoch 5414/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 128103648.0000 - mae: 8235.7070 - val_loss: 524256704.0000 - val_mae: 14002.1611\n",
      "Epoch 5415/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 128328416.0000 - mae: 8246.1035 - val_loss: 523060704.0000 - val_mae: 13925.9453\n",
      "Epoch 5416/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 128315352.0000 - mae: 8252.7510 - val_loss: 523995552.0000 - val_mae: 13969.9688\n",
      "Epoch 5417/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 128238200.0000 - mae: 8246.5420 - val_loss: 523446272.0000 - val_mae: 13943.4229\n",
      "Epoch 5418/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 129012056.0000 - mae: 8282.6309 - val_loss: 524308032.0000 - val_mae: 13987.8486\n",
      "Epoch 5419/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 129325368.0000 - mae: 8266.7324 - val_loss: 523052256.0000 - val_mae: 13914.3740\n",
      "Epoch 5420/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 129194720.0000 - mae: 8292.0361 - val_loss: 522855264.0000 - val_mae: 13922.8828\n",
      "Epoch 5421/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 128216504.0000 - mae: 8259.4131 - val_loss: 522880992.0000 - val_mae: 13881.9551\n",
      "Epoch 5422/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 128412264.0000 - mae: 8242.7061 - val_loss: 522881152.0000 - val_mae: 13918.9766\n",
      "Epoch 5423/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 128368760.0000 - mae: 8260.6484 - val_loss: 524604256.0000 - val_mae: 14022.3115\n",
      "Epoch 5424/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 128364392.0000 - mae: 8276.9404 - val_loss: 522771136.0000 - val_mae: 13941.6152\n",
      "Epoch 5425/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 128176288.0000 - mae: 8264.9639 - val_loss: 522897984.0000 - val_mae: 13918.0146\n",
      "Epoch 5426/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 127821384.0000 - mae: 8230.6172 - val_loss: 523770688.0000 - val_mae: 13970.4277\n",
      "Epoch 5427/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 128076112.0000 - mae: 8245.3652 - val_loss: 523880224.0000 - val_mae: 13976.5010\n",
      "Epoch 5428/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 128529640.0000 - mae: 8252.7256 - val_loss: 522831360.0000 - val_mae: 13933.7822\n",
      "Epoch 5429/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 127844160.0000 - mae: 8270.2617 - val_loss: 524485248.0000 - val_mae: 13875.8037\n",
      "Epoch 5430/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 128445832.0000 - mae: 8294.3301 - val_loss: 523458272.0000 - val_mae: 13978.7139\n",
      "Epoch 5431/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 128026920.0000 - mae: 8264.7646 - val_loss: 523442496.0000 - val_mae: 13877.2861\n",
      "Epoch 5432/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 128239496.0000 - mae: 8248.6035 - val_loss: 523209440.0000 - val_mae: 13918.9609\n",
      "Epoch 5433/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 127665008.0000 - mae: 8226.0762 - val_loss: 523530176.0000 - val_mae: 13975.2578\n",
      "Epoch 5434/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 128401448.0000 - mae: 8250.6797 - val_loss: 523533344.0000 - val_mae: 13915.4863\n",
      "Epoch 5435/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 127993576.0000 - mae: 8235.0586 - val_loss: 525111872.0000 - val_mae: 14046.5869\n",
      "Epoch 5436/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 128256392.0000 - mae: 8250.0576 - val_loss: 523072064.0000 - val_mae: 13953.0498\n",
      "Epoch 5437/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 128164776.0000 - mae: 8302.3945 - val_loss: 523546912.0000 - val_mae: 13889.8018\n",
      "Epoch 5438/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 127862640.0000 - mae: 8238.8496 - val_loss: 523111360.0000 - val_mae: 13902.8984\n",
      "Epoch 5439/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 127875288.0000 - mae: 8249.5566 - val_loss: 523452480.0000 - val_mae: 13976.8955\n",
      "Epoch 5440/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 128412000.0000 - mae: 8271.7900 - val_loss: 525854272.0000 - val_mae: 14074.7412\n",
      "Epoch 5441/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 128418328.0000 - mae: 8242.3125 - val_loss: 525797952.0000 - val_mae: 14070.1602\n",
      "Epoch 5442/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 127691088.0000 - mae: 8251.6924 - val_loss: 522863296.0000 - val_mae: 13911.6162\n",
      "Epoch 5443/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 127484032.0000 - mae: 8259.4434 - val_loss: 524949024.0000 - val_mae: 13866.6113\n",
      "Epoch 5444/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 129073000.0000 - mae: 8301.1748 - val_loss: 523507968.0000 - val_mae: 13979.4863\n",
      "Epoch 5445/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 127988952.0000 - mae: 8245.0010 - val_loss: 523416384.0000 - val_mae: 13920.6270\n",
      "Epoch 5446/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 127559112.0000 - mae: 8236.0264 - val_loss: 523336128.0000 - val_mae: 13957.5059\n",
      "Epoch 5447/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 127649496.0000 - mae: 8236.3115 - val_loss: 524560544.0000 - val_mae: 14026.0439\n",
      "Epoch 5448/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 127900800.0000 - mae: 8257.8018 - val_loss: 523354592.0000 - val_mae: 13908.9697\n",
      "Epoch 5449/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 128067864.0000 - mae: 8247.5625 - val_loss: 523146560.0000 - val_mae: 13919.2334\n",
      "Epoch 5450/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 127671216.0000 - mae: 8269.9170 - val_loss: 524046848.0000 - val_mae: 13909.9121\n",
      "Epoch 5451/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 127364280.0000 - mae: 8220.1582 - val_loss: 525957536.0000 - val_mae: 14088.7266\n",
      "Epoch 5452/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 127847296.0000 - mae: 8292.9375 - val_loss: 522778016.0000 - val_mae: 13893.8545\n",
      "Epoch 5453/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 127487048.0000 - mae: 8238.5713 - val_loss: 523211808.0000 - val_mae: 13942.2021\n",
      "Epoch 5454/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 127674456.0000 - mae: 8241.9609 - val_loss: 523477888.0000 - val_mae: 13947.3721\n",
      "Epoch 5455/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 128109152.0000 - mae: 8277.0039 - val_loss: 523751776.0000 - val_mae: 13986.4648\n",
      "Epoch 5456/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 127114656.0000 - mae: 8211.0352 - val_loss: 522928160.0000 - val_mae: 13910.9609\n",
      "Epoch 5457/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 127372000.0000 - mae: 8228.8350 - val_loss: 523228448.0000 - val_mae: 13926.0254\n",
      "Epoch 5458/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 127933424.0000 - mae: 8262.0518 - val_loss: 523625216.0000 - val_mae: 13881.7822\n",
      "Epoch 5459/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 127997064.0000 - mae: 8262.4414 - val_loss: 524339904.0000 - val_mae: 14032.8740\n",
      "Epoch 5460/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 128456016.0000 - mae: 8280.3984 - val_loss: 523434432.0000 - val_mae: 13975.7812\n",
      "Epoch 5461/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 127530192.0000 - mae: 8221.1152 - val_loss: 523457248.0000 - val_mae: 13944.7383\n",
      "Epoch 5462/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 127175696.0000 - mae: 8204.9170 - val_loss: 524747200.0000 - val_mae: 14026.2266\n",
      "Epoch 5463/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 128138360.0000 - mae: 8262.4141 - val_loss: 523786496.0000 - val_mae: 13966.7158\n",
      "Epoch 5464/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 127551848.0000 - mae: 8249.5596 - val_loss: 523244864.0000 - val_mae: 13899.2969\n",
      "Epoch 5465/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 126982960.0000 - mae: 8213.5762 - val_loss: 525725440.0000 - val_mae: 14076.7744\n",
      "Epoch 5466/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 127372112.0000 - mae: 8242.2168 - val_loss: 523389376.0000 - val_mae: 13929.9707\n",
      "Epoch 5467/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 127256520.0000 - mae: 8229.7441 - val_loss: 524062400.0000 - val_mae: 13881.6250\n",
      "Epoch 5468/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 128045000.0000 - mae: 8251.6211 - val_loss: 523597920.0000 - val_mae: 13968.1475\n",
      "Epoch 5469/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 127160848.0000 - mae: 8215.1406 - val_loss: 523556896.0000 - val_mae: 13935.3730\n",
      "Epoch 5470/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 127333624.0000 - mae: 8224.9004 - val_loss: 526671744.0000 - val_mae: 14113.5518\n",
      "Epoch 5471/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 128458512.0000 - mae: 8275.9561 - val_loss: 524937248.0000 - val_mae: 14044.0518\n",
      "Epoch 5472/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 127156960.0000 - mae: 8221.7695 - val_loss: 523296672.0000 - val_mae: 13934.6855\n",
      "Epoch 5473/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 127084984.0000 - mae: 8213.4385 - val_loss: 524800032.0000 - val_mae: 14050.5859\n",
      "Epoch 5474/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 127726752.0000 - mae: 8230.4004 - val_loss: 523076736.0000 - val_mae: 13939.1602\n",
      "Epoch 5475/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 127189600.0000 - mae: 8244.4287 - val_loss: 523498144.0000 - val_mae: 13909.1807\n",
      "Epoch 5476/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 127711984.0000 - mae: 8222.5186 - val_loss: 523800928.0000 - val_mae: 13959.7578\n",
      "Epoch 5477/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 127541480.0000 - mae: 8237.3389 - val_loss: 522959744.0000 - val_mae: 13899.1230\n",
      "Epoch 5478/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 127265584.0000 - mae: 8231.0869 - val_loss: 523376640.0000 - val_mae: 13929.5615\n",
      "Epoch 5479/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 128021112.0000 - mae: 8242.7363 - val_loss: 524127680.0000 - val_mae: 13892.8438\n",
      "Epoch 5480/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 127473280.0000 - mae: 8248.6572 - val_loss: 523273376.0000 - val_mae: 13930.5146\n",
      "Epoch 5481/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 127078416.0000 - mae: 8207.5566 - val_loss: 523677056.0000 - val_mae: 13962.1055\n",
      "Epoch 5482/6000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 126742320.0000 - mae: 8193.2510 - val_loss: 524902432.0000 - val_mae: 14042.6729\n",
      "Epoch 5483/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 127549480.0000 - mae: 8251.4395 - val_loss: 523770784.0000 - val_mae: 13966.8271\n",
      "Epoch 5484/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 127218464.0000 - mae: 8224.0117 - val_loss: 525072832.0000 - val_mae: 14053.8027\n",
      "Epoch 5485/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 127383616.0000 - mae: 8243.3896 - val_loss: 523946368.0000 - val_mae: 13984.7666\n",
      "Epoch 5486/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 126937384.0000 - mae: 8195.2588 - val_loss: 523012000.0000 - val_mae: 13908.5518\n",
      "Epoch 5487/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 127033424.0000 - mae: 8209.9463 - val_loss: 523186944.0000 - val_mae: 13924.2109\n",
      "Epoch 5488/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 127281752.0000 - mae: 8220.5400 - val_loss: 523503744.0000 - val_mae: 13973.6904\n",
      "Epoch 5489/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 126916168.0000 - mae: 8210.0088 - val_loss: 523625984.0000 - val_mae: 13920.0000\n",
      "Epoch 5490/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 127221376.0000 - mae: 8247.5244 - val_loss: 523962496.0000 - val_mae: 13908.0674\n",
      "Epoch 5491/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 126866728.0000 - mae: 8196.0391 - val_loss: 524573472.0000 - val_mae: 14036.5439\n",
      "Epoch 5492/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 126892456.0000 - mae: 8215.0166 - val_loss: 523800992.0000 - val_mae: 13983.1670\n",
      "Epoch 5493/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 126749880.0000 - mae: 8208.2588 - val_loss: 523147872.0000 - val_mae: 13941.7090\n",
      "Epoch 5494/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 126787488.0000 - mae: 8206.0596 - val_loss: 525299776.0000 - val_mae: 14057.5918\n",
      "Epoch 5495/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 127041384.0000 - mae: 8201.5420 - val_loss: 523932320.0000 - val_mae: 13983.6758\n",
      "Epoch 5496/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 126719768.0000 - mae: 8208.9482 - val_loss: 524355040.0000 - val_mae: 14008.9678\n",
      "Epoch 5497/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 126992872.0000 - mae: 8213.4150 - val_loss: 523368384.0000 - val_mae: 13926.1523\n",
      "Epoch 5498/6000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 126561640.0000 - mae: 8209.1348 - val_loss: 523582720.0000 - val_mae: 13965.3643\n",
      "Epoch 5499/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 126972744.0000 - mae: 8200.2666 - val_loss: 523234752.0000 - val_mae: 13951.6172\n",
      "Epoch 5500/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 127082936.0000 - mae: 8214.1182 - val_loss: 523430240.0000 - val_mae: 13964.0742\n",
      "Epoch 5501/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 126703392.0000 - mae: 8231.5850 - val_loss: 523985440.0000 - val_mae: 13933.2881\n",
      "Epoch 5502/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 126616352.0000 - mae: 8199.4492 - val_loss: 524111552.0000 - val_mae: 14025.0459\n",
      "Epoch 5503/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 127252040.0000 - mae: 8230.7920 - val_loss: 525960352.0000 - val_mae: 14103.9395\n",
      "Epoch 5504/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 127012408.0000 - mae: 8248.8584 - val_loss: 523464448.0000 - val_mae: 13945.7314\n",
      "Epoch 5505/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 126546704.0000 - mae: 8196.7256 - val_loss: 523289728.0000 - val_mae: 13957.3828\n",
      "Epoch 5506/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 127609944.0000 - mae: 8251.2812 - val_loss: 525442944.0000 - val_mae: 14067.1914\n",
      "Epoch 5507/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 126825056.0000 - mae: 8217.6113 - val_loss: 523088288.0000 - val_mae: 13967.0625\n",
      "Epoch 5508/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 126488912.0000 - mae: 8197.3428 - val_loss: 523601984.0000 - val_mae: 13961.2109\n",
      "Epoch 5509/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 126390640.0000 - mae: 8190.2188 - val_loss: 524365920.0000 - val_mae: 14033.7383\n",
      "Epoch 5510/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 126748432.0000 - mae: 8210.7705 - val_loss: 524263392.0000 - val_mae: 14020.5566\n",
      "Epoch 5511/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 126238472.0000 - mae: 8180.0640 - val_loss: 523280160.0000 - val_mae: 13956.4277\n",
      "Epoch 5512/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 126377392.0000 - mae: 8191.0586 - val_loss: 523213504.0000 - val_mae: 13943.0625\n",
      "Epoch 5513/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 126245760.0000 - mae: 8186.0044 - val_loss: 525844672.0000 - val_mae: 14092.5723\n",
      "Epoch 5514/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 127036448.0000 - mae: 8257.6953 - val_loss: 523397792.0000 - val_mae: 13911.4863\n",
      "Epoch 5515/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 126323096.0000 - mae: 8181.3330 - val_loss: 524767168.0000 - val_mae: 14046.7031\n",
      "Epoch 5516/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 126696432.0000 - mae: 8226.5137 - val_loss: 523233760.0000 - val_mae: 13931.7490\n",
      "Epoch 5517/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 126290288.0000 - mae: 8187.9321 - val_loss: 523847136.0000 - val_mae: 13980.9375\n",
      "Epoch 5518/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 126565568.0000 - mae: 8208.4541 - val_loss: 524014112.0000 - val_mae: 14017.7861\n",
      "Epoch 5519/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 126925064.0000 - mae: 8212.2695 - val_loss: 523280288.0000 - val_mae: 13939.4023\n",
      "Epoch 5520/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 126637728.0000 - mae: 8204.5283 - val_loss: 523693248.0000 - val_mae: 13960.5957\n",
      "Epoch 5521/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 126744048.0000 - mae: 8203.5840 - val_loss: 523998240.0000 - val_mae: 14008.8389\n",
      "Epoch 5522/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 126255856.0000 - mae: 8190.9551 - val_loss: 523728480.0000 - val_mae: 13965.8252\n",
      "Epoch 5523/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 126107208.0000 - mae: 8181.7329 - val_loss: 523922880.0000 - val_mae: 13996.0186\n",
      "Epoch 5524/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 126894688.0000 - mae: 8261.5674 - val_loss: 523385664.0000 - val_mae: 13936.9023\n",
      "Epoch 5525/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 127535712.0000 - mae: 8228.7871 - val_loss: 523796608.0000 - val_mae: 13899.8115\n",
      "Epoch 5526/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 126758968.0000 - mae: 8240.3701 - val_loss: 524097696.0000 - val_mae: 13916.3242\n",
      "Epoch 5527/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 126529152.0000 - mae: 8190.0107 - val_loss: 523651648.0000 - val_mae: 13960.4463\n",
      "Epoch 5528/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 126210624.0000 - mae: 8194.5010 - val_loss: 523665280.0000 - val_mae: 13981.9229\n",
      "Epoch 5529/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 126124392.0000 - mae: 8192.4395 - val_loss: 524579488.0000 - val_mae: 14045.9512\n",
      "Epoch 5530/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 126198808.0000 - mae: 8195.7861 - val_loss: 524265504.0000 - val_mae: 14014.0605\n",
      "Epoch 5531/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 126144600.0000 - mae: 8184.8438 - val_loss: 523516928.0000 - val_mae: 13978.5195\n",
      "Epoch 5532/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 126083032.0000 - mae: 8193.5020 - val_loss: 523505248.0000 - val_mae: 13967.2188\n",
      "Epoch 5533/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 127165504.0000 - mae: 8244.3213 - val_loss: 523647360.0000 - val_mae: 13909.6211\n",
      "Epoch 5534/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 126122848.0000 - mae: 8203.5361 - val_loss: 523180960.0000 - val_mae: 13979.4209\n",
      "Epoch 5535/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 125961344.0000 - mae: 8181.4673 - val_loss: 523733952.0000 - val_mae: 13974.8779\n",
      "Epoch 5536/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 126264992.0000 - mae: 8190.4082 - val_loss: 523639136.0000 - val_mae: 13996.6602\n",
      "Epoch 5537/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 126937568.0000 - mae: 8262.7266 - val_loss: 523320992.0000 - val_mae: 13928.8467\n",
      "Epoch 5538/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 126392304.0000 - mae: 8190.7544 - val_loss: 524267328.0000 - val_mae: 14009.6582\n",
      "Epoch 5539/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 126371864.0000 - mae: 8205.9688 - val_loss: 523676704.0000 - val_mae: 13997.1660\n",
      "Epoch 5540/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 125752080.0000 - mae: 8181.9775 - val_loss: 523885504.0000 - val_mae: 13938.5908\n",
      "Epoch 5541/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 126065352.0000 - mae: 8205.5762 - val_loss: 523376960.0000 - val_mae: 13966.6719\n",
      "Epoch 5542/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 126046016.0000 - mae: 8182.7559 - val_loss: 523353632.0000 - val_mae: 13969.7920\n",
      "Epoch 5543/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 125812752.0000 - mae: 8182.8613 - val_loss: 523396032.0000 - val_mae: 13940.0713\n",
      "Epoch 5544/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 126143520.0000 - mae: 8189.6816 - val_loss: 523446976.0000 - val_mae: 13976.1445\n",
      "Epoch 5545/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 126101192.0000 - mae: 8187.6733 - val_loss: 523710912.0000 - val_mae: 13973.4336\n",
      "Epoch 5546/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 126102760.0000 - mae: 8227.8887 - val_loss: 524179232.0000 - val_mae: 13924.0723\n",
      "Epoch 5547/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 126810624.0000 - mae: 8244.0391 - val_loss: 525536288.0000 - val_mae: 13900.9326\n",
      "Epoch 5548/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 126726192.0000 - mae: 8218.2383 - val_loss: 523748352.0000 - val_mae: 13962.3682\n",
      "Epoch 5549/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 125612328.0000 - mae: 8166.6094 - val_loss: 524598848.0000 - val_mae: 14033.1514\n",
      "Epoch 5550/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 126503720.0000 - mae: 8225.1631 - val_loss: 524435520.0000 - val_mae: 14037.0293\n",
      "Epoch 5551/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 126843592.0000 - mae: 8236.1465 - val_loss: 525749376.0000 - val_mae: 14102.7412\n",
      "Epoch 5552/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 126432416.0000 - mae: 8219.3223 - val_loss: 524913120.0000 - val_mae: 14063.7441\n",
      "Epoch 5553/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 126655944.0000 - mae: 8225.1934 - val_loss: 524337696.0000 - val_mae: 14029.1914\n",
      "Epoch 5554/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 125914624.0000 - mae: 8186.9521 - val_loss: 525142144.0000 - val_mae: 14073.8682\n",
      "Epoch 5555/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 126941856.0000 - mae: 8235.3389 - val_loss: 524757216.0000 - val_mae: 14058.6074\n",
      "Epoch 5556/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 126580824.0000 - mae: 8238.0615 - val_loss: 526911104.0000 - val_mae: 14120.9102\n",
      "Epoch 5557/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 126355488.0000 - mae: 8194.9531 - val_loss: 525230368.0000 - val_mae: 14080.9854\n",
      "Epoch 5558/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 126296728.0000 - mae: 8217.9375 - val_loss: 523786112.0000 - val_mae: 13976.1758\n",
      "Epoch 5559/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 125727848.0000 - mae: 8185.2798 - val_loss: 524221408.0000 - val_mae: 13999.1250\n",
      "Epoch 5560/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 125616216.0000 - mae: 8174.1987 - val_loss: 522728064.0000 - val_mae: 13947.5283\n",
      "Epoch 5561/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 125951704.0000 - mae: 8184.2627 - val_loss: 523888704.0000 - val_mae: 13947.1973\n",
      "Epoch 5562/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 125495880.0000 - mae: 8178.3662 - val_loss: 523513216.0000 - val_mae: 13981.6152\n",
      "Epoch 5563/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 125843088.0000 - mae: 8198.5234 - val_loss: 524524448.0000 - val_mae: 13924.3467\n",
      "Epoch 5564/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 126748864.0000 - mae: 8229.2969 - val_loss: 523594400.0000 - val_mae: 14001.3096\n",
      "Epoch 5565/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 125752744.0000 - mae: 8177.8003 - val_loss: 525120480.0000 - val_mae: 14076.2021\n",
      "Epoch 5566/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 125806272.0000 - mae: 8165.5161 - val_loss: 523795776.0000 - val_mae: 13996.2822\n",
      "Epoch 5567/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 125576048.0000 - mae: 8186.8208 - val_loss: 524875648.0000 - val_mae: 14064.1934\n",
      "Epoch 5568/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 125905688.0000 - mae: 8182.2266 - val_loss: 525419968.0000 - val_mae: 14095.8555\n",
      "Epoch 5569/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 126116488.0000 - mae: 8196.2617 - val_loss: 524123936.0000 - val_mae: 14019.6885\n",
      "Epoch 5570/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 125828680.0000 - mae: 8183.2041 - val_loss: 524613408.0000 - val_mae: 14049.3906\n",
      "Epoch 5571/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 125699912.0000 - mae: 8169.0439 - val_loss: 524127936.0000 - val_mae: 14006.8896\n",
      "Epoch 5572/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 125334504.0000 - mae: 8180.4375 - val_loss: 523882400.0000 - val_mae: 14026.0283\n",
      "Epoch 5573/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 125525328.0000 - mae: 8170.4116 - val_loss: 523668512.0000 - val_mae: 14000.7051\n",
      "Epoch 5574/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 125258088.0000 - mae: 8166.1572 - val_loss: 524400352.0000 - val_mae: 14029.2969\n",
      "Epoch 5575/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 125318768.0000 - mae: 8174.0981 - val_loss: 523672512.0000 - val_mae: 13991.3496\n",
      "Epoch 5576/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 125048520.0000 - mae: 8165.6118 - val_loss: 523270528.0000 - val_mae: 13964.4072\n",
      "Epoch 5577/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 125962880.0000 - mae: 8192.6484 - val_loss: 524849568.0000 - val_mae: 13915.0410\n",
      "Epoch 5578/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 125875320.0000 - mae: 8202.2373 - val_loss: 523670880.0000 - val_mae: 13980.3242\n",
      "Epoch 5579/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 125297520.0000 - mae: 8154.9150 - val_loss: 523690208.0000 - val_mae: 13997.8467\n",
      "Epoch 5580/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 125306288.0000 - mae: 8177.1567 - val_loss: 523526752.0000 - val_mae: 13958.9717\n",
      "Epoch 5581/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 125956608.0000 - mae: 8175.7646 - val_loss: 523798304.0000 - val_mae: 14009.5156\n",
      "Epoch 5582/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 125009480.0000 - mae: 8151.3164 - val_loss: 523656608.0000 - val_mae: 13941.2119\n",
      "Epoch 5583/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 126158120.0000 - mae: 8181.7207 - val_loss: 523447648.0000 - val_mae: 13952.7744\n",
      "Epoch 5584/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 125938992.0000 - mae: 8197.3652 - val_loss: 523800320.0000 - val_mae: 13918.3379\n",
      "Epoch 5585/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 126427056.0000 - mae: 8193.8506 - val_loss: 523867744.0000 - val_mae: 13933.0488\n",
      "Epoch 5586/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 127369768.0000 - mae: 8251.1660 - val_loss: 524863040.0000 - val_mae: 13937.5840\n",
      "Epoch 5587/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 125779504.0000 - mae: 8207.8613 - val_loss: 523878080.0000 - val_mae: 13949.8789\n",
      "Epoch 5588/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 125541744.0000 - mae: 8183.2256 - val_loss: 523637408.0000 - val_mae: 13948.0791\n",
      "Epoch 5589/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 125439704.0000 - mae: 8169.5576 - val_loss: 525878592.0000 - val_mae: 14104.3193\n",
      "Epoch 5590/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 126001200.0000 - mae: 8203.6475 - val_loss: 524492160.0000 - val_mae: 14048.5352\n",
      "Epoch 5591/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 125199608.0000 - mae: 8157.2368 - val_loss: 523762592.0000 - val_mae: 13980.8135\n",
      "Epoch 5592/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 125383848.0000 - mae: 8180.4043 - val_loss: 524147872.0000 - val_mae: 14037.2354\n",
      "Epoch 5593/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 125270104.0000 - mae: 8175.6372 - val_loss: 523773472.0000 - val_mae: 13977.5195\n",
      "Epoch 5594/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 124806576.0000 - mae: 8149.1689 - val_loss: 523883840.0000 - val_mae: 13989.4121\n",
      "Epoch 5595/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 125095184.0000 - mae: 8158.6245 - val_loss: 524735456.0000 - val_mae: 14042.9717\n",
      "Epoch 5596/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 124960768.0000 - mae: 8160.0854 - val_loss: 523430720.0000 - val_mae: 13966.1982\n",
      "Epoch 5597/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 125270232.0000 - mae: 8170.0430 - val_loss: 525175552.0000 - val_mae: 14079.9404\n",
      "Epoch 5598/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 125704776.0000 - mae: 8185.1938 - val_loss: 525232992.0000 - val_mae: 14075.2666\n",
      "Epoch 5599/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 124753072.0000 - mae: 8150.9526 - val_loss: 524899872.0000 - val_mae: 13918.8721\n",
      "Epoch 5600/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 125538312.0000 - mae: 8152.6333 - val_loss: 523362784.0000 - val_mae: 13968.3896\n",
      "Epoch 5601/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 125557632.0000 - mae: 8194.0430 - val_loss: 524997280.0000 - val_mae: 13923.5322\n",
      "Epoch 5602/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 125631344.0000 - mae: 8198.9834 - val_loss: 523477280.0000 - val_mae: 13958.4160\n",
      "Epoch 5603/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 124554392.0000 - mae: 8143.0479 - val_loss: 525588320.0000 - val_mae: 14110.4951\n",
      "Epoch 5604/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 125218896.0000 - mae: 8201.8271 - val_loss: 523953312.0000 - val_mae: 13974.8906\n",
      "Epoch 5605/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 125167176.0000 - mae: 8170.4619 - val_loss: 523561024.0000 - val_mae: 13993.3145\n",
      "Epoch 5606/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 124955184.0000 - mae: 8151.8633 - val_loss: 523430368.0000 - val_mae: 13994.1904\n",
      "Epoch 5607/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 124721216.0000 - mae: 8153.3921 - val_loss: 524233120.0000 - val_mae: 14008.4395\n",
      "Epoch 5608/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 124907528.0000 - mae: 8149.0791 - val_loss: 524528320.0000 - val_mae: 14060.4736\n",
      "Epoch 5609/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 125032104.0000 - mae: 8155.3633 - val_loss: 523023456.0000 - val_mae: 13970.7715\n",
      "Epoch 5610/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 125187744.0000 - mae: 8191.9048 - val_loss: 523729152.0000 - val_mae: 13944.0088\n",
      "Epoch 5611/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124807904.0000 - mae: 8172.0679 - val_loss: 523748288.0000 - val_mae: 13965.8643\n",
      "Epoch 5612/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 125126104.0000 - mae: 8157.9541 - val_loss: 523503776.0000 - val_mae: 14002.3418\n",
      "Epoch 5613/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 125095224.0000 - mae: 8170.2754 - val_loss: 524047200.0000 - val_mae: 14035.5322\n",
      "Epoch 5614/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 125991792.0000 - mae: 8202.3516 - val_loss: 523720160.0000 - val_mae: 14012.8584\n",
      "Epoch 5615/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 124617448.0000 - mae: 8131.1001 - val_loss: 523746208.0000 - val_mae: 13998.0010\n",
      "Epoch 5616/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 124777304.0000 - mae: 8174.2627 - val_loss: 523715264.0000 - val_mae: 13953.5293\n",
      "Epoch 5617/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 125103144.0000 - mae: 8177.2329 - val_loss: 523218400.0000 - val_mae: 13954.8750\n",
      "Epoch 5618/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 124851632.0000 - mae: 8167.2173 - val_loss: 524171168.0000 - val_mae: 13949.2949\n",
      "Epoch 5619/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 124830064.0000 - mae: 8186.2251 - val_loss: 524009536.0000 - val_mae: 14028.2871\n",
      "Epoch 5620/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124743088.0000 - mae: 8150.6587 - val_loss: 524975904.0000 - val_mae: 14079.3799\n",
      "Epoch 5621/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 124546592.0000 - mae: 8151.3501 - val_loss: 523736608.0000 - val_mae: 13999.7666\n",
      "Epoch 5622/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124594000.0000 - mae: 8146.6973 - val_loss: 525328576.0000 - val_mae: 14099.8164\n",
      "Epoch 5623/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 124918696.0000 - mae: 8176.4673 - val_loss: 523792672.0000 - val_mae: 14004.2568\n",
      "Epoch 5624/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124336488.0000 - mae: 8143.0708 - val_loss: 523897248.0000 - val_mae: 13995.8477\n",
      "Epoch 5625/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 124653160.0000 - mae: 8143.3408 - val_loss: 523514944.0000 - val_mae: 14010.1826\n",
      "Epoch 5626/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 125410416.0000 - mae: 8195.7539 - val_loss: 524077856.0000 - val_mae: 13956.1934\n",
      "Epoch 5627/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124852584.0000 - mae: 8152.3486 - val_loss: 523677504.0000 - val_mae: 13993.3389\n",
      "Epoch 5628/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124266680.0000 - mae: 8136.5894 - val_loss: 523800512.0000 - val_mae: 13955.1104\n",
      "Epoch 5629/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124639048.0000 - mae: 8145.8770 - val_loss: 523197760.0000 - val_mae: 13967.2432\n",
      "Epoch 5630/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 124568712.0000 - mae: 8162.0483 - val_loss: 523500096.0000 - val_mae: 13960.5791\n",
      "Epoch 5631/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 125196232.0000 - mae: 8184.1694 - val_loss: 523320320.0000 - val_mae: 13970.2793\n",
      "Epoch 5632/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124402896.0000 - mae: 8166.5942 - val_loss: 526024160.0000 - val_mae: 14119.9043\n",
      "Epoch 5633/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 125273432.0000 - mae: 8187.5327 - val_loss: 524243648.0000 - val_mae: 14046.1309\n",
      "Epoch 5634/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124445680.0000 - mae: 8140.0591 - val_loss: 523615040.0000 - val_mae: 14005.3828\n",
      "Epoch 5635/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124289040.0000 - mae: 8136.3389 - val_loss: 524091456.0000 - val_mae: 14029.4150\n",
      "Epoch 5636/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124732680.0000 - mae: 8174.5757 - val_loss: 523959648.0000 - val_mae: 13970.6279\n",
      "Epoch 5637/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124801520.0000 - mae: 8143.7070 - val_loss: 524224736.0000 - val_mae: 14046.6807\n",
      "Epoch 5638/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124544384.0000 - mae: 8146.9360 - val_loss: 523657760.0000 - val_mae: 14023.5312\n",
      "Epoch 5639/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 125305464.0000 - mae: 8216.4160 - val_loss: 524001536.0000 - val_mae: 13983.2168\n",
      "Epoch 5640/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124976696.0000 - mae: 8171.2295 - val_loss: 524119392.0000 - val_mae: 14021.7275\n",
      "Epoch 5641/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 124464872.0000 - mae: 8152.6382 - val_loss: 524073184.0000 - val_mae: 14040.4902\n",
      "Epoch 5642/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124120256.0000 - mae: 8132.7656 - val_loss: 523495744.0000 - val_mae: 13992.8926\n",
      "Epoch 5643/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124332672.0000 - mae: 8145.7197 - val_loss: 523927680.0000 - val_mae: 13998.0928\n",
      "Epoch 5644/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124278680.0000 - mae: 8137.4536 - val_loss: 523844032.0000 - val_mae: 14022.6152\n",
      "Epoch 5645/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124129560.0000 - mae: 8158.0610 - val_loss: 523562752.0000 - val_mae: 13960.5801\n",
      "Epoch 5646/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124868824.0000 - mae: 8131.7290 - val_loss: 523895552.0000 - val_mae: 14015.6094\n",
      "Epoch 5647/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124058928.0000 - mae: 8126.3589 - val_loss: 523463456.0000 - val_mae: 13962.7480\n",
      "Epoch 5648/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124101544.0000 - mae: 8127.9717 - val_loss: 524854976.0000 - val_mae: 14076.8115\n",
      "Epoch 5649/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124313528.0000 - mae: 8144.7104 - val_loss: 523573888.0000 - val_mae: 13980.8887\n",
      "Epoch 5650/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124638688.0000 - mae: 8161.2671 - val_loss: 524616160.0000 - val_mae: 13936.3545\n",
      "Epoch 5651/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 124157544.0000 - mae: 8158.0918 - val_loss: 524011936.0000 - val_mae: 13992.3936\n",
      "Epoch 5652/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124638936.0000 - mae: 8148.8789 - val_loss: 524109248.0000 - val_mae: 14054.0801\n",
      "Epoch 5653/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124195424.0000 - mae: 8126.9917 - val_loss: 523744512.0000 - val_mae: 13996.3740\n",
      "Epoch 5654/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124093368.0000 - mae: 8144.0522 - val_loss: 524011008.0000 - val_mae: 14033.3848\n",
      "Epoch 5655/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 123893376.0000 - mae: 8122.7080 - val_loss: 523791520.0000 - val_mae: 14033.6865\n",
      "Epoch 5656/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124112936.0000 - mae: 8136.3579 - val_loss: 525034880.0000 - val_mae: 14079.3428\n",
      "Epoch 5657/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124266192.0000 - mae: 8131.5986 - val_loss: 525102784.0000 - val_mae: 14095.0117\n",
      "Epoch 5658/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 124610656.0000 - mae: 8120.0610 - val_loss: 523977536.0000 - val_mae: 14045.3818\n",
      "Epoch 5659/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 123894568.0000 - mae: 8128.9878 - val_loss: 523283008.0000 - val_mae: 13994.0908\n",
      "Epoch 5660/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 125732208.0000 - mae: 8225.5449 - val_loss: 525150752.0000 - val_mae: 13931.1875\n",
      "Epoch 5661/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124642272.0000 - mae: 8168.3184 - val_loss: 523498208.0000 - val_mae: 13967.1885\n",
      "Epoch 5662/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 123989560.0000 - mae: 8161.6572 - val_loss: 525132128.0000 - val_mae: 14088.2441\n",
      "Epoch 5663/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 123708856.0000 - mae: 8120.9038 - val_loss: 523773536.0000 - val_mae: 14015.1982\n",
      "Epoch 5664/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124611256.0000 - mae: 8199.2109 - val_loss: 523754496.0000 - val_mae: 13953.6807\n",
      "Epoch 5665/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124096376.0000 - mae: 8134.8184 - val_loss: 523742720.0000 - val_mae: 13960.6914\n",
      "Epoch 5666/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124584936.0000 - mae: 8160.7319 - val_loss: 523678656.0000 - val_mae: 13999.2256\n",
      "Epoch 5667/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 126171328.0000 - mae: 8257.1748 - val_loss: 524312544.0000 - val_mae: 14054.7354\n",
      "Epoch 5668/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124143520.0000 - mae: 8136.4995 - val_loss: 527296352.0000 - val_mae: 14199.6475\n",
      "Epoch 5669/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 124980888.0000 - mae: 8197.6543 - val_loss: 524686240.0000 - val_mae: 14059.9629\n",
      "Epoch 5670/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124277928.0000 - mae: 8181.1943 - val_loss: 523752000.0000 - val_mae: 13971.2324\n",
      "Epoch 5671/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124015552.0000 - mae: 8141.4517 - val_loss: 523549248.0000 - val_mae: 13981.6582\n",
      "Epoch 5672/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124130728.0000 - mae: 8153.0454 - val_loss: 523488864.0000 - val_mae: 13978.4082\n",
      "Epoch 5673/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 124194072.0000 - mae: 8147.6978 - val_loss: 524232672.0000 - val_mae: 14032.1816\n",
      "Epoch 5674/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124322872.0000 - mae: 8154.3252 - val_loss: 524052480.0000 - val_mae: 13930.7256\n",
      "Epoch 5675/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 123788520.0000 - mae: 8131.3691 - val_loss: 523471488.0000 - val_mae: 13977.5879\n",
      "Epoch 5676/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 123469944.0000 - mae: 8108.2095 - val_loss: 524892416.0000 - val_mae: 14067.9453\n",
      "Epoch 5677/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124143400.0000 - mae: 8161.4829 - val_loss: 526141376.0000 - val_mae: 14130.1348\n",
      "Epoch 5678/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124310000.0000 - mae: 8154.4092 - val_loss: 524586528.0000 - val_mae: 14066.8301\n",
      "Epoch 5679/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124222152.0000 - mae: 8130.4160 - val_loss: 525076608.0000 - val_mae: 14083.9834\n",
      "Epoch 5680/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 123337592.0000 - mae: 8141.0430 - val_loss: 524284896.0000 - val_mae: 13949.5791\n",
      "Epoch 5681/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124521880.0000 - mae: 8157.7729 - val_loss: 523849248.0000 - val_mae: 14050.2529\n",
      "Epoch 5682/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 123844288.0000 - mae: 8128.2114 - val_loss: 524416448.0000 - val_mae: 14079.5342\n",
      "Epoch 5683/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 123882664.0000 - mae: 8140.3789 - val_loss: 523677440.0000 - val_mae: 14017.1504\n",
      "Epoch 5684/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124030440.0000 - mae: 8149.7979 - val_loss: 524080608.0000 - val_mae: 14019.8838\n",
      "Epoch 5685/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 123854400.0000 - mae: 8133.4312 - val_loss: 523853440.0000 - val_mae: 14004.9707\n",
      "Epoch 5686/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 123764656.0000 - mae: 8117.9829 - val_loss: 523984544.0000 - val_mae: 14030.7051\n",
      "Epoch 5687/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 123813128.0000 - mae: 8128.2163 - val_loss: 523356288.0000 - val_mae: 13999.8301\n",
      "Epoch 5688/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124095024.0000 - mae: 8131.7480 - val_loss: 523903936.0000 - val_mae: 13964.8398\n",
      "Epoch 5689/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 123876224.0000 - mae: 8141.6626 - val_loss: 523518400.0000 - val_mae: 13970.4307\n",
      "Epoch 5690/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 123313384.0000 - mae: 8113.5483 - val_loss: 524584832.0000 - val_mae: 14080.7842\n",
      "Epoch 5691/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 123666688.0000 - mae: 8129.0298 - val_loss: 524048192.0000 - val_mae: 14022.8936\n",
      "Epoch 5692/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 123635184.0000 - mae: 8121.4990 - val_loss: 524135776.0000 - val_mae: 14050.4600\n",
      "Epoch 5693/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 123971064.0000 - mae: 8128.2676 - val_loss: 524134720.0000 - val_mae: 14056.2480\n",
      "Epoch 5694/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 123870160.0000 - mae: 8137.5571 - val_loss: 524543168.0000 - val_mae: 14068.3271\n",
      "Epoch 5695/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 123126968.0000 - mae: 8123.9990 - val_loss: 523802720.0000 - val_mae: 13948.2432\n",
      "Epoch 5696/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 123782768.0000 - mae: 8105.8486 - val_loss: 524637920.0000 - val_mae: 14077.1826\n",
      "Epoch 5697/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 123895640.0000 - mae: 8173.8838 - val_loss: 523884032.0000 - val_mae: 13937.8232\n",
      "Epoch 5698/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 123786240.0000 - mae: 8152.8301 - val_loss: 524465952.0000 - val_mae: 13963.1758\n",
      "Epoch 5699/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 123714440.0000 - mae: 8132.2241 - val_loss: 524325056.0000 - val_mae: 14055.0049\n",
      "Epoch 5700/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 124473016.0000 - mae: 8150.6045 - val_loss: 524375264.0000 - val_mae: 14057.1621\n",
      "Epoch 5701/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 123617144.0000 - mae: 8113.5679 - val_loss: 524233024.0000 - val_mae: 14043.2520\n",
      "Epoch 5702/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 123681952.0000 - mae: 8137.3818 - val_loss: 524648448.0000 - val_mae: 14052.5693\n",
      "Epoch 5703/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 123237720.0000 - mae: 8111.5381 - val_loss: 524423008.0000 - val_mae: 14074.8818\n",
      "Epoch 5704/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 123708664.0000 - mae: 8137.9526 - val_loss: 524828480.0000 - val_mae: 14079.5605\n",
      "Epoch 5705/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 123812720.0000 - mae: 8117.3838 - val_loss: 524258976.0000 - val_mae: 14050.1318\n",
      "Epoch 5706/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 123552248.0000 - mae: 8120.7017 - val_loss: 525705184.0000 - val_mae: 14137.8350\n",
      "Epoch 5707/6000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 123311240.0000 - mae: 8127.9917 - val_loss: 523405728.0000 - val_mae: 13997.2812\n",
      "Epoch 5708/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 123084816.0000 - mae: 8090.5430 - val_loss: 523989280.0000 - val_mae: 14043.4355\n",
      "Epoch 5709/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 123078504.0000 - mae: 8099.5801 - val_loss: 523936224.0000 - val_mae: 14047.2646\n",
      "Epoch 5710/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 123256096.0000 - mae: 8112.6440 - val_loss: 523751008.0000 - val_mae: 14014.2559\n",
      "Epoch 5711/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 123319296.0000 - mae: 8117.9409 - val_loss: 523685888.0000 - val_mae: 13992.1182\n",
      "Epoch 5712/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 123943144.0000 - mae: 8125.7554 - val_loss: 522814400.0000 - val_mae: 13986.7939\n",
      "Epoch 5713/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 122980632.0000 - mae: 8104.9448 - val_loss: 525383200.0000 - val_mae: 14115.5391\n",
      "Epoch 5714/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 123345008.0000 - mae: 8122.9839 - val_loss: 523790336.0000 - val_mae: 14012.8027\n",
      "Epoch 5715/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 123265472.0000 - mae: 8091.6040 - val_loss: 523670976.0000 - val_mae: 13988.6748\n",
      "Epoch 5716/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 123289400.0000 - mae: 8111.6826 - val_loss: 523576224.0000 - val_mae: 14013.2744\n",
      "Epoch 5717/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 123760504.0000 - mae: 8132.1196 - val_loss: 523745344.0000 - val_mae: 13979.1924\n",
      "Epoch 5718/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 123244624.0000 - mae: 8118.9302 - val_loss: 524998688.0000 - val_mae: 14101.9004\n",
      "Epoch 5719/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 123411024.0000 - mae: 8096.4517 - val_loss: 524561120.0000 - val_mae: 14054.3672\n",
      "Epoch 5720/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 123745264.0000 - mae: 8183.0767 - val_loss: 523734240.0000 - val_mae: 13966.4629\n",
      "Epoch 5721/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 123743592.0000 - mae: 8150.8252 - val_loss: 523652032.0000 - val_mae: 13939.6729\n",
      "Epoch 5722/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122998520.0000 - mae: 8099.6333 - val_loss: 523371936.0000 - val_mae: 14018.9609\n",
      "Epoch 5723/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 122863008.0000 - mae: 8106.3062 - val_loss: 524646528.0000 - val_mae: 13979.7285\n",
      "Epoch 5724/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 122858472.0000 - mae: 8087.6030 - val_loss: 523665792.0000 - val_mae: 14027.3936\n",
      "Epoch 5725/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 123182288.0000 - mae: 8103.6523 - val_loss: 523879104.0000 - val_mae: 14009.4717\n",
      "Epoch 5726/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 122746000.0000 - mae: 8107.9233 - val_loss: 523849440.0000 - val_mae: 13983.1279\n",
      "Epoch 5727/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 123317248.0000 - mae: 8086.8223 - val_loss: 524762304.0000 - val_mae: 14092.3164\n",
      "Epoch 5728/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 122749128.0000 - mae: 8087.0054 - val_loss: 523428288.0000 - val_mae: 13988.1113\n",
      "Epoch 5729/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 123350096.0000 - mae: 8158.5894 - val_loss: 526145472.0000 - val_mae: 13951.1650\n",
      "Epoch 5730/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124061216.0000 - mae: 8134.4087 - val_loss: 523716512.0000 - val_mae: 14009.8828\n",
      "Epoch 5731/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 123183688.0000 - mae: 8103.0674 - val_loss: 523661088.0000 - val_mae: 13987.4199\n",
      "Epoch 5732/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 122948792.0000 - mae: 8099.4062 - val_loss: 523698048.0000 - val_mae: 13957.5771\n",
      "Epoch 5733/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 123668888.0000 - mae: 8123.5254 - val_loss: 523738048.0000 - val_mae: 14043.1045\n",
      "Epoch 5734/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 122954400.0000 - mae: 8086.1846 - val_loss: 523253888.0000 - val_mae: 14009.4912\n",
      "Epoch 5735/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 122695856.0000 - mae: 8088.1260 - val_loss: 524446208.0000 - val_mae: 14090.6445\n",
      "Epoch 5736/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 122666320.0000 - mae: 8116.4526 - val_loss: 523961664.0000 - val_mae: 13938.6152\n",
      "Epoch 5737/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 122811448.0000 - mae: 8100.1953 - val_loss: 524226752.0000 - val_mae: 14057.2207\n",
      "Epoch 5738/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 122889608.0000 - mae: 8095.8911 - val_loss: 523928864.0000 - val_mae: 14028.3184\n",
      "Epoch 5739/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122801680.0000 - mae: 8095.6597 - val_loss: 523321216.0000 - val_mae: 14017.9531\n",
      "Epoch 5740/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 122883304.0000 - mae: 8095.0405 - val_loss: 523939680.0000 - val_mae: 13984.4131\n",
      "Epoch 5741/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122796184.0000 - mae: 8110.0303 - val_loss: 523101632.0000 - val_mae: 13992.7383\n",
      "Epoch 5742/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 122829248.0000 - mae: 8074.7549 - val_loss: 526485824.0000 - val_mae: 14182.7812\n",
      "Epoch 5743/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 123359040.0000 - mae: 8130.5557 - val_loss: 523724512.0000 - val_mae: 13972.1377\n",
      "Epoch 5744/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122968608.0000 - mae: 8095.0986 - val_loss: 523420032.0000 - val_mae: 13951.7236\n",
      "Epoch 5745/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122963320.0000 - mae: 8100.2783 - val_loss: 523587296.0000 - val_mae: 14004.3047\n",
      "Epoch 5746/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 123063072.0000 - mae: 8112.4487 - val_loss: 523155968.0000 - val_mae: 14020.7178\n",
      "Epoch 5747/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122566544.0000 - mae: 8083.8228 - val_loss: 523711808.0000 - val_mae: 14036.1699\n",
      "Epoch 5748/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122636032.0000 - mae: 8096.7358 - val_loss: 523968384.0000 - val_mae: 14009.3975\n",
      "Epoch 5749/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 122541680.0000 - mae: 8079.4893 - val_loss: 523841184.0000 - val_mae: 14048.6416\n",
      "Epoch 5750/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122838960.0000 - mae: 8093.0640 - val_loss: 525996064.0000 - val_mae: 14160.4463\n",
      "Epoch 5751/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 123567800.0000 - mae: 8138.0073 - val_loss: 525688544.0000 - val_mae: 14158.1611\n",
      "Epoch 5752/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122977928.0000 - mae: 8093.2642 - val_loss: 523406400.0000 - val_mae: 14030.0752\n",
      "Epoch 5753/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122706352.0000 - mae: 8092.0337 - val_loss: 523893280.0000 - val_mae: 14054.3496\n",
      "Epoch 5754/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 122455328.0000 - mae: 8090.9819 - val_loss: 523442048.0000 - val_mae: 14032.3779\n",
      "Epoch 5755/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122727952.0000 - mae: 8084.4341 - val_loss: 523319872.0000 - val_mae: 14007.7969\n",
      "Epoch 5756/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 123007464.0000 - mae: 8099.2070 - val_loss: 523634016.0000 - val_mae: 14043.2061\n",
      "Epoch 5757/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122414968.0000 - mae: 8082.8906 - val_loss: 523627552.0000 - val_mae: 14035.7920\n",
      "Epoch 5758/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 123054128.0000 - mae: 8112.5459 - val_loss: 524600320.0000 - val_mae: 14103.9883\n",
      "Epoch 5759/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122413720.0000 - mae: 8082.8242 - val_loss: 523702624.0000 - val_mae: 14053.1523\n",
      "Epoch 5760/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 123065944.0000 - mae: 8102.3115 - val_loss: 525508160.0000 - val_mae: 14147.3770\n",
      "Epoch 5761/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122611624.0000 - mae: 8127.6060 - val_loss: 523704512.0000 - val_mae: 13989.3789\n",
      "Epoch 5762/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122717472.0000 - mae: 8090.3037 - val_loss: 524211328.0000 - val_mae: 14076.4688\n",
      "Epoch 5763/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 122585800.0000 - mae: 8108.1060 - val_loss: 523435712.0000 - val_mae: 13986.7910\n",
      "Epoch 5764/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122952488.0000 - mae: 8114.0552 - val_loss: 523512832.0000 - val_mae: 13986.6006\n",
      "Epoch 5765/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 122724944.0000 - mae: 8113.5635 - val_loss: 525836096.0000 - val_mae: 14155.6719\n",
      "Epoch 5766/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122491280.0000 - mae: 8080.2656 - val_loss: 523749152.0000 - val_mae: 14061.4795\n",
      "Epoch 5767/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122369544.0000 - mae: 8084.7100 - val_loss: 523861728.0000 - val_mae: 14015.3682\n",
      "Epoch 5768/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122786584.0000 - mae: 8096.0029 - val_loss: 523676064.0000 - val_mae: 14056.4932\n",
      "Epoch 5769/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122586280.0000 - mae: 8084.8408 - val_loss: 523567456.0000 - val_mae: 13996.3066\n",
      "Epoch 5770/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122353640.0000 - mae: 8097.6738 - val_loss: 523382432.0000 - val_mae: 14030.5049\n",
      "Epoch 5771/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122063336.0000 - mae: 8072.9258 - val_loss: 523821632.0000 - val_mae: 14016.7002\n",
      "Epoch 5772/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122344528.0000 - mae: 8087.1543 - val_loss: 523431520.0000 - val_mae: 14042.6162\n",
      "Epoch 5773/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122116104.0000 - mae: 8085.3721 - val_loss: 523850208.0000 - val_mae: 13968.9346\n",
      "Epoch 5774/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122434280.0000 - mae: 8087.0396 - val_loss: 523824832.0000 - val_mae: 14076.5469\n",
      "Epoch 5775/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 123057864.0000 - mae: 8104.2124 - val_loss: 523556320.0000 - val_mae: 14031.2119\n",
      "Epoch 5776/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122364528.0000 - mae: 8088.2446 - val_loss: 523434656.0000 - val_mae: 14034.4502\n",
      "Epoch 5777/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122214000.0000 - mae: 8075.5508 - val_loss: 523845024.0000 - val_mae: 13972.9482\n",
      "Epoch 5778/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122281032.0000 - mae: 8103.0850 - val_loss: 523905760.0000 - val_mae: 14051.9639\n",
      "Epoch 5779/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122282888.0000 - mae: 8067.1484 - val_loss: 524242880.0000 - val_mae: 14086.5156\n",
      "Epoch 5780/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122152448.0000 - mae: 8082.7471 - val_loss: 523701664.0000 - val_mae: 14034.9688\n",
      "Epoch 5781/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 122225792.0000 - mae: 8077.4941 - val_loss: 524226336.0000 - val_mae: 14078.2490\n",
      "Epoch 5782/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122006848.0000 - mae: 8066.3242 - val_loss: 523082528.0000 - val_mae: 14019.2109\n",
      "Epoch 5783/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 122032552.0000 - mae: 8070.2568 - val_loss: 524539520.0000 - val_mae: 14074.8545\n",
      "Epoch 5784/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122081264.0000 - mae: 8081.0806 - val_loss: 524037664.0000 - val_mae: 14078.7725\n",
      "Epoch 5785/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 121994720.0000 - mae: 8089.3652 - val_loss: 524259584.0000 - val_mae: 13985.5244\n",
      "Epoch 5786/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 122031936.0000 - mae: 8067.6113 - val_loss: 524833632.0000 - val_mae: 14106.3271\n",
      "Epoch 5787/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122443920.0000 - mae: 8093.2349 - val_loss: 523487040.0000 - val_mae: 14042.5117\n",
      "Epoch 5788/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 122255656.0000 - mae: 8073.3491 - val_loss: 523707008.0000 - val_mae: 14050.2949\n",
      "Epoch 5789/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 121931216.0000 - mae: 8074.6392 - val_loss: 523111808.0000 - val_mae: 13975.4658\n",
      "Epoch 5790/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 122308176.0000 - mae: 8073.7368 - val_loss: 523822144.0000 - val_mae: 14069.1709\n",
      "Epoch 5791/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 122439632.0000 - mae: 8092.6523 - val_loss: 524349664.0000 - val_mae: 14030.6221\n",
      "Epoch 5792/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122422040.0000 - mae: 8094.6489 - val_loss: 525140992.0000 - val_mae: 14149.1074\n",
      "Epoch 5793/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 121947568.0000 - mae: 8076.4258 - val_loss: 525121760.0000 - val_mae: 14139.8447\n",
      "Epoch 5794/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 122776992.0000 - mae: 8124.6133 - val_loss: 523214880.0000 - val_mae: 14034.2285\n",
      "Epoch 5795/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122698904.0000 - mae: 8114.4668 - val_loss: 523696960.0000 - val_mae: 14066.4678\n",
      "Epoch 5796/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 123018304.0000 - mae: 8146.1211 - val_loss: 523757792.0000 - val_mae: 13984.3623\n",
      "Epoch 5797/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122158744.0000 - mae: 8087.9893 - val_loss: 523208608.0000 - val_mae: 14035.7275\n",
      "Epoch 5798/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122739272.0000 - mae: 8115.8643 - val_loss: 523987584.0000 - val_mae: 13969.9092\n",
      "Epoch 5799/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 121690376.0000 - mae: 8077.4199 - val_loss: 523924928.0000 - val_mae: 14061.0859\n",
      "Epoch 5800/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 122092048.0000 - mae: 8074.8862 - val_loss: 523858144.0000 - val_mae: 14032.9229\n",
      "Epoch 5801/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 121972600.0000 - mae: 8083.9209 - val_loss: 524669568.0000 - val_mae: 14135.9150\n",
      "Epoch 5802/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 121652432.0000 - mae: 8053.3477 - val_loss: 523948608.0000 - val_mae: 14042.5215\n",
      "Epoch 5803/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122042464.0000 - mae: 8079.5034 - val_loss: 525332128.0000 - val_mae: 14148.7861\n",
      "Epoch 5804/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 121558232.0000 - mae: 8054.5664 - val_loss: 523333440.0000 - val_mae: 13992.9297\n",
      "Epoch 5805/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122358968.0000 - mae: 8090.2480 - val_loss: 522676384.0000 - val_mae: 13988.8418\n",
      "Epoch 5806/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 121773704.0000 - mae: 8085.7192 - val_loss: 523664064.0000 - val_mae: 13994.3252\n",
      "Epoch 5807/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 121785512.0000 - mae: 8061.3618 - val_loss: 523810400.0000 - val_mae: 14035.2178\n",
      "Epoch 5808/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122078056.0000 - mae: 8103.3374 - val_loss: 525928320.0000 - val_mae: 14173.4980\n",
      "Epoch 5809/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 122965752.0000 - mae: 8133.5791 - val_loss: 523519712.0000 - val_mae: 14048.1318\n",
      "Epoch 5810/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 121956672.0000 - mae: 8073.4902 - val_loss: 523999424.0000 - val_mae: 14057.4854\n",
      "Epoch 5811/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 121839120.0000 - mae: 8069.3149 - val_loss: 523380416.0000 - val_mae: 14029.3975\n",
      "Epoch 5812/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 121847392.0000 - mae: 8060.1948 - val_loss: 524012000.0000 - val_mae: 14076.8896\n",
      "Epoch 5813/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 121327688.0000 - mae: 8100.9951 - val_loss: 525872064.0000 - val_mae: 13977.1885\n",
      "Epoch 5814/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 122145080.0000 - mae: 8124.3501 - val_loss: 524229248.0000 - val_mae: 14089.0117\n",
      "Epoch 5815/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 121632592.0000 - mae: 8056.4663 - val_loss: 523577568.0000 - val_mae: 14066.0303\n",
      "Epoch 5816/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 121912184.0000 - mae: 8084.6636 - val_loss: 523427296.0000 - val_mae: 13975.7686\n",
      "Epoch 5817/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 122457408.0000 - mae: 8103.9727 - val_loss: 523636160.0000 - val_mae: 13964.5879\n",
      "Epoch 5818/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 122302184.0000 - mae: 8109.2173 - val_loss: 524343744.0000 - val_mae: 14009.8799\n",
      "Epoch 5819/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 121775776.0000 - mae: 8056.1694 - val_loss: 523463808.0000 - val_mae: 14024.8301\n",
      "Epoch 5820/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 121297800.0000 - mae: 8046.5083 - val_loss: 524272480.0000 - val_mae: 14092.7871\n",
      "Epoch 5821/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 122135520.0000 - mae: 8096.0776 - val_loss: 523263712.0000 - val_mae: 13994.6377\n",
      "Epoch 5822/6000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 121994272.0000 - mae: 8098.8408 - val_loss: 523885696.0000 - val_mae: 13969.5547\n",
      "Epoch 5823/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122125312.0000 - mae: 8096.7964 - val_loss: 525148352.0000 - val_mae: 14151.8232\n",
      "Epoch 5824/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 122476488.0000 - mae: 8100.2139 - val_loss: 524100320.0000 - val_mae: 14085.7129\n",
      "Epoch 5825/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 121501560.0000 - mae: 8054.8691 - val_loss: 523554976.0000 - val_mae: 14090.3643\n",
      "Epoch 5826/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 122222896.0000 - mae: 8095.8628 - val_loss: 524383776.0000 - val_mae: 14100.9932\n",
      "Epoch 5827/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 123041280.0000 - mae: 8115.3115 - val_loss: 525142816.0000 - val_mae: 14142.8145\n",
      "Epoch 5828/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 121567072.0000 - mae: 8061.3003 - val_loss: 523301504.0000 - val_mae: 14050.5449\n",
      "Epoch 5829/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 121397688.0000 - mae: 8056.9150 - val_loss: 524547872.0000 - val_mae: 14104.1533\n",
      "Epoch 5830/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 121493624.0000 - mae: 8057.0591 - val_loss: 523479008.0000 - val_mae: 14071.5918\n",
      "Epoch 5831/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 121608416.0000 - mae: 8083.4849 - val_loss: 523792160.0000 - val_mae: 14007.2129\n",
      "Epoch 5832/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 121586856.0000 - mae: 8060.5713 - val_loss: 523404416.0000 - val_mae: 14020.9336\n",
      "Epoch 5833/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 121403208.0000 - mae: 8059.7935 - val_loss: 523388928.0000 - val_mae: 14006.7568\n",
      "Epoch 5834/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 121527112.0000 - mae: 8065.1177 - val_loss: 526013728.0000 - val_mae: 14202.1709\n",
      "Epoch 5835/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 122152944.0000 - mae: 8086.2920 - val_loss: 524561216.0000 - val_mae: 14139.6699\n",
      "Epoch 5836/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 121940576.0000 - mae: 8076.1436 - val_loss: 525337568.0000 - val_mae: 14162.4854\n",
      "Epoch 5837/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 121719432.0000 - mae: 8068.9551 - val_loss: 523949088.0000 - val_mae: 14084.7178\n",
      "Epoch 5838/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 121800968.0000 - mae: 8093.6611 - val_loss: 523305792.0000 - val_mae: 14011.5439\n",
      "Epoch 5839/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 121619496.0000 - mae: 8070.5073 - val_loss: 523701312.0000 - val_mae: 14072.9863\n",
      "Epoch 5840/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 121405344.0000 - mae: 8067.9819 - val_loss: 523531584.0000 - val_mae: 14061.6865\n",
      "Epoch 5841/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 121063576.0000 - mae: 8062.0850 - val_loss: 523767168.0000 - val_mae: 13991.6094\n",
      "Epoch 5842/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 121079032.0000 - mae: 8030.4907 - val_loss: 523789568.0000 - val_mae: 14075.4150\n",
      "Epoch 5843/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 121042536.0000 - mae: 8040.4370 - val_loss: 524340896.0000 - val_mae: 14089.6973\n",
      "Epoch 5844/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 121417304.0000 - mae: 8068.4604 - val_loss: 522896640.0000 - val_mae: 14016.6152\n",
      "Epoch 5845/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 121504224.0000 - mae: 8097.4448 - val_loss: 523372032.0000 - val_mae: 13978.4434\n",
      "Epoch 5846/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 121263072.0000 - mae: 8055.4932 - val_loss: 523530304.0000 - val_mae: 14044.1660\n",
      "Epoch 5847/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 121148512.0000 - mae: 8058.1167 - val_loss: 524032128.0000 - val_mae: 13982.1826\n",
      "Epoch 5848/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 121511104.0000 - mae: 8071.9297 - val_loss: 523575392.0000 - val_mae: 14006.9414\n",
      "Epoch 5849/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 121629264.0000 - mae: 8086.6445 - val_loss: 523374016.0000 - val_mae: 14024.6504\n",
      "Epoch 5850/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 122488680.0000 - mae: 8092.4731 - val_loss: 523217088.0000 - val_mae: 13987.3330\n",
      "Epoch 5851/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 121701960.0000 - mae: 8055.8086 - val_loss: 523283488.0000 - val_mae: 14011.9375\n",
      "Epoch 5852/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 120893392.0000 - mae: 8046.7827 - val_loss: 524014240.0000 - val_mae: 14092.6504\n",
      "Epoch 5853/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 121089440.0000 - mae: 8047.7529 - val_loss: 522788800.0000 - val_mae: 14032.5498\n",
      "Epoch 5854/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120936608.0000 - mae: 8033.0024 - val_loss: 526729152.0000 - val_mae: 14224.2695\n",
      "Epoch 5855/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 121728536.0000 - mae: 8091.5171 - val_loss: 524246560.0000 - val_mae: 14089.8818\n",
      "Epoch 5856/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 121737920.0000 - mae: 8069.6411 - val_loss: 524900192.0000 - val_mae: 14145.1406\n",
      "Epoch 5857/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 121137888.0000 - mae: 8050.0928 - val_loss: 523129088.0000 - val_mae: 14005.7988\n",
      "Epoch 5858/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 121273616.0000 - mae: 8052.7617 - val_loss: 523394816.0000 - val_mae: 14026.8896\n",
      "Epoch 5859/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 121686784.0000 - mae: 8091.0679 - val_loss: 523236448.0000 - val_mae: 14034.8936\n",
      "Epoch 5860/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120866888.0000 - mae: 8043.3970 - val_loss: 522962816.0000 - val_mae: 14036.3643\n",
      "Epoch 5861/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120649496.0000 - mae: 8037.3477 - val_loss: 523215872.0000 - val_mae: 14016.0352\n",
      "Epoch 5862/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 121873456.0000 - mae: 8098.2832 - val_loss: 522975456.0000 - val_mae: 14006.4893\n",
      "Epoch 5863/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120904200.0000 - mae: 8036.0527 - val_loss: 523893088.0000 - val_mae: 14095.5264\n",
      "Epoch 5864/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 120807792.0000 - mae: 8036.1104 - val_loss: 523212672.0000 - val_mae: 14054.1719\n",
      "Epoch 5865/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120681656.0000 - mae: 8035.5400 - val_loss: 522962016.0000 - val_mae: 14052.8936\n",
      "Epoch 5866/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 121036392.0000 - mae: 8063.0908 - val_loss: 523113824.0000 - val_mae: 13980.3193\n",
      "Epoch 5867/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120791176.0000 - mae: 8061.4624 - val_loss: 523325440.0000 - val_mae: 14030.0166\n",
      "Epoch 5868/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120679504.0000 - mae: 8043.3506 - val_loss: 523634016.0000 - val_mae: 14079.0244\n",
      "Epoch 5869/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120560256.0000 - mae: 8040.5054 - val_loss: 523287552.0000 - val_mae: 14012.0762\n",
      "Epoch 5870/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120906344.0000 - mae: 8036.1084 - val_loss: 523235936.0000 - val_mae: 14031.4355\n",
      "Epoch 5871/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120516056.0000 - mae: 8035.6367 - val_loss: 526573824.0000 - val_mae: 14219.9229\n",
      "Epoch 5872/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 122090632.0000 - mae: 8082.5625 - val_loss: 523804416.0000 - val_mae: 14090.7812\n",
      "Epoch 5873/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120739648.0000 - mae: 8048.7559 - val_loss: 523401056.0000 - val_mae: 14069.3486\n",
      "Epoch 5874/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120691992.0000 - mae: 8040.2300 - val_loss: 522639840.0000 - val_mae: 13983.3164\n",
      "Epoch 5875/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120884704.0000 - mae: 8042.5044 - val_loss: 523714880.0000 - val_mae: 14084.0352\n",
      "Epoch 5876/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120801456.0000 - mae: 8037.2124 - val_loss: 522634144.0000 - val_mae: 14007.1953\n",
      "Epoch 5877/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 120585448.0000 - mae: 8030.2832 - val_loss: 523582368.0000 - val_mae: 14090.0537\n",
      "Epoch 5878/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 121174536.0000 - mae: 8073.0029 - val_loss: 523328192.0000 - val_mae: 14064.9004\n",
      "Epoch 5879/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120812048.0000 - mae: 8071.6650 - val_loss: 523328640.0000 - val_mae: 13995.4531\n",
      "Epoch 5880/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 121833128.0000 - mae: 8073.9619 - val_loss: 522657728.0000 - val_mae: 14038.1328\n",
      "Epoch 5881/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 121051848.0000 - mae: 8069.6396 - val_loss: 523436256.0000 - val_mae: 14041.1699\n",
      "Epoch 5882/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 120734896.0000 - mae: 8030.6851 - val_loss: 522958880.0000 - val_mae: 14045.8906\n",
      "Epoch 5883/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120563664.0000 - mae: 8039.4302 - val_loss: 524269152.0000 - val_mae: 14120.3584\n",
      "Epoch 5884/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120600632.0000 - mae: 8034.0684 - val_loss: 523713568.0000 - val_mae: 14095.0000\n",
      "Epoch 5885/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120636064.0000 - mae: 8038.7622 - val_loss: 523043648.0000 - val_mae: 14064.5215\n",
      "Epoch 5886/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 120857272.0000 - mae: 8048.7075 - val_loss: 524004832.0000 - val_mae: 14126.1201\n",
      "Epoch 5887/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120541568.0000 - mae: 8028.2627 - val_loss: 524016096.0000 - val_mae: 14096.3936\n",
      "Epoch 5888/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120682072.0000 - mae: 8041.9165 - val_loss: 522834816.0000 - val_mae: 14054.4287\n",
      "Epoch 5889/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 121305448.0000 - mae: 8068.9980 - val_loss: 523167264.0000 - val_mae: 13976.4199\n",
      "Epoch 5890/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120734592.0000 - mae: 8042.7773 - val_loss: 523098368.0000 - val_mae: 14024.3301\n",
      "Epoch 5891/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120652528.0000 - mae: 8030.5903 - val_loss: 523303168.0000 - val_mae: 14071.5898\n",
      "Epoch 5892/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120743992.0000 - mae: 8029.7622 - val_loss: 524382272.0000 - val_mae: 14135.9834\n",
      "Epoch 5893/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 121216968.0000 - mae: 8091.7217 - val_loss: 524083072.0000 - val_mae: 14103.8281\n",
      "Epoch 5894/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120282552.0000 - mae: 8024.3491 - val_loss: 523104992.0000 - val_mae: 14038.4531\n",
      "Epoch 5895/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 121501584.0000 - mae: 8087.3965 - val_loss: 524845696.0000 - val_mae: 13961.1826\n",
      "Epoch 5896/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120507080.0000 - mae: 8033.3330 - val_loss: 522969696.0000 - val_mae: 14050.5371\n",
      "Epoch 5897/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120729800.0000 - mae: 8033.9297 - val_loss: 522979264.0000 - val_mae: 14011.2646\n",
      "Epoch 5898/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120127792.0000 - mae: 8012.0562 - val_loss: 524021728.0000 - val_mae: 14108.4463\n",
      "Epoch 5899/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120365040.0000 - mae: 8040.5640 - val_loss: 523870592.0000 - val_mae: 13986.1426\n",
      "Epoch 5900/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 121118024.0000 - mae: 8093.0894 - val_loss: 523407712.0000 - val_mae: 14066.4688\n",
      "Epoch 5901/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 121485360.0000 - mae: 8081.4463 - val_loss: 525251040.0000 - val_mae: 14184.7109\n",
      "Epoch 5902/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120627528.0000 - mae: 8024.8013 - val_loss: 523926496.0000 - val_mae: 14126.4404\n",
      "Epoch 5903/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120453416.0000 - mae: 8054.6006 - val_loss: 523152000.0000 - val_mae: 14027.3291\n",
      "Epoch 5904/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120527208.0000 - mae: 8075.8857 - val_loss: 523568704.0000 - val_mae: 13962.4629\n",
      "Epoch 5905/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120741392.0000 - mae: 8059.6094 - val_loss: 522766720.0000 - val_mae: 14046.6680\n",
      "Epoch 5906/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 120329976.0000 - mae: 8036.4941 - val_loss: 522920128.0000 - val_mae: 13999.8047\n",
      "Epoch 5907/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 121200696.0000 - mae: 8056.5093 - val_loss: 523359072.0000 - val_mae: 14007.5771\n",
      "Epoch 5908/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120058144.0000 - mae: 8016.3062 - val_loss: 523390560.0000 - val_mae: 14089.3643\n",
      "Epoch 5909/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120303992.0000 - mae: 8027.2046 - val_loss: 522956128.0000 - val_mae: 14065.8369\n",
      "Epoch 5910/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120343968.0000 - mae: 8028.1445 - val_loss: 523306592.0000 - val_mae: 14076.2832\n",
      "Epoch 5911/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120191696.0000 - mae: 8022.0532 - val_loss: 522991456.0000 - val_mae: 14070.4590\n",
      "Epoch 5912/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 120339664.0000 - mae: 8043.3481 - val_loss: 523221600.0000 - val_mae: 14015.4912\n",
      "Epoch 5913/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120253968.0000 - mae: 8029.0508 - val_loss: 523352000.0000 - val_mae: 14069.5518\n",
      "Epoch 5914/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 120097328.0000 - mae: 8029.7407 - val_loss: 523941088.0000 - val_mae: 14119.6484\n",
      "Epoch 5915/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120635624.0000 - mae: 8044.5376 - val_loss: 524697088.0000 - val_mae: 14179.2744\n",
      "Epoch 5916/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120428688.0000 - mae: 8033.2773 - val_loss: 523832736.0000 - val_mae: 14112.5322\n",
      "Epoch 5917/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120392640.0000 - mae: 8043.3325 - val_loss: 523124192.0000 - val_mae: 14086.6367\n",
      "Epoch 5918/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 119853336.0000 - mae: 8014.2856 - val_loss: 523145792.0000 - val_mae: 14040.7988\n",
      "Epoch 5919/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 119874400.0000 - mae: 8011.4048 - val_loss: 524750432.0000 - val_mae: 14165.4512\n",
      "Epoch 5920/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120645824.0000 - mae: 8044.5957 - val_loss: 522495680.0000 - val_mae: 14051.5918\n",
      "Epoch 5921/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120197656.0000 - mae: 8032.8960 - val_loss: 522491616.0000 - val_mae: 14044.6572\n",
      "Epoch 5922/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 119967728.0000 - mae: 8017.2749 - val_loss: 523320320.0000 - val_mae: 14084.6914\n",
      "Epoch 5923/6000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 119906288.0000 - mae: 8011.0386 - val_loss: 522700256.0000 - val_mae: 14070.9053\n",
      "Epoch 5924/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 119933224.0000 - mae: 8019.9858 - val_loss: 524085760.0000 - val_mae: 14137.5547\n",
      "Epoch 5925/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 120082072.0000 - mae: 8038.6509 - val_loss: 522648576.0000 - val_mae: 13974.2666\n",
      "Epoch 5926/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 120328064.0000 - mae: 8028.2695 - val_loss: 523188448.0000 - val_mae: 14091.8076\n",
      "Epoch 5927/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 120169768.0000 - mae: 8034.7856 - val_loss: 522631456.0000 - val_mae: 14037.2773\n",
      "Epoch 5928/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 119792072.0000 - mae: 8000.7661 - val_loss: 522654880.0000 - val_mae: 14002.4336\n",
      "Epoch 5929/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 120164544.0000 - mae: 8028.4395 - val_loss: 522620576.0000 - val_mae: 14031.2109\n",
      "Epoch 5930/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 119860176.0000 - mae: 8005.5737 - val_loss: 522530144.0000 - val_mae: 14040.4736\n",
      "Epoch 5931/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 119875488.0000 - mae: 8021.9502 - val_loss: 523319904.0000 - val_mae: 13959.1055\n",
      "Epoch 5932/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 121086856.0000 - mae: 8070.1499 - val_loss: 522541088.0000 - val_mae: 14038.0996\n",
      "Epoch 5933/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 119850992.0000 - mae: 8006.8955 - val_loss: 523473440.0000 - val_mae: 14107.5859\n",
      "Epoch 5934/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 120029128.0000 - mae: 8020.6440 - val_loss: 522499264.0000 - val_mae: 14006.5840\n",
      "Epoch 5935/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 119992576.0000 - mae: 8009.5513 - val_loss: 522394848.0000 - val_mae: 14051.5371\n",
      "Epoch 5936/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 119572392.0000 - mae: 8005.1006 - val_loss: 522838592.0000 - val_mae: 14078.6504\n",
      "Epoch 5937/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 119867536.0000 - mae: 8014.9336 - val_loss: 522780352.0000 - val_mae: 14089.6777\n",
      "Epoch 5938/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 120116240.0000 - mae: 8022.9121 - val_loss: 524148288.0000 - val_mae: 14151.9072\n",
      "Epoch 5939/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 120012920.0000 - mae: 8016.4409 - val_loss: 523163104.0000 - val_mae: 14097.7207\n",
      "Epoch 5940/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 119500888.0000 - mae: 8011.5322 - val_loss: 522234336.0000 - val_mae: 13999.2881\n",
      "Epoch 5941/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 119861512.0000 - mae: 8003.3291 - val_loss: 524357024.0000 - val_mae: 14157.1904\n",
      "Epoch 5942/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 119781976.0000 - mae: 8019.0938 - val_loss: 521832736.0000 - val_mae: 14036.9805\n",
      "Epoch 5943/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 119619392.0000 - mae: 7998.9351 - val_loss: 523121696.0000 - val_mae: 14091.2725\n",
      "Epoch 5944/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 120429976.0000 - mae: 8029.2329 - val_loss: 522174784.0000 - val_mae: 14020.4541\n",
      "Epoch 5945/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 119765688.0000 - mae: 8020.4600 - val_loss: 522536608.0000 - val_mae: 13976.5098\n",
      "Epoch 5946/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 120102072.0000 - mae: 8058.4111 - val_loss: 522658752.0000 - val_mae: 14039.7510\n",
      "Epoch 5947/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 119689592.0000 - mae: 8010.0610 - val_loss: 522815136.0000 - val_mae: 14084.6270\n",
      "Epoch 5948/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 119494632.0000 - mae: 7993.0815 - val_loss: 522402016.0000 - val_mae: 14051.7109\n",
      "Epoch 5949/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 119413424.0000 - mae: 7993.8228 - val_loss: 522586400.0000 - val_mae: 14055.4082\n",
      "Epoch 5950/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 119472056.0000 - mae: 7992.9165 - val_loss: 521716416.0000 - val_mae: 14028.6055\n",
      "Epoch 5951/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 119495536.0000 - mae: 8004.2876 - val_loss: 523129152.0000 - val_mae: 14108.7119\n",
      "Epoch 5952/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 119765560.0000 - mae: 8013.0762 - val_loss: 521932992.0000 - val_mae: 14035.5752\n",
      "Epoch 5953/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 119679952.0000 - mae: 8024.0303 - val_loss: 522004704.0000 - val_mae: 14016.2725\n",
      "Epoch 5954/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 119754312.0000 - mae: 8005.3643 - val_loss: 521488832.0000 - val_mae: 14048.6621\n",
      "Epoch 5955/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 119568064.0000 - mae: 8010.4771 - val_loss: 523104480.0000 - val_mae: 14115.1719\n",
      "Epoch 5956/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 119853640.0000 - mae: 8004.9375 - val_loss: 522998624.0000 - val_mae: 14119.6143\n",
      "Epoch 5957/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 119735648.0000 - mae: 8013.9546 - val_loss: 523084480.0000 - val_mae: 14085.5068\n",
      "Epoch 5958/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 119472016.0000 - mae: 8003.9058 - val_loss: 522240064.0000 - val_mae: 14076.5352\n",
      "Epoch 5959/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 119364352.0000 - mae: 7997.7681 - val_loss: 521610688.0000 - val_mae: 14021.0625\n",
      "Epoch 5960/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 119680304.0000 - mae: 8003.5229 - val_loss: 522411776.0000 - val_mae: 14070.6328\n",
      "Epoch 5961/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 121072744.0000 - mae: 8072.8374 - val_loss: 522279936.0000 - val_mae: 13991.3691\n",
      "Epoch 5962/6000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 119578904.0000 - mae: 8022.9409 - val_loss: 522184576.0000 - val_mae: 14034.9033\n",
      "Epoch 5963/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 120151720.0000 - mae: 8027.9790 - val_loss: 522231904.0000 - val_mae: 13964.9688\n",
      "Epoch 5964/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 119063184.0000 - mae: 7988.7178 - val_loss: 523275296.0000 - val_mae: 14126.1377\n",
      "Epoch 5965/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 119411424.0000 - mae: 8009.1572 - val_loss: 522249248.0000 - val_mae: 14022.0098\n",
      "Epoch 5966/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 119352304.0000 - mae: 7991.0488 - val_loss: 522050208.0000 - val_mae: 13975.9053\n",
      "Epoch 5967/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 119305640.0000 - mae: 7992.5615 - val_loss: 522671168.0000 - val_mae: 14109.8926\n",
      "Epoch 5968/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 119098032.0000 - mae: 7989.9707 - val_loss: 522380800.0000 - val_mae: 14037.1006\n",
      "Epoch 5969/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 119664400.0000 - mae: 8030.1494 - val_loss: 522313024.0000 - val_mae: 13999.8643\n",
      "Epoch 5970/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 119690576.0000 - mae: 8057.4492 - val_loss: 522605632.0000 - val_mae: 14095.7021\n",
      "Epoch 5971/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 119702208.0000 - mae: 8004.0068 - val_loss: 522297056.0000 - val_mae: 14087.7832\n",
      "Epoch 5972/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 119825656.0000 - mae: 8008.7559 - val_loss: 521861312.0000 - val_mae: 14046.8691\n",
      "Epoch 5973/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 119728896.0000 - mae: 8030.4019 - val_loss: 521906464.0000 - val_mae: 14063.0762\n",
      "Epoch 5974/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 119165680.0000 - mae: 7980.2324 - val_loss: 522214880.0000 - val_mae: 14097.9697\n",
      "Epoch 5975/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 119216304.0000 - mae: 7997.7139 - val_loss: 521998400.0000 - val_mae: 14045.8301\n",
      "Epoch 5976/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 119954448.0000 - mae: 8048.0059 - val_loss: 525169920.0000 - val_mae: 14226.8770\n",
      "Epoch 5977/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 119407288.0000 - mae: 7989.2529 - val_loss: 522101952.0000 - val_mae: 14083.0088\n",
      "Epoch 5978/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 119167200.0000 - mae: 7996.7573 - val_loss: 521222848.0000 - val_mae: 14039.5146\n",
      "Epoch 5979/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 119905112.0000 - mae: 8020.1499 - val_loss: 522818592.0000 - val_mae: 14126.7002\n",
      "Epoch 5980/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 119012808.0000 - mae: 7977.9419 - val_loss: 521625888.0000 - val_mae: 14078.2432\n",
      "Epoch 5981/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 119203856.0000 - mae: 7985.4272 - val_loss: 521589056.0000 - val_mae: 14068.0674\n",
      "Epoch 5982/6000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 119294048.0000 - mae: 7975.1436 - val_loss: 524865760.0000 - val_mae: 14227.0771\n",
      "Epoch 5983/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 119295184.0000 - mae: 8012.7041 - val_loss: 521060992.0000 - val_mae: 14050.4160\n",
      "Epoch 5984/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 118872928.0000 - mae: 7993.6475 - val_loss: 521600864.0000 - val_mae: 14021.5908\n",
      "Epoch 5985/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 119078120.0000 - mae: 7997.9663 - val_loss: 524997536.0000 - val_mae: 14226.4297\n",
      "Epoch 5986/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 119509416.0000 - mae: 8000.1304 - val_loss: 521152640.0000 - val_mae: 14044.8652\n",
      "Epoch 5987/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 119004240.0000 - mae: 8005.7217 - val_loss: 521564960.0000 - val_mae: 13982.6934\n",
      "Epoch 5988/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 119110352.0000 - mae: 7992.4497 - val_loss: 522390784.0000 - val_mae: 14110.5820\n",
      "Epoch 5989/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 118966944.0000 - mae: 7982.9438 - val_loss: 521486208.0000 - val_mae: 14047.2129\n",
      "Epoch 5990/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 118790960.0000 - mae: 7977.8452 - val_loss: 521378816.0000 - val_mae: 14041.0879\n",
      "Epoch 5991/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 118791648.0000 - mae: 7981.6797 - val_loss: 522303552.0000 - val_mae: 14123.4707\n",
      "Epoch 5992/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 119008864.0000 - mae: 7986.0308 - val_loss: 521918784.0000 - val_mae: 14010.1533\n",
      "Epoch 5993/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 119256848.0000 - mae: 7995.7070 - val_loss: 521153056.0000 - val_mae: 14048.3350\n",
      "Epoch 5994/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 118754208.0000 - mae: 7983.4141 - val_loss: 521618720.0000 - val_mae: 14066.0449\n",
      "Epoch 5995/6000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 119538576.0000 - mae: 7996.2520 - val_loss: 522279584.0000 - val_mae: 14120.0342\n",
      "Epoch 5996/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 119112648.0000 - mae: 7992.7192 - val_loss: 523002240.0000 - val_mae: 14162.0088\n",
      "Epoch 5997/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 118867952.0000 - mae: 7993.6372 - val_loss: 521178304.0000 - val_mae: 14044.5928\n",
      "Epoch 5998/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 119726936.0000 - mae: 8000.6992 - val_loss: 522031104.0000 - val_mae: 14085.1650\n",
      "Epoch 5999/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 119315784.0000 - mae: 8008.2510 - val_loss: 522804000.0000 - val_mae: 14140.0039\n",
      "Epoch 6000/6000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 118794400.0000 - mae: 7994.6445 - val_loss: 521490080.0000 - val_mae: 14071.5674\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=6000, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HUAHOA-q985e",
    "outputId": "bdb4a8da-7cbe-4336-d297-2f84006a8573"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step\n",
      "Mean Absolute Error: 14015.752931576402\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VFWPRv8iDYDE"
   },
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "71s4qMRlGeqK"
   },
   "outputs": [],
   "source": [
    "hist['epoch'] = history.epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "hcZG7VzVGvW1",
    "outputId": "74dcbaf4-d1d2-47ec-e235-59973a98c5b7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-3e2b2b07-fbe8-4697-b6f8-d7c9be14d927\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mae</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.758908e+10</td>\n",
       "      <td>177786.578125</td>\n",
       "      <td>3.606101e+10</td>\n",
       "      <td>177421.828125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.758062e+10</td>\n",
       "      <td>177763.421875</td>\n",
       "      <td>3.604423e+10</td>\n",
       "      <td>177375.828125</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.754921e+10</td>\n",
       "      <td>177678.203125</td>\n",
       "      <td>3.599292e+10</td>\n",
       "      <td>177234.937500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.747015e+10</td>\n",
       "      <td>177463.656250</td>\n",
       "      <td>3.587984e+10</td>\n",
       "      <td>176924.031250</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.731558e+10</td>\n",
       "      <td>177037.515625</td>\n",
       "      <td>3.567375e+10</td>\n",
       "      <td>176355.953125</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>2.387697e+08</td>\n",
       "      <td>10386.867188</td>\n",
       "      <td>4.677786e+08</td>\n",
       "      <td>12944.836914</td>\n",
       "      <td>2995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>2.389488e+08</td>\n",
       "      <td>10398.130859</td>\n",
       "      <td>4.682433e+08</td>\n",
       "      <td>12992.738281</td>\n",
       "      <td>2996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>2.386132e+08</td>\n",
       "      <td>10361.023438</td>\n",
       "      <td>4.686691e+08</td>\n",
       "      <td>12997.216797</td>\n",
       "      <td>2997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>2.389136e+08</td>\n",
       "      <td>10407.131836</td>\n",
       "      <td>4.677820e+08</td>\n",
       "      <td>12965.449219</td>\n",
       "      <td>2998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>2.387283e+08</td>\n",
       "      <td>10380.575195</td>\n",
       "      <td>4.706961e+08</td>\n",
       "      <td>13084.266602</td>\n",
       "      <td>2999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 5 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e2b2b07-fbe8-4697-b6f8-d7c9be14d927')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-3e2b2b07-fbe8-4697-b6f8-d7c9be14d927 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-3e2b2b07-fbe8-4697-b6f8-d7c9be14d927');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "              loss            mae      val_loss        val_mae  epoch\n",
       "0     3.758908e+10  177786.578125  3.606101e+10  177421.828125      0\n",
       "1     3.758062e+10  177763.421875  3.604423e+10  177375.828125      1\n",
       "2     3.754921e+10  177678.203125  3.599292e+10  177234.937500      2\n",
       "3     3.747015e+10  177463.656250  3.587984e+10  176924.031250      3\n",
       "4     3.731558e+10  177037.515625  3.567375e+10  176355.953125      4\n",
       "...            ...            ...           ...            ...    ...\n",
       "2995  2.387697e+08   10386.867188  4.677786e+08   12944.836914   2995\n",
       "2996  2.389488e+08   10398.130859  4.682433e+08   12992.738281   2996\n",
       "2997  2.386132e+08   10361.023438  4.686691e+08   12997.216797   2997\n",
       "2998  2.389136e+08   10407.131836  4.677820e+08   12965.449219   2998\n",
       "2999  2.387283e+08   10380.575195  4.706961e+08   13084.266602   2999\n",
       "\n",
       "[3000 rows x 5 columns]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 491
    },
    "id": "eSSXVAxLGw2Y",
    "outputId": "8b1a50a5-a209-4c56-8c70-002671e96851"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Training History of Deep Learning')"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Abs Error')\n",
    "plt.plot(hist['epoch'],hist['mae'],label='Train Error')\n",
    "plt.plot(hist['epoch'],hist['val_mae'],label='Val Error')\n",
    "plt.legend()\n",
    "plt.title(\"Training History of Deep Learning\", fontsize=16, fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "250rqbzNGmJi"
   },
   "outputs": [],
   "source": [
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gcwElEI8gpZG"
   },
   "outputs": [],
   "source": [
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sgXmiEqZhM63"
   },
   "outputs": [],
   "source": [
    "df = df[['YearBuilt','2ndFlrSF','GrLivArea','FullBath','HalfBath','BedroomAbvGr','TotRmsAbvGrd','YrSold','SalePrice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "zupT9Ze5hZXI",
    "outputId": "0221f963-7356-4d05-c244-d3079fdda5a8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-9ff31d4e-0782-4951-9759-c15944acd913\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1939</td>\n",
       "      <td>0</td>\n",
       "      <td>856</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>126000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1984</td>\n",
       "      <td>0</td>\n",
       "      <td>1049</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2009</td>\n",
       "      <td>139500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1930</td>\n",
       "      <td>0</td>\n",
       "      <td>1001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>124900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1900</td>\n",
       "      <td>322</td>\n",
       "      <td>1039</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2009</td>\n",
       "      <td>114000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001</td>\n",
       "      <td>855</td>\n",
       "      <td>1665</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2009</td>\n",
       "      <td>227000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577</th>\n",
       "      <td>1916</td>\n",
       "      <td>0</td>\n",
       "      <td>952</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2009</td>\n",
       "      <td>121000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2578</th>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>1733</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "      <td>139600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2579</th>\n",
       "      <td>1949</td>\n",
       "      <td>1001</td>\n",
       "      <td>2002</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2580</th>\n",
       "      <td>2000</td>\n",
       "      <td>857</td>\n",
       "      <td>1842</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2007</td>\n",
       "      <td>217500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2581</th>\n",
       "      <td>1993</td>\n",
       "      <td>846</td>\n",
       "      <td>1911</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2006</td>\n",
       "      <td>215000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2582 rows × 9 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ff31d4e-0782-4951-9759-c15944acd913')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-9ff31d4e-0782-4951-9759-c15944acd913 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-9ff31d4e-0782-4951-9759-c15944acd913');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      YearBuilt  2ndFlrSF  GrLivArea  FullBath  HalfBath  BedroomAbvGr  \\\n",
       "0          1939         0        856         1         0             2   \n",
       "1          1984         0       1049         2         0             2   \n",
       "2          1930         0       1001         1         0             2   \n",
       "3          1900       322       1039         1         0             2   \n",
       "4          2001       855       1665         2         1             3   \n",
       "...         ...       ...        ...       ...       ...           ...   \n",
       "2577       1916         0        952         1         0             2   \n",
       "2578       1955         0       1733         2         0             4   \n",
       "2579       1949      1001       2002         2         0             4   \n",
       "2580       2000       857       1842         2         1             3   \n",
       "2581       1993       846       1911         2         1             3   \n",
       "\n",
       "      TotRmsAbvGrd  YrSold  SalePrice  \n",
       "0                4    2010     126000  \n",
       "1                5    2009     139500  \n",
       "2                5    2007     124900  \n",
       "3                6    2009     114000  \n",
       "4                6    2009     227000  \n",
       "...            ...     ...        ...  \n",
       "2577             4    2009     121000  \n",
       "2578             8    2009     139600  \n",
       "2579             8    2007     145000  \n",
       "2580             7    2007     217500  \n",
       "2581             8    2006     215000  \n",
       "\n",
       "[2582 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "wcTWfMVWqlsc",
    "outputId": "8334172c-83bc-47b8-c63e-1dc031d4efe8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-6c9669f1-e424-41dc-8e5e-80edb060779f\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2582.000000</td>\n",
       "      <td>2582.000000</td>\n",
       "      <td>2582.000000</td>\n",
       "      <td>2582.000000</td>\n",
       "      <td>2582.000000</td>\n",
       "      <td>2582.000000</td>\n",
       "      <td>2582.000000</td>\n",
       "      <td>2582.000000</td>\n",
       "      <td>2582.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1970.290473</td>\n",
       "      <td>337.017816</td>\n",
       "      <td>1486.218823</td>\n",
       "      <td>1.550349</td>\n",
       "      <td>0.378776</td>\n",
       "      <td>2.849729</td>\n",
       "      <td>6.387684</td>\n",
       "      <td>2007.836948</td>\n",
       "      <td>178071.970565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>29.720160</td>\n",
       "      <td>423.967580</td>\n",
       "      <td>488.503095</td>\n",
       "      <td>0.545829</td>\n",
       "      <td>0.499344</td>\n",
       "      <td>0.822884</td>\n",
       "      <td>1.534686</td>\n",
       "      <td>1.312822</td>\n",
       "      <td>75003.324773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1872.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>334.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>12789.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1953.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1112.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>130000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1972.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1436.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>159900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1999.000000</td>\n",
       "      <td>702.750000</td>\n",
       "      <td>1733.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>209500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>4676.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>755000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c9669f1-e424-41dc-8e5e-80edb060779f')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-6c9669f1-e424-41dc-8e5e-80edb060779f button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-6c9669f1-e424-41dc-8e5e-80edb060779f');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "         YearBuilt     2ndFlrSF    GrLivArea     FullBath     HalfBath  \\\n",
       "count  2582.000000  2582.000000  2582.000000  2582.000000  2582.000000   \n",
       "mean   1970.290473   337.017816  1486.218823     1.550349     0.378776   \n",
       "std      29.720160   423.967580   488.503095     0.545829     0.499344   \n",
       "min    1872.000000     0.000000   334.000000     0.000000     0.000000   \n",
       "25%    1953.000000     0.000000  1112.000000     1.000000     0.000000   \n",
       "50%    1972.000000     0.000000  1436.000000     2.000000     0.000000   \n",
       "75%    1999.000000   702.750000  1733.000000     2.000000     1.000000   \n",
       "max    2010.000000  1872.000000  4676.000000     4.000000     2.000000   \n",
       "\n",
       "       BedroomAbvGr  TotRmsAbvGrd       YrSold      SalePrice  \n",
       "count   2582.000000   2582.000000  2582.000000    2582.000000  \n",
       "mean       2.849729      6.387684  2007.836948  178071.970565  \n",
       "std        0.822884      1.534686     1.312822   75003.324773  \n",
       "min        0.000000      2.000000  2006.000000   12789.000000  \n",
       "25%        2.000000      5.000000  2007.000000  130000.000000  \n",
       "50%        3.000000      6.000000  2008.000000  159900.000000  \n",
       "75%        3.000000      7.000000  2009.000000  209500.000000  \n",
       "max        6.000000     13.000000  2010.000000  755000.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SSCfq7rRkZ24"
   },
   "outputs": [],
   "source": [
    "X = df.drop('SalePrice', axis=1)\n",
    "y = df['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zu7UG4gIksgu"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BLbzQsW4kvwb"
   },
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CDhK63u4ooo9",
    "outputId": "0c79e082-98fd-4f72-f0ac-07b21a1c6389"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.87681159, 0.        , 0.19714417, ..., 0.5       , 0.36363636,\n",
       "        0.75      ],\n",
       "       [0.92028986, 0.60042735, 0.43298019, ..., 0.5       , 0.54545455,\n",
       "        0.        ],\n",
       "       [0.39130435, 0.        , 0.13127591, ..., 0.33333333, 0.18181818,\n",
       "        0.75      ],\n",
       "       ...,\n",
       "       [0.97101449, 0.45405983, 0.25886688, ..., 0.5       , 0.36363636,\n",
       "        0.25      ],\n",
       "       [0.94202899, 0.        , 0.26715799, ..., 0.5       , 0.36363636,\n",
       "        0.5       ],\n",
       "       [0.95652174, 0.        , 0.3021649 , ..., 0.33333333, 0.27272727,\n",
       "        0.5       ]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JxPbt5R8lFY2"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(8, activation='relu', input_shape=(8,)))\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1))\n",
    "\n",
    "learning_rate = 0.01\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_logarithmic_error',metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7UBXjiglmSgW",
    "outputId": "28d6ac28-efde-423d-a948-bc8cafa94a04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 4.1273 - mae: 155192.4062 - val_loss: 4.0741 - val_mae: 154349.0000\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 4.0501 - mae: 154750.6406 - val_loss: 3.9975 - val_mae: 153900.5156\n",
      "Epoch 3/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.9743 - mae: 154305.9531 - val_loss: 3.9224 - val_mae: 153447.5469\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.9000 - mae: 153855.2031 - val_loss: 3.8487 - val_mae: 152990.4219\n",
      "Epoch 5/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.8270 - mae: 153401.6719 - val_loss: 3.7764 - val_mae: 152528.7344\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.7554 - mae: 152943.1719 - val_loss: 3.7054 - val_mae: 152062.2188\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.6850 - mae: 152480.7812 - val_loss: 3.6356 - val_mae: 151590.5000\n",
      "Epoch 8/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 3.6159 - mae: 152012.2500 - val_loss: 3.5673 - val_mae: 151115.6719\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.5482 - mae: 151540.0938 - val_loss: 3.4999 - val_mae: 150634.2812\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.4816 - mae: 151062.2812 - val_loss: 3.4339 - val_mae: 150149.2969\n",
      "Epoch 11/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.4162 - mae: 150581.0312 - val_loss: 3.3691 - val_mae: 149659.7656\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.3519 - mae: 150097.3750 - val_loss: 3.3055 - val_mae: 149166.7344\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.2889 - mae: 149604.1719 - val_loss: 3.2429 - val_mae: 148666.8594\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.2269 - mae: 149109.1250 - val_loss: 3.1814 - val_mae: 148163.0625\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.1660 - mae: 148610.0312 - val_loss: 3.1212 - val_mae: 147655.5625\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.1063 - mae: 148105.8438 - val_loss: 3.0619 - val_mae: 147142.6094\n",
      "Epoch 17/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.0476 - mae: 147595.8125 - val_loss: 3.0036 - val_mae: 146624.5938\n",
      "Epoch 18/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 2.9899 - mae: 147082.7031 - val_loss: 2.9464 - val_mae: 146102.4062\n",
      "Epoch 19/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 2.9332 - mae: 146563.5469 - val_loss: 2.8902 - val_mae: 145575.7656\n",
      "Epoch 20/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 2.8776 - mae: 146040.6719 - val_loss: 2.8349 - val_mae: 145043.4062\n",
      "Epoch 21/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 2.8229 - mae: 145514.7500 - val_loss: 2.7808 - val_mae: 144508.5469\n",
      "Epoch 22/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 2.7692 - mae: 144982.4844 - val_loss: 2.7275 - val_mae: 143967.0938\n",
      "Epoch 23/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 2.7164 - mae: 144446.1719 - val_loss: 2.6751 - val_mae: 143421.5938\n",
      "Epoch 24/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 2.6646 - mae: 143904.8594 - val_loss: 2.6238 - val_mae: 142872.2656\n",
      "Epoch 25/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 2.6136 - mae: 143358.6406 - val_loss: 2.5732 - val_mae: 142317.4688\n",
      "Epoch 26/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 2.5636 - mae: 142808.5938 - val_loss: 2.5235 - val_mae: 141757.7500\n",
      "Epoch 27/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 2.5144 - mae: 142253.8125 - val_loss: 2.4748 - val_mae: 141195.0625\n",
      "Epoch 28/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 2.4661 - mae: 141694.5469 - val_loss: 2.4269 - val_mae: 140626.9688\n",
      "Epoch 29/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 2.4186 - mae: 141131.2344 - val_loss: 2.3798 - val_mae: 140053.7812\n",
      "Epoch 30/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 2.3720 - mae: 140562.4062 - val_loss: 2.3335 - val_mae: 139475.4844\n",
      "Epoch 31/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 2.3261 - mae: 139988.6719 - val_loss: 2.2880 - val_mae: 138892.3906\n",
      "Epoch 32/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 2.2811 - mae: 139408.9375 - val_loss: 2.2432 - val_mae: 138304.9844\n",
      "Epoch 33/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 2.2367 - mae: 138828.9062 - val_loss: 2.1994 - val_mae: 137714.4062\n",
      "Epoch 34/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 2.1933 - mae: 138242.7969 - val_loss: 2.1562 - val_mae: 137118.3281\n",
      "Epoch 35/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 2.1506 - mae: 137652.8438 - val_loss: 2.1138 - val_mae: 136516.8750\n",
      "Epoch 36/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 2.1085 - mae: 137055.2812 - val_loss: 2.0721 - val_mae: 135912.1875\n",
      "Epoch 37/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 2.0673 - mae: 136456.9844 - val_loss: 2.0312 - val_mae: 135302.7812\n",
      "Epoch 38/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 2.0267 - mae: 135851.3281 - val_loss: 1.9911 - val_mae: 134690.0781\n",
      "Epoch 39/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 1.9869 - mae: 135243.0156 - val_loss: 1.9516 - val_mae: 134071.1094\n",
      "Epoch 40/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 1.9477 - mae: 134627.7656 - val_loss: 1.9126 - val_mae: 133446.7969\n",
      "Epoch 41/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 1.9092 - mae: 134008.9375 - val_loss: 1.8745 - val_mae: 132818.8906\n",
      "Epoch 42/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 1.8714 - mae: 133387.3438 - val_loss: 1.8370 - val_mae: 132187.7344\n",
      "Epoch 43/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 1.8343 - mae: 132761.4062 - val_loss: 1.8001 - val_mae: 131549.9219\n",
      "Epoch 44/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 1.7978 - mae: 132129.8594 - val_loss: 1.7640 - val_mae: 130910.7734\n",
      "Epoch 45/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 1.7619 - mae: 131494.2812 - val_loss: 1.7284 - val_mae: 130268.0078\n",
      "Epoch 46/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 1.7267 - mae: 130853.0078 - val_loss: 1.6933 - val_mae: 129618.7109\n",
      "Epoch 47/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 1.6921 - mae: 130206.5156 - val_loss: 1.6589 - val_mae: 128966.2109\n",
      "Epoch 48/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 1.6580 - mae: 129558.7344 - val_loss: 1.6253 - val_mae: 128311.5078\n",
      "Epoch 49/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 1.6247 - mae: 128908.3906 - val_loss: 1.5922 - val_mae: 127652.2969\n",
      "Epoch 50/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 1.5919 - mae: 128250.8125 - val_loss: 1.5596 - val_mae: 126987.6250\n",
      "Epoch 51/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 1.5596 - mae: 127590.7891 - val_loss: 1.5277 - val_mae: 126319.9453\n",
      "Epoch 52/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 1.5280 - mae: 126925.4922 - val_loss: 1.4962 - val_mae: 125645.0938\n",
      "Epoch 53/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 1.4968 - mae: 126256.0547 - val_loss: 1.4653 - val_mae: 124968.7344\n",
      "Epoch 54/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 1.4662 - mae: 125584.6016 - val_loss: 1.4351 - val_mae: 124288.8516\n",
      "Epoch 55/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 1.4363 - mae: 124905.0625 - val_loss: 1.4052 - val_mae: 123601.2656\n",
      "Epoch 56/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 1.4067 - mae: 124222.2969 - val_loss: 1.3760 - val_mae: 122913.5703\n",
      "Epoch 57/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 1.3778 - mae: 123538.5156 - val_loss: 1.3472 - val_mae: 122218.6797\n",
      "Epoch 58/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 1.3494 - mae: 122846.8828 - val_loss: 1.3190 - val_mae: 121520.6172\n",
      "Epoch 59/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 1.3214 - mae: 122153.4141 - val_loss: 1.2913 - val_mae: 120819.1641\n",
      "Epoch 60/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 1.2940 - mae: 121454.4141 - val_loss: 1.2641 - val_mae: 120112.0391\n",
      "Epoch 61/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 1.2670 - mae: 120754.4219 - val_loss: 1.2374 - val_mae: 119405.3047\n",
      "Epoch 62/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 1.2407 - mae: 120049.4141 - val_loss: 1.2112 - val_mae: 118690.0625\n",
      "Epoch 63/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 1.2147 - mae: 119339.6406 - val_loss: 1.1854 - val_mae: 117973.1172\n",
      "Epoch 64/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 1.1892 - mae: 118626.7031 - val_loss: 1.1602 - val_mae: 117252.8359\n",
      "Epoch 65/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 1.1641 - mae: 117911.6250 - val_loss: 1.1353 - val_mae: 116528.0156\n",
      "Epoch 66/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 1.1396 - mae: 117192.7656 - val_loss: 1.1109 - val_mae: 115798.8203\n",
      "Epoch 67/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 1.1155 - mae: 116467.4062 - val_loss: 1.0870 - val_mae: 115066.9219\n",
      "Epoch 68/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 1.0918 - mae: 115740.8828 - val_loss: 1.0635 - val_mae: 114330.4375\n",
      "Epoch 69/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 1.0685 - mae: 115012.5312 - val_loss: 1.0405 - val_mae: 113592.7188\n",
      "Epoch 70/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 1.0458 - mae: 114281.1719 - val_loss: 1.0178 - val_mae: 112847.0859\n",
      "Epoch 71/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 1.0233 - mae: 113542.0234 - val_loss: 0.9957 - val_mae: 112102.0625\n",
      "Epoch 72/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 1.0014 - mae: 112801.3828 - val_loss: 0.9739 - val_mae: 111352.2734\n",
      "Epoch 73/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.9799 - mae: 112058.8281 - val_loss: 0.9525 - val_mae: 110597.6484\n",
      "Epoch 74/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.9587 - mae: 111310.4531 - val_loss: 0.9315 - val_mae: 109839.5469\n",
      "Epoch 75/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.9379 - mae: 110563.0391 - val_loss: 0.9110 - val_mae: 109080.8516\n",
      "Epoch 76/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.9176 - mae: 109812.3281 - val_loss: 0.8908 - val_mae: 108316.6172\n",
      "Epoch 77/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.8976 - mae: 109056.8906 - val_loss: 0.8710 - val_mae: 107550.6641\n",
      "Epoch 78/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.8780 - mae: 108300.3281 - val_loss: 0.8516 - val_mae: 106781.5000\n",
      "Epoch 79/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.8589 - mae: 107537.7891 - val_loss: 0.8325 - val_mae: 106006.3906\n",
      "Epoch 80/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.8400 - mae: 106775.3047 - val_loss: 0.8138 - val_mae: 105231.7500\n",
      "Epoch 81/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.8215 - mae: 106010.5781 - val_loss: 0.7955 - val_mae: 104453.8281\n",
      "Epoch 82/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.8034 - mae: 105246.0703 - val_loss: 0.7775 - val_mae: 103671.3281\n",
      "Epoch 83/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.7857 - mae: 104473.9297 - val_loss: 0.7599 - val_mae: 102887.5469\n",
      "Epoch 84/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.7682 - mae: 103708.3750 - val_loss: 0.7427 - val_mae: 102103.0547\n",
      "Epoch 85/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.7512 - mae: 102937.7422 - val_loss: 0.7258 - val_mae: 101318.6641\n",
      "Epoch 86/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.7345 - mae: 102158.0625 - val_loss: 0.7091 - val_mae: 100529.9141\n",
      "Epoch 87/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.7181 - mae: 101389.8203 - val_loss: 0.6929 - val_mae: 99739.2422\n",
      "Epoch 88/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.7020 - mae: 100613.4531 - val_loss: 0.6770 - val_mae: 98949.0938\n",
      "Epoch 89/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6863 - mae: 99839.2266 - val_loss: 0.6614 - val_mae: 98155.8047\n",
      "Epoch 90/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6708 - mae: 99064.2500 - val_loss: 0.6462 - val_mae: 97363.8438\n",
      "Epoch 91/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6558 - mae: 98285.6953 - val_loss: 0.6312 - val_mae: 96564.6172\n",
      "Epoch 92/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6410 - mae: 97505.0547 - val_loss: 0.6164 - val_mae: 95761.9531\n",
      "Epoch 93/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6265 - mae: 96722.3047 - val_loss: 0.6021 - val_mae: 94962.6328\n",
      "Epoch 94/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6123 - mae: 95943.2344 - val_loss: 0.5881 - val_mae: 94168.0156\n",
      "Epoch 95/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5985 - mae: 95164.4062 - val_loss: 0.5742 - val_mae: 93359.2734\n",
      "Epoch 96/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5848 - mae: 94379.3672 - val_loss: 0.5608 - val_mae: 92560.2344\n",
      "Epoch 97/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5715 - mae: 93598.7344 - val_loss: 0.5476 - val_mae: 91754.5156\n",
      "Epoch 98/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5585 - mae: 92813.8125 - val_loss: 0.5347 - val_mae: 90952.0078\n",
      "Epoch 99/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5457 - mae: 92026.8828 - val_loss: 0.5220 - val_mae: 90143.7656\n",
      "Epoch 100/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5333 - mae: 91240.9297 - val_loss: 0.5096 - val_mae: 89336.8125\n",
      "Epoch 101/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5210 - mae: 90459.5547 - val_loss: 0.4976 - val_mae: 88540.2266\n",
      "Epoch 102/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5091 - mae: 89682.2109 - val_loss: 0.4857 - val_mae: 87739.0391\n",
      "Epoch 103/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4974 - mae: 88906.4609 - val_loss: 0.4741 - val_mae: 86935.7109\n",
      "Epoch 104/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4860 - mae: 88128.7969 - val_loss: 0.4628 - val_mae: 86134.5781\n",
      "Epoch 105/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4748 - mae: 87351.2266 - val_loss: 0.4517 - val_mae: 85328.7578\n",
      "Epoch 106/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4639 - mae: 86585.0469 - val_loss: 0.4409 - val_mae: 84523.7266\n",
      "Epoch 107/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4532 - mae: 85809.6953 - val_loss: 0.4304 - val_mae: 83719.9297\n",
      "Epoch 108/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4428 - mae: 85039.7500 - val_loss: 0.4200 - val_mae: 82911.4375\n",
      "Epoch 109/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4326 - mae: 84266.0547 - val_loss: 0.4100 - val_mae: 82110.7109\n",
      "Epoch 110/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4226 - mae: 83505.5078 - val_loss: 0.4001 - val_mae: 81310.6797\n",
      "Epoch 111/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4129 - mae: 82740.6875 - val_loss: 0.3904 - val_mae: 80497.8516\n",
      "Epoch 112/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4034 - mae: 81975.0703 - val_loss: 0.3810 - val_mae: 79700.7188\n",
      "Epoch 113/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3941 - mae: 81215.3828 - val_loss: 0.3718 - val_mae: 78900.3594\n",
      "Epoch 114/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3850 - mae: 80454.5938 - val_loss: 0.3628 - val_mae: 78107.0156\n",
      "Epoch 115/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3762 - mae: 79706.1250 - val_loss: 0.3541 - val_mae: 77321.8828\n",
      "Epoch 116/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3676 - mae: 78968.0703 - val_loss: 0.3455 - val_mae: 76531.6016\n",
      "Epoch 117/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3591 - mae: 78221.0625 - val_loss: 0.3372 - val_mae: 75749.5781\n",
      "Epoch 118/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3509 - mae: 77484.2109 - val_loss: 0.3290 - val_mae: 74966.3125\n",
      "Epoch 119/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3429 - mae: 76752.1094 - val_loss: 0.3211 - val_mae: 74189.3125\n",
      "Epoch 120/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3351 - mae: 76018.3516 - val_loss: 0.3133 - val_mae: 73411.1641\n",
      "Epoch 121/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3274 - mae: 75292.8984 - val_loss: 0.3058 - val_mae: 72637.9766\n",
      "Epoch 122/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3200 - mae: 74558.3906 - val_loss: 0.2984 - val_mae: 71865.3281\n",
      "Epoch 123/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3128 - mae: 73834.6562 - val_loss: 0.2912 - val_mae: 71093.3672\n",
      "Epoch 124/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3057 - mae: 73114.3594 - val_loss: 0.2842 - val_mae: 70334.8750\n",
      "Epoch 125/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2988 - mae: 72411.5234 - val_loss: 0.2774 - val_mae: 69573.9453\n",
      "Epoch 126/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.2921 - mae: 71702.7812 - val_loss: 0.2707 - val_mae: 68809.1719\n",
      "Epoch 127/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.2855 - mae: 70996.2891 - val_loss: 0.2643 - val_mae: 68057.8906\n",
      "Epoch 128/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.2792 - mae: 70298.4688 - val_loss: 0.2580 - val_mae: 67302.9297\n",
      "Epoch 129/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.2730 - mae: 69602.2266 - val_loss: 0.2519 - val_mae: 66560.9609\n",
      "Epoch 130/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2670 - mae: 68915.0938 - val_loss: 0.2459 - val_mae: 65816.0312\n",
      "Epoch 131/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.2611 - mae: 68237.4453 - val_loss: 0.2401 - val_mae: 65071.1562\n",
      "Epoch 132/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.2554 - mae: 67565.8047 - val_loss: 0.2345 - val_mae: 64348.0195\n",
      "Epoch 133/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.2499 - mae: 66901.5391 - val_loss: 0.2290 - val_mae: 63617.1953\n",
      "Epoch 134/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.2445 - mae: 66241.8672 - val_loss: 0.2236 - val_mae: 62892.4492\n",
      "Epoch 135/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2392 - mae: 65592.3359 - val_loss: 0.2184 - val_mae: 62182.1172\n",
      "Epoch 136/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.2341 - mae: 64949.3477 - val_loss: 0.2134 - val_mae: 61489.5117\n",
      "Epoch 137/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.2292 - mae: 64317.2305 - val_loss: 0.2085 - val_mae: 60805.6367\n",
      "Epoch 138/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.2244 - mae: 63689.4219 - val_loss: 0.2038 - val_mae: 60136.7500\n",
      "Epoch 139/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.2197 - mae: 63057.9727 - val_loss: 0.1992 - val_mae: 59485.7617\n",
      "Epoch 140/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.2152 - mae: 62445.6367 - val_loss: 0.1947 - val_mae: 58833.5156\n",
      "Epoch 141/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.2108 - mae: 61832.4180 - val_loss: 0.1903 - val_mae: 58184.2812\n",
      "Epoch 142/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.2065 - mae: 61226.3867 - val_loss: 0.1861 - val_mae: 57542.3672\n",
      "Epoch 143/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.2023 - mae: 60619.5625 - val_loss: 0.1820 - val_mae: 56908.3672\n",
      "Epoch 144/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.1983 - mae: 60035.4414 - val_loss: 0.1780 - val_mae: 56298.4023\n",
      "Epoch 145/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.1944 - mae: 59450.0156 - val_loss: 0.1741 - val_mae: 55694.5781\n",
      "Epoch 146/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.1907 - mae: 58881.6016 - val_loss: 0.1704 - val_mae: 55101.1250\n",
      "Epoch 147/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.1870 - mae: 58316.7500 - val_loss: 0.1668 - val_mae: 54535.4102\n",
      "Epoch 148/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.1834 - mae: 57770.6484 - val_loss: 0.1633 - val_mae: 53957.0547\n",
      "Epoch 149/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.1800 - mae: 57218.7109 - val_loss: 0.1599 - val_mae: 53383.1992\n",
      "Epoch 150/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.1767 - mae: 56678.1680 - val_loss: 0.1566 - val_mae: 52822.2617\n",
      "Epoch 151/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.1735 - mae: 56145.8320 - val_loss: 0.1535 - val_mae: 52282.5664\n",
      "Epoch 152/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.1704 - mae: 55621.2461 - val_loss: 0.1504 - val_mae: 51761.9062\n",
      "Epoch 153/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.1674 - mae: 55109.4922 - val_loss: 0.1474 - val_mae: 51250.1445\n",
      "Epoch 154/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.1645 - mae: 54603.0312 - val_loss: 0.1445 - val_mae: 50739.2578\n",
      "Epoch 155/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.1616 - mae: 54118.1367 - val_loss: 0.1417 - val_mae: 50258.1289\n",
      "Epoch 156/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.1589 - mae: 53632.8047 - val_loss: 0.1390 - val_mae: 49781.5625\n",
      "Epoch 157/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.1563 - mae: 53165.6172 - val_loss: 0.1364 - val_mae: 49315.0586\n",
      "Epoch 158/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.1538 - mae: 52701.8984 - val_loss: 0.1340 - val_mae: 48863.2734\n",
      "Epoch 159/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.1514 - mae: 52261.8125 - val_loss: 0.1315 - val_mae: 48409.4102\n",
      "Epoch 160/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.1490 - mae: 51832.1992 - val_loss: 0.1292 - val_mae: 47966.4648\n",
      "Epoch 161/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.1467 - mae: 51406.1836 - val_loss: 0.1270 - val_mae: 47536.8867\n",
      "Epoch 162/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.1445 - mae: 50994.4258 - val_loss: 0.1248 - val_mae: 47120.2070\n",
      "Epoch 163/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.1424 - mae: 50593.9023 - val_loss: 0.1227 - val_mae: 46726.8008\n",
      "Epoch 164/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.1404 - mae: 50209.4805 - val_loss: 0.1208 - val_mae: 46350.7891\n",
      "Epoch 165/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.1384 - mae: 49839.8633 - val_loss: 0.1188 - val_mae: 45975.3906\n",
      "Epoch 166/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.1365 - mae: 49470.2969 - val_loss: 0.1170 - val_mae: 45616.4062\n",
      "Epoch 167/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.1347 - mae: 49112.4648 - val_loss: 0.1151 - val_mae: 45255.0234\n",
      "Epoch 168/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1330 - mae: 48762.4609 - val_loss: 0.1134 - val_mae: 44911.2383\n",
      "Epoch 169/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1313 - mae: 48423.2344 - val_loss: 0.1118 - val_mae: 44586.8320\n",
      "Epoch 170/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.1297 - mae: 48102.1016 - val_loss: 0.1102 - val_mae: 44263.1719\n",
      "Epoch 171/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.1281 - mae: 47785.3750 - val_loss: 0.1087 - val_mae: 43951.5820\n",
      "Epoch 172/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1267 - mae: 47482.3594 - val_loss: 0.1072 - val_mae: 43656.4688\n",
      "Epoch 173/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1252 - mae: 47187.6133 - val_loss: 0.1058 - val_mae: 43362.0234\n",
      "Epoch 174/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.1239 - mae: 46897.5586 - val_loss: 0.1044 - val_mae: 43069.6367\n",
      "Epoch 175/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1226 - mae: 46626.8828 - val_loss: 0.1031 - val_mae: 42790.7930\n",
      "Epoch 176/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1213 - mae: 46356.3359 - val_loss: 0.1019 - val_mae: 42531.0508\n",
      "Epoch 177/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1201 - mae: 46112.1484 - val_loss: 0.1007 - val_mae: 42289.5938\n",
      "Epoch 178/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.1189 - mae: 45877.0312 - val_loss: 0.0996 - val_mae: 42055.7656\n",
      "Epoch 179/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1178 - mae: 45646.0977 - val_loss: 0.0985 - val_mae: 41835.7188\n",
      "Epoch 180/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1168 - mae: 45432.7891 - val_loss: 0.0974 - val_mae: 41623.2734\n",
      "Epoch 181/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1158 - mae: 45224.0625 - val_loss: 0.0964 - val_mae: 41424.6484\n",
      "Epoch 182/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.1148 - mae: 45030.4688 - val_loss: 0.0955 - val_mae: 41236.7539\n",
      "Epoch 183/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1139 - mae: 44845.0664 - val_loss: 0.0946 - val_mae: 41058.3008\n",
      "Epoch 184/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.1130 - mae: 44673.3555 - val_loss: 0.0937 - val_mae: 40884.6406\n",
      "Epoch 185/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1122 - mae: 44508.6328 - val_loss: 0.0929 - val_mae: 40713.2891\n",
      "Epoch 186/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.1114 - mae: 44340.9062 - val_loss: 0.0921 - val_mae: 40556.9688\n",
      "Epoch 187/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1106 - mae: 44194.2500 - val_loss: 0.0913 - val_mae: 40393.7109\n",
      "Epoch 188/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.1099 - mae: 44050.8828 - val_loss: 0.0906 - val_mae: 40244.8164\n",
      "Epoch 189/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1092 - mae: 43905.3164 - val_loss: 0.0899 - val_mae: 40093.6758\n",
      "Epoch 190/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1085 - mae: 43781.0039 - val_loss: 0.0893 - val_mae: 39958.9844\n",
      "Epoch 191/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.1079 - mae: 43666.1445 - val_loss: 0.0886 - val_mae: 39830.1953\n",
      "Epoch 192/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.1073 - mae: 43549.2188 - val_loss: 0.0881 - val_mae: 39712.7461\n",
      "Epoch 193/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.1067 - mae: 43447.1484 - val_loss: 0.0875 - val_mae: 39596.9648\n",
      "Epoch 194/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1062 - mae: 43348.3281 - val_loss: 0.0869 - val_mae: 39481.8320\n",
      "Epoch 195/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1057 - mae: 43248.3203 - val_loss: 0.0864 - val_mae: 39378.5195\n",
      "Epoch 196/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1052 - mae: 43160.9883 - val_loss: 0.0860 - val_mae: 39284.2656\n",
      "Epoch 197/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.1047 - mae: 43072.7031 - val_loss: 0.0855 - val_mae: 39201.7344\n",
      "Epoch 198/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1043 - mae: 42992.8125 - val_loss: 0.0851 - val_mae: 39123.5547\n",
      "Epoch 199/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.1039 - mae: 42914.3594 - val_loss: 0.0847 - val_mae: 39051.4141\n",
      "Epoch 200/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1035 - mae: 42839.6016 - val_loss: 0.0843 - val_mae: 38980.5781\n",
      "Epoch 201/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1031 - mae: 42767.0781 - val_loss: 0.0839 - val_mae: 38911.5195\n",
      "Epoch 202/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1027 - mae: 42698.7461 - val_loss: 0.0835 - val_mae: 38849.0078\n",
      "Epoch 203/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1024 - mae: 42637.8125 - val_loss: 0.0832 - val_mae: 38790.8047\n",
      "Epoch 204/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1021 - mae: 42577.9961 - val_loss: 0.0829 - val_mae: 38731.0078\n",
      "Epoch 205/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1018 - mae: 42529.8594 - val_loss: 0.0826 - val_mae: 38673.9023\n",
      "Epoch 206/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1015 - mae: 42476.9219 - val_loss: 0.0823 - val_mae: 38623.0977\n",
      "Epoch 207/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1012 - mae: 42427.9258 - val_loss: 0.0821 - val_mae: 38575.0977\n",
      "Epoch 208/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1010 - mae: 42387.0586 - val_loss: 0.0818 - val_mae: 38537.3555\n",
      "Epoch 209/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1007 - mae: 42347.4961 - val_loss: 0.0816 - val_mae: 38491.8047\n",
      "Epoch 210/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1005 - mae: 42306.3438 - val_loss: 0.0813 - val_mae: 38456.9062\n",
      "Epoch 211/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1003 - mae: 42269.6953 - val_loss: 0.0811 - val_mae: 38422.4922\n",
      "Epoch 212/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1001 - mae: 42236.1055 - val_loss: 0.0809 - val_mae: 38391.3164\n",
      "Epoch 213/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0999 - mae: 42208.4609 - val_loss: 0.0807 - val_mae: 38358.0078\n",
      "Epoch 214/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0997 - mae: 42174.0977 - val_loss: 0.0806 - val_mae: 38327.8438\n",
      "Epoch 215/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0995 - mae: 42148.3398 - val_loss: 0.0804 - val_mae: 38302.1875\n",
      "Epoch 216/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0994 - mae: 42119.9609 - val_loss: 0.0802 - val_mae: 38277.0547\n",
      "Epoch 217/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0992 - mae: 42092.6914 - val_loss: 0.0801 - val_mae: 38252.3516\n",
      "Epoch 218/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0991 - mae: 42069.8711 - val_loss: 0.0799 - val_mae: 38231.9219\n",
      "Epoch 219/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0990 - mae: 42049.1641 - val_loss: 0.0798 - val_mae: 38216.2656\n",
      "Epoch 220/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0988 - mae: 42028.2812 - val_loss: 0.0797 - val_mae: 38200.2344\n",
      "Epoch 221/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0987 - mae: 42008.5703 - val_loss: 0.0796 - val_mae: 38187.5000\n",
      "Epoch 222/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0986 - mae: 41989.5977 - val_loss: 0.0795 - val_mae: 38176.5039\n",
      "Epoch 223/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0985 - mae: 41972.3359 - val_loss: 0.0794 - val_mae: 38165.5391\n",
      "Epoch 224/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0984 - mae: 41958.5820 - val_loss: 0.0792 - val_mae: 38153.7578\n",
      "Epoch 225/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0983 - mae: 41941.8359 - val_loss: 0.0792 - val_mae: 38143.1914\n",
      "Epoch 226/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0982 - mae: 41929.0664 - val_loss: 0.0790 - val_mae: 38133.9531\n",
      "Epoch 227/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0981 - mae: 41919.2188 - val_loss: 0.0789 - val_mae: 38125.0664\n",
      "Epoch 228/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0980 - mae: 41902.2031 - val_loss: 0.0789 - val_mae: 38116.4297\n",
      "Epoch 229/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0979 - mae: 41892.8633 - val_loss: 0.0788 - val_mae: 38107.0820\n",
      "Epoch 230/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0978 - mae: 41880.7852 - val_loss: 0.0787 - val_mae: 38097.9414\n",
      "Epoch 231/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0978 - mae: 41868.8008 - val_loss: 0.0786 - val_mae: 38088.2656\n",
      "Epoch 232/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0977 - mae: 41857.3789 - val_loss: 0.0786 - val_mae: 38078.9453\n",
      "Epoch 233/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0976 - mae: 41846.8867 - val_loss: 0.0785 - val_mae: 38069.3906\n",
      "Epoch 234/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0975 - mae: 41838.0664 - val_loss: 0.0784 - val_mae: 38059.4570\n",
      "Epoch 235/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0975 - mae: 41827.6094 - val_loss: 0.0784 - val_mae: 38049.7031\n",
      "Epoch 236/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0974 - mae: 41817.9062 - val_loss: 0.0783 - val_mae: 38039.6016\n",
      "Epoch 237/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0974 - mae: 41808.2812 - val_loss: 0.0782 - val_mae: 38029.3711\n",
      "Epoch 238/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0973 - mae: 41799.5391 - val_loss: 0.0782 - val_mae: 38018.9922\n",
      "Epoch 239/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0972 - mae: 41789.4062 - val_loss: 0.0781 - val_mae: 38008.9258\n",
      "Epoch 240/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0972 - mae: 41781.8867 - val_loss: 0.0781 - val_mae: 37999.6055\n",
      "Epoch 241/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0971 - mae: 41771.3203 - val_loss: 0.0780 - val_mae: 37989.4492\n",
      "Epoch 242/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0971 - mae: 41762.4883 - val_loss: 0.0780 - val_mae: 37980.0391\n",
      "Epoch 243/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0970 - mae: 41753.8984 - val_loss: 0.0779 - val_mae: 37969.5625\n",
      "Epoch 244/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0970 - mae: 41742.6445 - val_loss: 0.0778 - val_mae: 37959.0586\n",
      "Epoch 245/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0969 - mae: 41733.3008 - val_loss: 0.0778 - val_mae: 37948.7344\n",
      "Epoch 246/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0968 - mae: 41724.9102 - val_loss: 0.0777 - val_mae: 37938.1250\n",
      "Epoch 247/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0968 - mae: 41715.5156 - val_loss: 0.0777 - val_mae: 37926.9023\n",
      "Epoch 248/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0967 - mae: 41705.6016 - val_loss: 0.0776 - val_mae: 37915.8750\n",
      "Epoch 249/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0967 - mae: 41696.3242 - val_loss: 0.0776 - val_mae: 37904.7930\n",
      "Epoch 250/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0966 - mae: 41686.9258 - val_loss: 0.0775 - val_mae: 37893.3750\n",
      "Epoch 251/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0966 - mae: 41675.9766 - val_loss: 0.0775 - val_mae: 37882.2773\n",
      "Epoch 252/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0965 - mae: 41667.0742 - val_loss: 0.0774 - val_mae: 37870.9961\n",
      "Epoch 253/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0965 - mae: 41656.1992 - val_loss: 0.0774 - val_mae: 37860.1602\n",
      "Epoch 254/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0964 - mae: 41645.9375 - val_loss: 0.0773 - val_mae: 37848.4258\n",
      "Epoch 255/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0964 - mae: 41636.1875 - val_loss: 0.0773 - val_mae: 37836.9766\n",
      "Epoch 256/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0963 - mae: 41624.8320 - val_loss: 0.0773 - val_mae: 37824.5781\n",
      "Epoch 257/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0963 - mae: 41616.7148 - val_loss: 0.0772 - val_mae: 37813.1055\n",
      "Epoch 258/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0962 - mae: 41603.8750 - val_loss: 0.0772 - val_mae: 37799.7969\n",
      "Epoch 259/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0962 - mae: 41591.3398 - val_loss: 0.0771 - val_mae: 37786.8438\n",
      "Epoch 260/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0961 - mae: 41582.6680 - val_loss: 0.0771 - val_mae: 37774.8242\n",
      "Epoch 261/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0961 - mae: 41570.0039 - val_loss: 0.0770 - val_mae: 37761.6133\n",
      "Epoch 262/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0960 - mae: 41558.0781 - val_loss: 0.0770 - val_mae: 37748.1797\n",
      "Epoch 263/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0960 - mae: 41546.1445 - val_loss: 0.0769 - val_mae: 37734.6953\n",
      "Epoch 264/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0959 - mae: 41535.4102 - val_loss: 0.0769 - val_mae: 37721.3789\n",
      "Epoch 265/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0959 - mae: 41522.3047 - val_loss: 0.0768 - val_mae: 37707.2266\n",
      "Epoch 266/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0958 - mae: 41510.6133 - val_loss: 0.0767 - val_mae: 37695.0859\n",
      "Epoch 267/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0957 - mae: 41501.6836 - val_loss: 0.0767 - val_mae: 37681.9219\n",
      "Epoch 268/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0957 - mae: 41487.6992 - val_loss: 0.0766 - val_mae: 37666.1406\n",
      "Epoch 269/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0956 - mae: 41473.2578 - val_loss: 0.0766 - val_mae: 37652.0156\n",
      "Epoch 270/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0956 - mae: 41461.9766 - val_loss: 0.0765 - val_mae: 37637.7109\n",
      "Epoch 271/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0955 - mae: 41447.8945 - val_loss: 0.0765 - val_mae: 37622.6719\n",
      "Epoch 272/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0954 - mae: 41435.5117 - val_loss: 0.0764 - val_mae: 37608.8633\n",
      "Epoch 273/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0954 - mae: 41421.1797 - val_loss: 0.0764 - val_mae: 37592.8867\n",
      "Epoch 274/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0953 - mae: 41408.3203 - val_loss: 0.0763 - val_mae: 37578.6250\n",
      "Epoch 275/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0953 - mae: 41394.0781 - val_loss: 0.0763 - val_mae: 37562.3633\n",
      "Epoch 276/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0952 - mae: 41379.4766 - val_loss: 0.0762 - val_mae: 37546.8438\n",
      "Epoch 277/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0951 - mae: 41365.7305 - val_loss: 0.0761 - val_mae: 37532.0703\n",
      "Epoch 278/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0951 - mae: 41351.4375 - val_loss: 0.0761 - val_mae: 37515.7422\n",
      "Epoch 279/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0950 - mae: 41338.5469 - val_loss: 0.0760 - val_mae: 37501.1562\n",
      "Epoch 280/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0950 - mae: 41323.3320 - val_loss: 0.0760 - val_mae: 37484.6992\n",
      "Epoch 281/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0949 - mae: 41308.7930 - val_loss: 0.0759 - val_mae: 37467.6016\n",
      "Epoch 282/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0948 - mae: 41291.0273 - val_loss: 0.0758 - val_mae: 37449.5273\n",
      "Epoch 283/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0948 - mae: 41275.9453 - val_loss: 0.0758 - val_mae: 37434.4102\n",
      "Epoch 284/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0947 - mae: 41261.4492 - val_loss: 0.0757 - val_mae: 37416.7148\n",
      "Epoch 285/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0946 - mae: 41244.9023 - val_loss: 0.0757 - val_mae: 37398.7539\n",
      "Epoch 286/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0946 - mae: 41230.4297 - val_loss: 0.0756 - val_mae: 37382.3867\n",
      "Epoch 287/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0945 - mae: 41212.9961 - val_loss: 0.0755 - val_mae: 37362.9414\n",
      "Epoch 288/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0944 - mae: 41194.7891 - val_loss: 0.0755 - val_mae: 37345.0156\n",
      "Epoch 289/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0943 - mae: 41178.1875 - val_loss: 0.0754 - val_mae: 37324.8281\n",
      "Epoch 290/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0943 - mae: 41166.2148 - val_loss: 0.0753 - val_mae: 37310.9102\n",
      "Epoch 291/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0942 - mae: 41145.0117 - val_loss: 0.0753 - val_mae: 37290.1250\n",
      "Epoch 292/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0941 - mae: 41126.8555 - val_loss: 0.0752 - val_mae: 37270.1758\n",
      "Epoch 293/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0941 - mae: 41108.3203 - val_loss: 0.0751 - val_mae: 37250.1367\n",
      "Epoch 294/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0940 - mae: 41093.7305 - val_loss: 0.0751 - val_mae: 37233.8672\n",
      "Epoch 295/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0939 - mae: 41073.9180 - val_loss: 0.0750 - val_mae: 37212.6055\n",
      "Epoch 296/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0938 - mae: 41054.9023 - val_loss: 0.0749 - val_mae: 37192.8125\n",
      "Epoch 297/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0938 - mae: 41040.4805 - val_loss: 0.0749 - val_mae: 37174.4180\n",
      "Epoch 298/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0937 - mae: 41019.1250 - val_loss: 0.0748 - val_mae: 37153.1133\n",
      "Epoch 299/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0936 - mae: 41001.7773 - val_loss: 0.0747 - val_mae: 37133.7344\n",
      "Epoch 300/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0935 - mae: 40982.8906 - val_loss: 0.0747 - val_mae: 37113.8047\n",
      "Epoch 301/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0934 - mae: 40962.5625 - val_loss: 0.0746 - val_mae: 37091.8203\n",
      "Epoch 302/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0934 - mae: 40945.7812 - val_loss: 0.0745 - val_mae: 37072.3477\n",
      "Epoch 303/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0933 - mae: 40925.1758 - val_loss: 0.0744 - val_mae: 37050.0352\n",
      "Epoch 304/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0932 - mae: 40906.3711 - val_loss: 0.0744 - val_mae: 37029.6094\n",
      "Epoch 305/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0931 - mae: 40886.4570 - val_loss: 0.0743 - val_mae: 37007.3984\n",
      "Epoch 306/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0930 - mae: 40866.4648 - val_loss: 0.0742 - val_mae: 36982.5625\n",
      "Epoch 307/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0930 - mae: 40843.1797 - val_loss: 0.0741 - val_mae: 36962.0078\n",
      "Epoch 308/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0929 - mae: 40825.0469 - val_loss: 0.0741 - val_mae: 36941.5781\n",
      "Epoch 309/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0928 - mae: 40805.3320 - val_loss: 0.0740 - val_mae: 36920.4648\n",
      "Epoch 310/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0927 - mae: 40784.5859 - val_loss: 0.0739 - val_mae: 36895.8594\n",
      "Epoch 311/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0926 - mae: 40762.1797 - val_loss: 0.0738 - val_mae: 36872.9492\n",
      "Epoch 312/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0925 - mae: 40741.7734 - val_loss: 0.0737 - val_mae: 36846.9531\n",
      "Epoch 313/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0924 - mae: 40719.8047 - val_loss: 0.0737 - val_mae: 36827.8672\n",
      "Epoch 314/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0923 - mae: 40698.8086 - val_loss: 0.0736 - val_mae: 36804.6562\n",
      "Epoch 315/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0923 - mae: 40675.7773 - val_loss: 0.0735 - val_mae: 36778.9961\n",
      "Epoch 316/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0922 - mae: 40652.1211 - val_loss: 0.0734 - val_mae: 36751.1094\n",
      "Epoch 317/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0921 - mae: 40632.7812 - val_loss: 0.0733 - val_mae: 36731.9141\n",
      "Epoch 318/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0920 - mae: 40609.5781 - val_loss: 0.0732 - val_mae: 36706.4492\n",
      "Epoch 319/1000\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.0919 - mae: 40586.0430 - val_loss: 0.0732 - val_mae: 36679.9102\n",
      "Epoch 320/1000\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.0918 - mae: 40562.9531 - val_loss: 0.0731 - val_mae: 36656.2461\n",
      "Epoch 321/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0917 - mae: 40538.9258 - val_loss: 0.0730 - val_mae: 36628.8438\n",
      "Epoch 322/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0916 - mae: 40515.3828 - val_loss: 0.0729 - val_mae: 36605.3359\n",
      "Epoch 323/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0915 - mae: 40491.0586 - val_loss: 0.0728 - val_mae: 36573.9336\n",
      "Epoch 324/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0914 - mae: 40468.0938 - val_loss: 0.0727 - val_mae: 36552.3203\n",
      "Epoch 325/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0913 - mae: 40444.0117 - val_loss: 0.0726 - val_mae: 36525.2773\n",
      "Epoch 326/1000\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.0912 - mae: 40419.6875 - val_loss: 0.0725 - val_mae: 36499.3711\n",
      "Epoch 327/1000\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.0911 - mae: 40396.9023 - val_loss: 0.0724 - val_mae: 36473.0742\n",
      "Epoch 328/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0910 - mae: 40369.0898 - val_loss: 0.0723 - val_mae: 36442.0430\n",
      "Epoch 329/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0909 - mae: 40340.4844 - val_loss: 0.0723 - val_mae: 36412.2617\n",
      "Epoch 330/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0908 - mae: 40314.0234 - val_loss: 0.0722 - val_mae: 36386.0742\n",
      "Epoch 331/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0907 - mae: 40288.4688 - val_loss: 0.0721 - val_mae: 36356.4141\n",
      "Epoch 332/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0906 - mae: 40261.9688 - val_loss: 0.0720 - val_mae: 36331.1211\n",
      "Epoch 333/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0905 - mae: 40242.3125 - val_loss: 0.0719 - val_mae: 36309.7812\n",
      "Epoch 334/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0904 - mae: 40218.2383 - val_loss: 0.0718 - val_mae: 36282.2852\n",
      "Epoch 335/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0903 - mae: 40187.4375 - val_loss: 0.0717 - val_mae: 36245.0508\n",
      "Epoch 336/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0902 - mae: 40160.6797 - val_loss: 0.0716 - val_mae: 36218.4023\n",
      "Epoch 337/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0900 - mae: 40133.1719 - val_loss: 0.0715 - val_mae: 36190.5078\n",
      "Epoch 338/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0899 - mae: 40107.6289 - val_loss: 0.0714 - val_mae: 36163.2344\n",
      "Epoch 339/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0898 - mae: 40080.3906 - val_loss: 0.0713 - val_mae: 36134.1367\n",
      "Epoch 340/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0897 - mae: 40053.6406 - val_loss: 0.0712 - val_mae: 36104.2461\n",
      "Epoch 341/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0896 - mae: 40023.9219 - val_loss: 0.0711 - val_mae: 36073.5742\n",
      "Epoch 342/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0895 - mae: 39994.9531 - val_loss: 0.0710 - val_mae: 36038.6328\n",
      "Epoch 343/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0894 - mae: 39964.4258 - val_loss: 0.0709 - val_mae: 36012.0469\n",
      "Epoch 344/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0893 - mae: 39940.6641 - val_loss: 0.0708 - val_mae: 35985.9141\n",
      "Epoch 345/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0891 - mae: 39911.4453 - val_loss: 0.0707 - val_mae: 35952.5391\n",
      "Epoch 346/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0890 - mae: 39878.8125 - val_loss: 0.0706 - val_mae: 35916.4531\n",
      "Epoch 347/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0889 - mae: 39849.9961 - val_loss: 0.0705 - val_mae: 35890.2461\n",
      "Epoch 348/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0888 - mae: 39825.5312 - val_loss: 0.0703 - val_mae: 35860.4023\n",
      "Epoch 349/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0887 - mae: 39792.7227 - val_loss: 0.0702 - val_mae: 35828.6094\n",
      "Epoch 350/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0885 - mae: 39760.2461 - val_loss: 0.0701 - val_mae: 35792.6250\n",
      "Epoch 351/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0884 - mae: 39735.7344 - val_loss: 0.0700 - val_mae: 35764.8828\n",
      "Epoch 352/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0883 - mae: 39707.1289 - val_loss: 0.0699 - val_mae: 35731.5977\n",
      "Epoch 353/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0882 - mae: 39672.5781 - val_loss: 0.0698 - val_mae: 35699.2344\n",
      "Epoch 354/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0881 - mae: 39644.1406 - val_loss: 0.0697 - val_mae: 35669.3867\n",
      "Epoch 355/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0879 - mae: 39611.8320 - val_loss: 0.0696 - val_mae: 35634.0078\n",
      "Epoch 356/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0878 - mae: 39580.7734 - val_loss: 0.0695 - val_mae: 35594.9141\n",
      "Epoch 357/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0877 - mae: 39548.6016 - val_loss: 0.0693 - val_mae: 35566.8008\n",
      "Epoch 358/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0875 - mae: 39514.4922 - val_loss: 0.0692 - val_mae: 35531.3906\n",
      "Epoch 359/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0874 - mae: 39483.0703 - val_loss: 0.0691 - val_mae: 35499.1484\n",
      "Epoch 360/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0873 - mae: 39451.0977 - val_loss: 0.0690 - val_mae: 35464.5156\n",
      "Epoch 361/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0872 - mae: 39416.2070 - val_loss: 0.0689 - val_mae: 35422.5195\n",
      "Epoch 362/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0870 - mae: 39379.4336 - val_loss: 0.0688 - val_mae: 35392.7344\n",
      "Epoch 363/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0869 - mae: 39353.2148 - val_loss: 0.0686 - val_mae: 35363.0469\n",
      "Epoch 364/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0868 - mae: 39320.1289 - val_loss: 0.0685 - val_mae: 35327.1445\n",
      "Epoch 365/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0866 - mae: 39286.8945 - val_loss: 0.0684 - val_mae: 35290.0195\n",
      "Epoch 366/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0865 - mae: 39251.4570 - val_loss: 0.0683 - val_mae: 35256.3047\n",
      "Epoch 367/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0863 - mae: 39218.3320 - val_loss: 0.0682 - val_mae: 35217.5703\n",
      "Epoch 368/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0862 - mae: 39185.1016 - val_loss: 0.0680 - val_mae: 35187.6797\n",
      "Epoch 369/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0861 - mae: 39149.5820 - val_loss: 0.0679 - val_mae: 35146.5469\n",
      "Epoch 370/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0859 - mae: 39117.4531 - val_loss: 0.0678 - val_mae: 35112.1562\n",
      "Epoch 371/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0858 - mae: 39083.2070 - val_loss: 0.0677 - val_mae: 35075.4180\n",
      "Epoch 372/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0857 - mae: 39045.6133 - val_loss: 0.0675 - val_mae: 35038.5312\n",
      "Epoch 373/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0855 - mae: 39008.5664 - val_loss: 0.0674 - val_mae: 34993.9922\n",
      "Epoch 374/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0854 - mae: 38975.8359 - val_loss: 0.0673 - val_mae: 34965.9219\n",
      "Epoch 375/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0852 - mae: 38938.4727 - val_loss: 0.0672 - val_mae: 34921.5703\n",
      "Epoch 376/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0851 - mae: 38903.6289 - val_loss: 0.0670 - val_mae: 34891.7227\n",
      "Epoch 377/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0849 - mae: 38866.6875 - val_loss: 0.0669 - val_mae: 34853.7109\n",
      "Epoch 378/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0848 - mae: 38828.3555 - val_loss: 0.0668 - val_mae: 34813.8203\n",
      "Epoch 379/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0847 - mae: 38796.8359 - val_loss: 0.0666 - val_mae: 34782.4961\n",
      "Epoch 380/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0845 - mae: 38753.1445 - val_loss: 0.0665 - val_mae: 34737.2930\n",
      "Epoch 381/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0844 - mae: 38714.1133 - val_loss: 0.0664 - val_mae: 34695.8086\n",
      "Epoch 382/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0842 - mae: 38679.6719 - val_loss: 0.0662 - val_mae: 34664.5898\n",
      "Epoch 383/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0841 - mae: 38642.6289 - val_loss: 0.0661 - val_mae: 34626.9414\n",
      "Epoch 384/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0839 - mae: 38602.1328 - val_loss: 0.0660 - val_mae: 34585.5781\n",
      "Epoch 385/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0838 - mae: 38569.0938 - val_loss: 0.0659 - val_mae: 34547.4609\n",
      "Epoch 386/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0836 - mae: 38526.2148 - val_loss: 0.0657 - val_mae: 34506.2852\n",
      "Epoch 387/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0834 - mae: 38487.2539 - val_loss: 0.0656 - val_mae: 34469.3086\n",
      "Epoch 388/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0833 - mae: 38448.5586 - val_loss: 0.0655 - val_mae: 34436.3047\n",
      "Epoch 389/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0831 - mae: 38413.4180 - val_loss: 0.0653 - val_mae: 34398.7422\n",
      "Epoch 390/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0830 - mae: 38368.7422 - val_loss: 0.0652 - val_mae: 34347.6055\n",
      "Epoch 391/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0828 - mae: 38325.8867 - val_loss: 0.0650 - val_mae: 34312.7539\n",
      "Epoch 392/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0827 - mae: 38286.9414 - val_loss: 0.0649 - val_mae: 34276.9727\n",
      "Epoch 393/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0825 - mae: 38247.7930 - val_loss: 0.0648 - val_mae: 34239.8047\n",
      "Epoch 394/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0823 - mae: 38208.5781 - val_loss: 0.0646 - val_mae: 34202.9648\n",
      "Epoch 395/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0822 - mae: 38171.3711 - val_loss: 0.0645 - val_mae: 34166.6914\n",
      "Epoch 396/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0820 - mae: 38130.9844 - val_loss: 0.0643 - val_mae: 34126.5469\n",
      "Epoch 397/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0819 - mae: 38091.7305 - val_loss: 0.0642 - val_mae: 34079.1367\n",
      "Epoch 398/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0817 - mae: 38046.8633 - val_loss: 0.0641 - val_mae: 34043.9531\n",
      "Epoch 399/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0815 - mae: 38007.6133 - val_loss: 0.0639 - val_mae: 34007.6641\n",
      "Epoch 400/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0814 - mae: 37966.0586 - val_loss: 0.0638 - val_mae: 33965.0078\n",
      "Epoch 401/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0812 - mae: 37921.3828 - val_loss: 0.0636 - val_mae: 33919.9336\n",
      "Epoch 402/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0811 - mae: 37881.8398 - val_loss: 0.0635 - val_mae: 33883.7305\n",
      "Epoch 403/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0809 - mae: 37841.9844 - val_loss: 0.0634 - val_mae: 33845.1133\n",
      "Epoch 404/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0807 - mae: 37796.8867 - val_loss: 0.0632 - val_mae: 33797.2461\n",
      "Epoch 405/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0806 - mae: 37753.8828 - val_loss: 0.0631 - val_mae: 33761.7422\n",
      "Epoch 406/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0804 - mae: 37711.8438 - val_loss: 0.0629 - val_mae: 33718.7422\n",
      "Epoch 407/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0802 - mae: 37670.0859 - val_loss: 0.0628 - val_mae: 33679.5430\n",
      "Epoch 408/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0801 - mae: 37626.2812 - val_loss: 0.0626 - val_mae: 33627.4531\n",
      "Epoch 409/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0799 - mae: 37581.1133 - val_loss: 0.0625 - val_mae: 33586.1602\n",
      "Epoch 410/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0797 - mae: 37541.6602 - val_loss: 0.0623 - val_mae: 33553.8359\n",
      "Epoch 411/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0796 - mae: 37496.9844 - val_loss: 0.0622 - val_mae: 33505.3047\n",
      "Epoch 412/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0794 - mae: 37456.9922 - val_loss: 0.0620 - val_mae: 33467.4844\n",
      "Epoch 413/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0792 - mae: 37412.2344 - val_loss: 0.0619 - val_mae: 33420.2344\n",
      "Epoch 414/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0791 - mae: 37367.0938 - val_loss: 0.0618 - val_mae: 33370.4297\n",
      "Epoch 415/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0789 - mae: 37327.1992 - val_loss: 0.0616 - val_mae: 33339.6016\n",
      "Epoch 416/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0787 - mae: 37284.9336 - val_loss: 0.0615 - val_mae: 33284.5625\n",
      "Epoch 417/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0785 - mae: 37236.4102 - val_loss: 0.0613 - val_mae: 33242.5508\n",
      "Epoch 418/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0784 - mae: 37207.0781 - val_loss: 0.0612 - val_mae: 33210.4922\n",
      "Epoch 419/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0782 - mae: 37152.1875 - val_loss: 0.0610 - val_mae: 33150.4805\n",
      "Epoch 420/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0780 - mae: 37106.9570 - val_loss: 0.0609 - val_mae: 33117.5664\n",
      "Epoch 421/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0778 - mae: 37065.4961 - val_loss: 0.0607 - val_mae: 33065.5273\n",
      "Epoch 422/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0777 - mae: 37028.2773 - val_loss: 0.0606 - val_mae: 33019.5156\n",
      "Epoch 423/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0775 - mae: 36978.2539 - val_loss: 0.0604 - val_mae: 32971.4531\n",
      "Epoch 424/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0773 - mae: 36934.2812 - val_loss: 0.0603 - val_mae: 32925.7266\n",
      "Epoch 425/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0771 - mae: 36890.2500 - val_loss: 0.0601 - val_mae: 32887.2305\n",
      "Epoch 426/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0769 - mae: 36847.6875 - val_loss: 0.0600 - val_mae: 32838.4102\n",
      "Epoch 427/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0768 - mae: 36803.8594 - val_loss: 0.0598 - val_mae: 32787.8906\n",
      "Epoch 428/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0766 - mae: 36758.5430 - val_loss: 0.0596 - val_mae: 32741.6465\n",
      "Epoch 429/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0764 - mae: 36717.0469 - val_loss: 0.0595 - val_mae: 32699.9727\n",
      "Epoch 430/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0762 - mae: 36675.5312 - val_loss: 0.0593 - val_mae: 32655.5586\n",
      "Epoch 431/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0761 - mae: 36627.7305 - val_loss: 0.0592 - val_mae: 32596.2832\n",
      "Epoch 432/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0759 - mae: 36580.8672 - val_loss: 0.0590 - val_mae: 32552.0508\n",
      "Epoch 433/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0757 - mae: 36534.2070 - val_loss: 0.0589 - val_mae: 32504.6504\n",
      "Epoch 434/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0755 - mae: 36489.5078 - val_loss: 0.0587 - val_mae: 32471.4102\n",
      "Epoch 435/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0754 - mae: 36448.7852 - val_loss: 0.0586 - val_mae: 32414.1191\n",
      "Epoch 436/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0752 - mae: 36400.2539 - val_loss: 0.0584 - val_mae: 32371.0879\n",
      "Epoch 437/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0750 - mae: 36355.8633 - val_loss: 0.0583 - val_mae: 32333.8828\n",
      "Epoch 438/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0748 - mae: 36313.2383 - val_loss: 0.0581 - val_mae: 32289.4551\n",
      "Epoch 439/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0746 - mae: 36267.9336 - val_loss: 0.0580 - val_mae: 32243.7031\n",
      "Epoch 440/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0745 - mae: 36228.8828 - val_loss: 0.0578 - val_mae: 32201.3340\n",
      "Epoch 441/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0743 - mae: 36184.3594 - val_loss: 0.0577 - val_mae: 32148.1602\n",
      "Epoch 442/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0741 - mae: 36126.2891 - val_loss: 0.0575 - val_mae: 32098.8359\n",
      "Epoch 443/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0739 - mae: 36083.3555 - val_loss: 0.0574 - val_mae: 32047.8789\n",
      "Epoch 444/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0737 - mae: 36037.0508 - val_loss: 0.0572 - val_mae: 32011.3125\n",
      "Epoch 445/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0736 - mae: 35991.8477 - val_loss: 0.0571 - val_mae: 31955.9922\n",
      "Epoch 446/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0734 - mae: 35954.4102 - val_loss: 0.0569 - val_mae: 31947.4707\n",
      "Epoch 447/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0732 - mae: 35904.6523 - val_loss: 0.0568 - val_mae: 31896.6387\n",
      "Epoch 448/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0730 - mae: 35863.7734 - val_loss: 0.0566 - val_mae: 31843.1523\n",
      "Epoch 449/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0728 - mae: 35815.3555 - val_loss: 0.0565 - val_mae: 31805.3125\n",
      "Epoch 450/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0726 - mae: 35770.3750 - val_loss: 0.0563 - val_mae: 31760.5762\n",
      "Epoch 451/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0725 - mae: 35728.8633 - val_loss: 0.0562 - val_mae: 31700.0918\n",
      "Epoch 452/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0723 - mae: 35685.6406 - val_loss: 0.0560 - val_mae: 31686.7949\n",
      "Epoch 453/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0721 - mae: 35629.8945 - val_loss: 0.0559 - val_mae: 31633.3770\n",
      "Epoch 454/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0719 - mae: 35598.3359 - val_loss: 0.0557 - val_mae: 31609.9805\n",
      "Epoch 455/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0717 - mae: 35540.7070 - val_loss: 0.0556 - val_mae: 31551.6133\n",
      "Epoch 456/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0715 - mae: 35492.9531 - val_loss: 0.0554 - val_mae: 31510.1426\n",
      "Epoch 457/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0713 - mae: 35454.8672 - val_loss: 0.0552 - val_mae: 31472.8242\n",
      "Epoch 458/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0712 - mae: 35406.0859 - val_loss: 0.0551 - val_mae: 31428.5430\n",
      "Epoch 459/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0710 - mae: 35361.6016 - val_loss: 0.0549 - val_mae: 31390.2051\n",
      "Epoch 460/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0708 - mae: 35319.5742 - val_loss: 0.0548 - val_mae: 31347.0918\n",
      "Epoch 461/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0706 - mae: 35271.5195 - val_loss: 0.0546 - val_mae: 31310.3906\n",
      "Epoch 462/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0705 - mae: 35232.9531 - val_loss: 0.0545 - val_mae: 31252.3027\n",
      "Epoch 463/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0703 - mae: 35184.6406 - val_loss: 0.0543 - val_mae: 31228.0586\n",
      "Epoch 464/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0701 - mae: 35138.9180 - val_loss: 0.0542 - val_mae: 31182.1602\n",
      "Epoch 465/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0699 - mae: 35083.4688 - val_loss: 0.0541 - val_mae: 31138.0781\n",
      "Epoch 466/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0697 - mae: 35039.4922 - val_loss: 0.0539 - val_mae: 31097.4727\n",
      "Epoch 467/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0695 - mae: 34994.2969 - val_loss: 0.0537 - val_mae: 31061.0645\n",
      "Epoch 468/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0693 - mae: 34952.3398 - val_loss: 0.0536 - val_mae: 31014.0801\n",
      "Epoch 469/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0691 - mae: 34906.5391 - val_loss: 0.0535 - val_mae: 30966.7578\n",
      "Epoch 470/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0690 - mae: 34859.3203 - val_loss: 0.0533 - val_mae: 30924.7246\n",
      "Epoch 471/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0688 - mae: 34810.2344 - val_loss: 0.0532 - val_mae: 30880.3535\n",
      "Epoch 472/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0686 - mae: 34764.7109 - val_loss: 0.0530 - val_mae: 30840.1094\n",
      "Epoch 473/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0684 - mae: 34721.3516 - val_loss: 0.0529 - val_mae: 30796.7715\n",
      "Epoch 474/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0682 - mae: 34676.2266 - val_loss: 0.0527 - val_mae: 30759.6074\n",
      "Epoch 475/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0681 - mae: 34636.4180 - val_loss: 0.0526 - val_mae: 30719.5625\n",
      "Epoch 476/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0679 - mae: 34594.6094 - val_loss: 0.0524 - val_mae: 30669.4316\n",
      "Epoch 477/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0677 - mae: 34544.8867 - val_loss: 0.0523 - val_mae: 30624.3770\n",
      "Epoch 478/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0676 - mae: 34509.3008 - val_loss: 0.0521 - val_mae: 30596.2188\n",
      "Epoch 479/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0673 - mae: 34456.0547 - val_loss: 0.0520 - val_mae: 30539.4043\n",
      "Epoch 480/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0672 - mae: 34404.4023 - val_loss: 0.0518 - val_mae: 30494.6484\n",
      "Epoch 481/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0670 - mae: 34361.7656 - val_loss: 0.0517 - val_mae: 30462.1836\n",
      "Epoch 482/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0668 - mae: 34321.1406 - val_loss: 0.0516 - val_mae: 30410.3828\n",
      "Epoch 483/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0666 - mae: 34276.2891 - val_loss: 0.0514 - val_mae: 30368.2422\n",
      "Epoch 484/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0665 - mae: 34229.6406 - val_loss: 0.0513 - val_mae: 30328.2559\n",
      "Epoch 485/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0663 - mae: 34187.3438 - val_loss: 0.0511 - val_mae: 30282.0820\n",
      "Epoch 486/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0661 - mae: 34142.8438 - val_loss: 0.0510 - val_mae: 30250.3906\n",
      "Epoch 487/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0660 - mae: 34110.5469 - val_loss: 0.0508 - val_mae: 30202.6582\n",
      "Epoch 488/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0658 - mae: 34063.2969 - val_loss: 0.0507 - val_mae: 30166.5234\n",
      "Epoch 489/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0656 - mae: 34014.3945 - val_loss: 0.0506 - val_mae: 30128.8770\n",
      "Epoch 490/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0654 - mae: 33983.5078 - val_loss: 0.0504 - val_mae: 30094.2441\n",
      "Epoch 491/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0652 - mae: 33934.4922 - val_loss: 0.0503 - val_mae: 30054.6035\n",
      "Epoch 492/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0651 - mae: 33890.9062 - val_loss: 0.0502 - val_mae: 30012.8613\n",
      "Epoch 493/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0649 - mae: 33847.6992 - val_loss: 0.0500 - val_mae: 29976.2832\n",
      "Epoch 494/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0647 - mae: 33807.0273 - val_loss: 0.0499 - val_mae: 29939.0469\n",
      "Epoch 495/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0645 - mae: 33771.1953 - val_loss: 0.0497 - val_mae: 29901.5547\n",
      "Epoch 496/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0644 - mae: 33728.1680 - val_loss: 0.0496 - val_mae: 29867.9902\n",
      "Epoch 497/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0642 - mae: 33685.8203 - val_loss: 0.0495 - val_mae: 29828.6445\n",
      "Epoch 498/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0640 - mae: 33644.5156 - val_loss: 0.0493 - val_mae: 29786.5742\n",
      "Epoch 499/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0639 - mae: 33612.9062 - val_loss: 0.0492 - val_mae: 29755.4746\n",
      "Epoch 500/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0637 - mae: 33565.2891 - val_loss: 0.0491 - val_mae: 29716.1309\n",
      "Epoch 501/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0635 - mae: 33524.8633 - val_loss: 0.0489 - val_mae: 29675.6543\n",
      "Epoch 502/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0633 - mae: 33483.5312 - val_loss: 0.0488 - val_mae: 29638.4414\n",
      "Epoch 503/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0632 - mae: 33443.6406 - val_loss: 0.0487 - val_mae: 29603.5273\n",
      "Epoch 504/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0630 - mae: 33408.0898 - val_loss: 0.0485 - val_mae: 29569.9434\n",
      "Epoch 505/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0629 - mae: 33361.2266 - val_loss: 0.0484 - val_mae: 29526.0703\n",
      "Epoch 506/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0627 - mae: 33323.1133 - val_loss: 0.0483 - val_mae: 29493.5273\n",
      "Epoch 507/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0625 - mae: 33282.4375 - val_loss: 0.0481 - val_mae: 29453.8281\n",
      "Epoch 508/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0624 - mae: 33244.5820 - val_loss: 0.0480 - val_mae: 29425.2520\n",
      "Epoch 509/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0622 - mae: 33215.4648 - val_loss: 0.0479 - val_mae: 29386.4023\n",
      "Epoch 510/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0620 - mae: 33164.3242 - val_loss: 0.0477 - val_mae: 29340.3398\n",
      "Epoch 511/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0619 - mae: 33124.0742 - val_loss: 0.0476 - val_mae: 29308.1719\n",
      "Epoch 512/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0617 - mae: 33090.5703 - val_loss: 0.0475 - val_mae: 29280.4375\n",
      "Epoch 513/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0616 - mae: 33052.5586 - val_loss: 0.0473 - val_mae: 29238.4102\n",
      "Epoch 514/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0614 - mae: 33005.3594 - val_loss: 0.0472 - val_mae: 29211.8750\n",
      "Epoch 515/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0612 - mae: 32971.9219 - val_loss: 0.0471 - val_mae: 29170.9277\n",
      "Epoch 516/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0611 - mae: 32934.6797 - val_loss: 0.0470 - val_mae: 29142.4727\n",
      "Epoch 517/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0609 - mae: 32881.9492 - val_loss: 0.0468 - val_mae: 29101.9219\n",
      "Epoch 518/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0608 - mae: 32853.3008 - val_loss: 0.0467 - val_mae: 29068.4980\n",
      "Epoch 519/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0606 - mae: 32807.0352 - val_loss: 0.0466 - val_mae: 29037.4844\n",
      "Epoch 520/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0604 - mae: 32762.1250 - val_loss: 0.0465 - val_mae: 28993.0840\n",
      "Epoch 521/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0603 - mae: 32724.9629 - val_loss: 0.0463 - val_mae: 28962.0781\n",
      "Epoch 522/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0601 - mae: 32682.0645 - val_loss: 0.0462 - val_mae: 28929.5742\n",
      "Epoch 523/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0600 - mae: 32648.3203 - val_loss: 0.0461 - val_mae: 28895.6543\n",
      "Epoch 524/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0598 - mae: 32607.3730 - val_loss: 0.0460 - val_mae: 28859.5996\n",
      "Epoch 525/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0597 - mae: 32565.8262 - val_loss: 0.0459 - val_mae: 28817.6855\n",
      "Epoch 526/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0595 - mae: 32540.9258 - val_loss: 0.0457 - val_mae: 28791.9805\n",
      "Epoch 527/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0593 - mae: 32487.2129 - val_loss: 0.0456 - val_mae: 28751.7852\n",
      "Epoch 528/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0592 - mae: 32453.7969 - val_loss: 0.0455 - val_mae: 28718.4961\n",
      "Epoch 529/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0590 - mae: 32414.1328 - val_loss: 0.0454 - val_mae: 28686.1426\n",
      "Epoch 530/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0589 - mae: 32366.1230 - val_loss: 0.0453 - val_mae: 28642.6738\n",
      "Epoch 531/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0587 - mae: 32344.3008 - val_loss: 0.0452 - val_mae: 28623.0801\n",
      "Epoch 532/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0586 - mae: 32295.7305 - val_loss: 0.0450 - val_mae: 28574.7891\n",
      "Epoch 533/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0584 - mae: 32247.9922 - val_loss: 0.0449 - val_mae: 28550.6035\n",
      "Epoch 534/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0583 - mae: 32216.8594 - val_loss: 0.0448 - val_mae: 28509.1406\n",
      "Epoch 535/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0581 - mae: 32175.3711 - val_loss: 0.0447 - val_mae: 28480.5625\n",
      "Epoch 536/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0580 - mae: 32140.7461 - val_loss: 0.0446 - val_mae: 28436.4434\n",
      "Epoch 537/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0579 - mae: 32103.3340 - val_loss: 0.0445 - val_mae: 28411.6699\n",
      "Epoch 538/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0577 - mae: 32056.8867 - val_loss: 0.0444 - val_mae: 28369.5273\n",
      "Epoch 539/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0576 - mae: 32021.3164 - val_loss: 0.0442 - val_mae: 28331.5898\n",
      "Epoch 540/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0574 - mae: 31988.0078 - val_loss: 0.0441 - val_mae: 28307.6738\n",
      "Epoch 541/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0573 - mae: 31956.1914 - val_loss: 0.0440 - val_mae: 28271.3672\n",
      "Epoch 542/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0572 - mae: 31930.3438 - val_loss: 0.0439 - val_mae: 28243.4121\n",
      "Epoch 543/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0570 - mae: 31884.2930 - val_loss: 0.0438 - val_mae: 28189.6699\n",
      "Epoch 544/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0569 - mae: 31852.8691 - val_loss: 0.0437 - val_mae: 28178.2656\n",
      "Epoch 545/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0567 - mae: 31799.5879 - val_loss: 0.0436 - val_mae: 28117.5586\n",
      "Epoch 546/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0566 - mae: 31764.6543 - val_loss: 0.0435 - val_mae: 28088.0137\n",
      "Epoch 547/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0564 - mae: 31732.0273 - val_loss: 0.0434 - val_mae: 28049.7207\n",
      "Epoch 548/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0563 - mae: 31685.0312 - val_loss: 0.0433 - val_mae: 28025.7676\n",
      "Epoch 549/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0562 - mae: 31697.9512 - val_loss: 0.0432 - val_mae: 28008.1914\n",
      "Epoch 550/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0561 - mae: 31618.2227 - val_loss: 0.0431 - val_mae: 27963.2656\n",
      "Epoch 551/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0559 - mae: 31585.9258 - val_loss: 0.0430 - val_mae: 27906.7949\n",
      "Epoch 552/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0558 - mae: 31559.3672 - val_loss: 0.0429 - val_mae: 27912.9023\n",
      "Epoch 553/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0556 - mae: 31512.1133 - val_loss: 0.0428 - val_mae: 27857.1816\n",
      "Epoch 554/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0555 - mae: 31468.2930 - val_loss: 0.0427 - val_mae: 27838.3926\n",
      "Epoch 555/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0554 - mae: 31444.3926 - val_loss: 0.0426 - val_mae: 27804.0293\n",
      "Epoch 556/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0552 - mae: 31391.3613 - val_loss: 0.0425 - val_mae: 27755.4844\n",
      "Epoch 557/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0551 - mae: 31358.4980 - val_loss: 0.0424 - val_mae: 27728.4414\n",
      "Epoch 558/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0550 - mae: 31329.0527 - val_loss: 0.0423 - val_mae: 27704.8242\n",
      "Epoch 559/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0549 - mae: 31297.8418 - val_loss: 0.0422 - val_mae: 27679.0566\n",
      "Epoch 560/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0548 - mae: 31271.4453 - val_loss: 0.0421 - val_mae: 27641.5234\n",
      "Epoch 561/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0547 - mae: 31232.9375 - val_loss: 0.0420 - val_mae: 27611.3867\n",
      "Epoch 562/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0545 - mae: 31200.8867 - val_loss: 0.0419 - val_mae: 27577.7578\n",
      "Epoch 563/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0545 - mae: 31171.4551 - val_loss: 0.0418 - val_mae: 27519.2832\n",
      "Epoch 564/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0543 - mae: 31131.8320 - val_loss: 0.0417 - val_mae: 27521.6133\n",
      "Epoch 565/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0541 - mae: 31100.6484 - val_loss: 0.0416 - val_mae: 27481.5664\n",
      "Epoch 566/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0540 - mae: 31061.2969 - val_loss: 0.0415 - val_mae: 27432.2852\n",
      "Epoch 567/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0539 - mae: 31033.9492 - val_loss: 0.0414 - val_mae: 27406.9590\n",
      "Epoch 568/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0538 - mae: 30997.7598 - val_loss: 0.0414 - val_mae: 27361.7168\n",
      "Epoch 569/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0537 - mae: 30968.3242 - val_loss: 0.0413 - val_mae: 27359.4355\n",
      "Epoch 570/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0536 - mae: 30941.8359 - val_loss: 0.0412 - val_mae: 27315.5684\n",
      "Epoch 571/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0535 - mae: 30893.6074 - val_loss: 0.0411 - val_mae: 27262.9219\n",
      "Epoch 572/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0533 - mae: 30859.4512 - val_loss: 0.0410 - val_mae: 27269.6836\n",
      "Epoch 573/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0532 - mae: 30847.7676 - val_loss: 0.0409 - val_mae: 27219.9902\n",
      "Epoch 574/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0531 - mae: 30798.4961 - val_loss: 0.0408 - val_mae: 27193.6934\n",
      "Epoch 575/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0530 - mae: 30783.6250 - val_loss: 0.0408 - val_mae: 27151.2246\n",
      "Epoch 576/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0529 - mae: 30757.0918 - val_loss: 0.0407 - val_mae: 27141.5664\n",
      "Epoch 577/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0528 - mae: 30707.2559 - val_loss: 0.0406 - val_mae: 27083.5938\n",
      "Epoch 578/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0527 - mae: 30681.5723 - val_loss: 0.0405 - val_mae: 27061.9863\n",
      "Epoch 579/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0526 - mae: 30643.2402 - val_loss: 0.0404 - val_mae: 27021.2148\n",
      "Epoch 580/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0525 - mae: 30636.8906 - val_loss: 0.0403 - val_mae: 27019.0996\n",
      "Epoch 581/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0524 - mae: 30580.7266 - val_loss: 0.0403 - val_mae: 26961.2500\n",
      "Epoch 582/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0523 - mae: 30563.0586 - val_loss: 0.0402 - val_mae: 26941.9102\n",
      "Epoch 583/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0523 - mae: 30539.4922 - val_loss: 0.0401 - val_mae: 26907.2285\n",
      "Epoch 584/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0521 - mae: 30509.4883 - val_loss: 0.0400 - val_mae: 26893.4160\n",
      "Epoch 585/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0520 - mae: 30467.5664 - val_loss: 0.0400 - val_mae: 26832.8457\n",
      "Epoch 586/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0519 - mae: 30429.8398 - val_loss: 0.0399 - val_mae: 26813.4355\n",
      "Epoch 587/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0518 - mae: 30421.5176 - val_loss: 0.0398 - val_mae: 26790.6172\n",
      "Epoch 588/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0517 - mae: 30383.0273 - val_loss: 0.0397 - val_mae: 26762.9785\n",
      "Epoch 589/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0516 - mae: 30358.7031 - val_loss: 0.0397 - val_mae: 26737.4863\n",
      "Epoch 590/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0515 - mae: 30309.7480 - val_loss: 0.0396 - val_mae: 26684.9082\n",
      "Epoch 591/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0514 - mae: 30298.9375 - val_loss: 0.0395 - val_mae: 26666.8984\n",
      "Epoch 592/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0513 - mae: 30248.0000 - val_loss: 0.0394 - val_mae: 26625.4473\n",
      "Epoch 593/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0512 - mae: 30223.8008 - val_loss: 0.0394 - val_mae: 26599.9785\n",
      "Epoch 594/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0511 - mae: 30203.2012 - val_loss: 0.0393 - val_mae: 26577.0605\n",
      "Epoch 595/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0510 - mae: 30176.6328 - val_loss: 0.0392 - val_mae: 26540.2812\n",
      "Epoch 596/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0509 - mae: 30147.7695 - val_loss: 0.0392 - val_mae: 26517.9629\n",
      "Epoch 597/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0508 - mae: 30105.9082 - val_loss: 0.0391 - val_mae: 26477.8164\n",
      "Epoch 598/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0507 - mae: 30100.6445 - val_loss: 0.0390 - val_mae: 26479.5391\n",
      "Epoch 599/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0507 - mae: 30070.7188 - val_loss: 0.0390 - val_mae: 26410.9199\n",
      "Epoch 600/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0506 - mae: 30034.3633 - val_loss: 0.0389 - val_mae: 26388.3965\n",
      "Epoch 601/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0505 - mae: 29998.1484 - val_loss: 0.0388 - val_mae: 26357.2754\n",
      "Epoch 602/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0504 - mae: 29994.2305 - val_loss: 0.0387 - val_mae: 26331.4727\n",
      "Epoch 603/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0503 - mae: 29953.4551 - val_loss: 0.0387 - val_mae: 26299.2969\n",
      "Epoch 604/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0502 - mae: 29918.3047 - val_loss: 0.0386 - val_mae: 26264.5020\n",
      "Epoch 605/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0501 - mae: 29903.2012 - val_loss: 0.0385 - val_mae: 26233.3965\n",
      "Epoch 606/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0501 - mae: 29874.2129 - val_loss: 0.0385 - val_mae: 26206.8672\n",
      "Epoch 607/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0500 - mae: 29846.4355 - val_loss: 0.0384 - val_mae: 26174.6465\n",
      "Epoch 608/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0499 - mae: 29830.0938 - val_loss: 0.0384 - val_mae: 26149.5664\n",
      "Epoch 609/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0498 - mae: 29788.0039 - val_loss: 0.0383 - val_mae: 26123.3145\n",
      "Epoch 610/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0498 - mae: 29789.5352 - val_loss: 0.0383 - val_mae: 26120.4453\n",
      "Epoch 611/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0497 - mae: 29727.5566 - val_loss: 0.0382 - val_mae: 26078.6895\n",
      "Epoch 612/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0495 - mae: 29703.9961 - val_loss: 0.0381 - val_mae: 26049.8711\n",
      "Epoch 613/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0495 - mae: 29684.5449 - val_loss: 0.0381 - val_mae: 26025.0840\n",
      "Epoch 614/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0494 - mae: 29687.2051 - val_loss: 0.0380 - val_mae: 25990.5059\n",
      "Epoch 615/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0493 - mae: 29623.5293 - val_loss: 0.0379 - val_mae: 25971.3828\n",
      "Epoch 616/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0493 - mae: 29604.6250 - val_loss: 0.0379 - val_mae: 25947.2949\n",
      "Epoch 617/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0492 - mae: 29581.3457 - val_loss: 0.0378 - val_mae: 25926.4922\n",
      "Epoch 618/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0491 - mae: 29553.7695 - val_loss: 0.0378 - val_mae: 25889.8594\n",
      "Epoch 619/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0490 - mae: 29531.2344 - val_loss: 0.0377 - val_mae: 25871.9707\n",
      "Epoch 620/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0489 - mae: 29495.5371 - val_loss: 0.0377 - val_mae: 25845.2402\n",
      "Epoch 621/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0489 - mae: 29485.8555 - val_loss: 0.0376 - val_mae: 25826.1211\n",
      "Epoch 622/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0488 - mae: 29446.6250 - val_loss: 0.0376 - val_mae: 25801.1133\n",
      "Epoch 623/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0487 - mae: 29421.0566 - val_loss: 0.0375 - val_mae: 25772.7383\n",
      "Epoch 624/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0487 - mae: 29398.1504 - val_loss: 0.0374 - val_mae: 25747.4180\n",
      "Epoch 625/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0486 - mae: 29372.5469 - val_loss: 0.0374 - val_mae: 25720.9980\n",
      "Epoch 626/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0485 - mae: 29362.0977 - val_loss: 0.0373 - val_mae: 25699.0898\n",
      "Epoch 627/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0485 - mae: 29327.0332 - val_loss: 0.0373 - val_mae: 25670.3164\n",
      "Epoch 628/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0484 - mae: 29307.3555 - val_loss: 0.0372 - val_mae: 25664.9531\n",
      "Epoch 629/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0484 - mae: 29309.7207 - val_loss: 0.0372 - val_mae: 25641.3262\n",
      "Epoch 630/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0483 - mae: 29271.5625 - val_loss: 0.0371 - val_mae: 25604.8086\n",
      "Epoch 631/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0482 - mae: 29237.6602 - val_loss: 0.0371 - val_mae: 25583.8262\n",
      "Epoch 632/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0481 - mae: 29217.3438 - val_loss: 0.0370 - val_mae: 25552.8926\n",
      "Epoch 633/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0481 - mae: 29184.9023 - val_loss: 0.0370 - val_mae: 25533.8750\n",
      "Epoch 634/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0480 - mae: 29165.3027 - val_loss: 0.0369 - val_mae: 25511.2500\n",
      "Epoch 635/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0479 - mae: 29144.8262 - val_loss: 0.0369 - val_mae: 25488.4766\n",
      "Epoch 636/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0479 - mae: 29127.8691 - val_loss: 0.0368 - val_mae: 25475.6484\n",
      "Epoch 637/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0478 - mae: 29101.7910 - val_loss: 0.0368 - val_mae: 25445.1934\n",
      "Epoch 638/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0478 - mae: 29107.6836 - val_loss: 0.0367 - val_mae: 25430.7988\n",
      "Epoch 639/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0477 - mae: 29050.0508 - val_loss: 0.0367 - val_mae: 25417.6875\n",
      "Epoch 640/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0476 - mae: 29026.7539 - val_loss: 0.0366 - val_mae: 25391.8867\n",
      "Epoch 641/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0476 - mae: 29018.4609 - val_loss: 0.0366 - val_mae: 25391.6367\n",
      "Epoch 642/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0475 - mae: 29003.7793 - val_loss: 0.0366 - val_mae: 25337.5234\n",
      "Epoch 643/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0475 - mae: 28986.2969 - val_loss: 0.0365 - val_mae: 25336.8262\n",
      "Epoch 644/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0474 - mae: 28945.2734 - val_loss: 0.0365 - val_mae: 25301.5234\n",
      "Epoch 645/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0474 - mae: 28959.0117 - val_loss: 0.0364 - val_mae: 25286.9160\n",
      "Epoch 646/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0473 - mae: 28899.1641 - val_loss: 0.0364 - val_mae: 25286.4707\n",
      "Epoch 647/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0472 - mae: 28888.2559 - val_loss: 0.0363 - val_mae: 25251.7383\n",
      "Epoch 648/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0472 - mae: 28863.3359 - val_loss: 0.0363 - val_mae: 25230.9316\n",
      "Epoch 649/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0471 - mae: 28847.3672 - val_loss: 0.0362 - val_mae: 25208.8320\n",
      "Epoch 650/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0470 - mae: 28822.1543 - val_loss: 0.0362 - val_mae: 25193.5117\n",
      "Epoch 651/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0470 - mae: 28806.7715 - val_loss: 0.0362 - val_mae: 25172.1504\n",
      "Epoch 652/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0470 - mae: 28775.1133 - val_loss: 0.0361 - val_mae: 25153.6348\n",
      "Epoch 653/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0469 - mae: 28769.8926 - val_loss: 0.0361 - val_mae: 25127.2246\n",
      "Epoch 654/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0468 - mae: 28730.3047 - val_loss: 0.0360 - val_mae: 25119.7969\n",
      "Epoch 655/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0468 - mae: 28730.4785 - val_loss: 0.0360 - val_mae: 25097.5723\n",
      "Epoch 656/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0467 - mae: 28705.6289 - val_loss: 0.0360 - val_mae: 25082.6934\n",
      "Epoch 657/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0467 - mae: 28680.6152 - val_loss: 0.0359 - val_mae: 25064.5391\n",
      "Epoch 658/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0466 - mae: 28676.3340 - val_loss: 0.0359 - val_mae: 25035.9160\n",
      "Epoch 659/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0466 - mae: 28653.9395 - val_loss: 0.0358 - val_mae: 25022.2031\n",
      "Epoch 660/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0465 - mae: 28614.1211 - val_loss: 0.0358 - val_mae: 25013.4434\n",
      "Epoch 661/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0465 - mae: 28610.7109 - val_loss: 0.0357 - val_mae: 24979.4766\n",
      "Epoch 662/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0464 - mae: 28588.9062 - val_loss: 0.0357 - val_mae: 24989.0918\n",
      "Epoch 663/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0464 - mae: 28571.4570 - val_loss: 0.0357 - val_mae: 24944.5020\n",
      "Epoch 664/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0463 - mae: 28553.7148 - val_loss: 0.0356 - val_mae: 24935.2188\n",
      "Epoch 665/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0463 - mae: 28530.7695 - val_loss: 0.0356 - val_mae: 24930.2852\n",
      "Epoch 666/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0462 - mae: 28509.1602 - val_loss: 0.0355 - val_mae: 24899.8242\n",
      "Epoch 667/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0461 - mae: 28490.4766 - val_loss: 0.0355 - val_mae: 24889.7031\n",
      "Epoch 668/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0461 - mae: 28468.8828 - val_loss: 0.0355 - val_mae: 24855.6289\n",
      "Epoch 669/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0461 - mae: 28463.9492 - val_loss: 0.0354 - val_mae: 24865.7637\n",
      "Epoch 670/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0460 - mae: 28439.3262 - val_loss: 0.0354 - val_mae: 24823.0117\n",
      "Epoch 671/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0460 - mae: 28421.8574 - val_loss: 0.0354 - val_mae: 24848.2305\n",
      "Epoch 672/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0459 - mae: 28395.7656 - val_loss: 0.0353 - val_mae: 24807.8164\n",
      "Epoch 673/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0459 - mae: 28383.4785 - val_loss: 0.0353 - val_mae: 24790.8262\n",
      "Epoch 674/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0458 - mae: 28365.0938 - val_loss: 0.0353 - val_mae: 24771.1895\n",
      "Epoch 675/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0458 - mae: 28338.1953 - val_loss: 0.0352 - val_mae: 24770.9980\n",
      "Epoch 676/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0457 - mae: 28326.4355 - val_loss: 0.0352 - val_mae: 24734.2285\n",
      "Epoch 677/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0457 - mae: 28299.1484 - val_loss: 0.0351 - val_mae: 24726.2402\n",
      "Epoch 678/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0456 - mae: 28290.2363 - val_loss: 0.0351 - val_mae: 24716.7578\n",
      "Epoch 679/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0456 - mae: 28263.3926 - val_loss: 0.0351 - val_mae: 24704.6172\n",
      "Epoch 680/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0455 - mae: 28255.9004 - val_loss: 0.0351 - val_mae: 24685.5586\n",
      "Epoch 681/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0455 - mae: 28232.3652 - val_loss: 0.0350 - val_mae: 24673.8262\n",
      "Epoch 682/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0454 - mae: 28210.9375 - val_loss: 0.0350 - val_mae: 24653.1504\n",
      "Epoch 683/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0454 - mae: 28201.2656 - val_loss: 0.0349 - val_mae: 24635.5430\n",
      "Epoch 684/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0454 - mae: 28188.4023 - val_loss: 0.0349 - val_mae: 24627.1211\n",
      "Epoch 685/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0453 - mae: 28172.6172 - val_loss: 0.0349 - val_mae: 24616.8203\n",
      "Epoch 686/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0453 - mae: 28143.4375 - val_loss: 0.0348 - val_mae: 24591.4707\n",
      "Epoch 687/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0452 - mae: 28130.7949 - val_loss: 0.0348 - val_mae: 24584.1309\n",
      "Epoch 688/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0452 - mae: 28143.5723 - val_loss: 0.0348 - val_mae: 24582.7969\n",
      "Epoch 689/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0451 - mae: 28088.9512 - val_loss: 0.0348 - val_mae: 24581.0000\n",
      "Epoch 690/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0451 - mae: 28078.9805 - val_loss: 0.0347 - val_mae: 24536.1035\n",
      "Epoch 691/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0451 - mae: 28086.7891 - val_loss: 0.0347 - val_mae: 24532.2324\n",
      "Epoch 692/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0450 - mae: 28057.1758 - val_loss: 0.0346 - val_mae: 24527.3809\n",
      "Epoch 693/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0450 - mae: 28020.3145 - val_loss: 0.0346 - val_mae: 24526.4102\n",
      "Epoch 694/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0450 - mae: 28027.9395 - val_loss: 0.0346 - val_mae: 24483.5039\n",
      "Epoch 695/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0449 - mae: 27998.4277 - val_loss: 0.0346 - val_mae: 24496.1348\n",
      "Epoch 696/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0449 - mae: 27990.7500 - val_loss: 0.0345 - val_mae: 24468.4746\n",
      "Epoch 697/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0448 - mae: 27964.2227 - val_loss: 0.0345 - val_mae: 24464.3730\n",
      "Epoch 698/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0449 - mae: 28018.4160 - val_loss: 0.0345 - val_mae: 24442.8262\n",
      "Epoch 699/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0448 - mae: 27948.0234 - val_loss: 0.0345 - val_mae: 24434.0000\n",
      "Epoch 700/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0447 - mae: 27916.6875 - val_loss: 0.0344 - val_mae: 24423.8711\n",
      "Epoch 701/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0447 - mae: 27936.0234 - val_loss: 0.0344 - val_mae: 24404.8320\n",
      "Epoch 702/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0447 - mae: 27887.9219 - val_loss: 0.0344 - val_mae: 24408.2969\n",
      "Epoch 703/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0446 - mae: 27886.8320 - val_loss: 0.0343 - val_mae: 24375.2148\n",
      "Epoch 704/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0446 - mae: 27888.3613 - val_loss: 0.0343 - val_mae: 24375.3809\n",
      "Epoch 705/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0446 - mae: 27875.4766 - val_loss: 0.0343 - val_mae: 24371.2441\n",
      "Epoch 706/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0445 - mae: 27821.0195 - val_loss: 0.0342 - val_mae: 24344.0117\n",
      "Epoch 707/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0444 - mae: 27826.5996 - val_loss: 0.0343 - val_mae: 24331.0566\n",
      "Epoch 708/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0444 - mae: 27821.3008 - val_loss: 0.0342 - val_mae: 24320.6680\n",
      "Epoch 709/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0444 - mae: 27808.3828 - val_loss: 0.0342 - val_mae: 24322.1113\n",
      "Epoch 710/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0443 - mae: 27786.2852 - val_loss: 0.0342 - val_mae: 24307.0430\n",
      "Epoch 711/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0443 - mae: 27759.2461 - val_loss: 0.0341 - val_mae: 24289.4531\n",
      "Epoch 712/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0443 - mae: 27772.4980 - val_loss: 0.0341 - val_mae: 24283.5234\n",
      "Epoch 713/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0443 - mae: 27760.2852 - val_loss: 0.0341 - val_mae: 24278.0605\n",
      "Epoch 714/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0442 - mae: 27723.0488 - val_loss: 0.0341 - val_mae: 24259.9082\n",
      "Epoch 715/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0442 - mae: 27731.3008 - val_loss: 0.0340 - val_mae: 24241.4453\n",
      "Epoch 716/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0442 - mae: 27708.1719 - val_loss: 0.0340 - val_mae: 24231.1934\n",
      "Epoch 717/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0441 - mae: 27687.8594 - val_loss: 0.0340 - val_mae: 24214.3730\n",
      "Epoch 718/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0441 - mae: 27668.3457 - val_loss: 0.0340 - val_mae: 24198.7266\n",
      "Epoch 719/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0440 - mae: 27678.8184 - val_loss: 0.0339 - val_mae: 24191.2949\n",
      "Epoch 720/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0441 - mae: 27632.1523 - val_loss: 0.0339 - val_mae: 24191.9805\n",
      "Epoch 721/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0440 - mae: 27659.3203 - val_loss: 0.0339 - val_mae: 24188.0723\n",
      "Epoch 722/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0440 - mae: 27640.5078 - val_loss: 0.0339 - val_mae: 24167.1895\n",
      "Epoch 723/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0439 - mae: 27605.9883 - val_loss: 0.0338 - val_mae: 24155.1816\n",
      "Epoch 724/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0439 - mae: 27575.1348 - val_loss: 0.0338 - val_mae: 24146.4121\n",
      "Epoch 725/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0439 - mae: 27588.3828 - val_loss: 0.0338 - val_mae: 24142.4922\n",
      "Epoch 726/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0438 - mae: 27571.4434 - val_loss: 0.0338 - val_mae: 24127.0605\n",
      "Epoch 727/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0438 - mae: 27561.9980 - val_loss: 0.0338 - val_mae: 24113.2949\n",
      "Epoch 728/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0438 - mae: 27542.5840 - val_loss: 0.0338 - val_mae: 24104.4141\n",
      "Epoch 729/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0438 - mae: 27558.7969 - val_loss: 0.0337 - val_mae: 24098.1641\n",
      "Epoch 730/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0437 - mae: 27519.5430 - val_loss: 0.0337 - val_mae: 24095.4707\n",
      "Epoch 731/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0437 - mae: 27522.2598 - val_loss: 0.0337 - val_mae: 24087.7559\n",
      "Epoch 732/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0436 - mae: 27485.3711 - val_loss: 0.0336 - val_mae: 24067.9609\n",
      "Epoch 733/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0436 - mae: 27491.7656 - val_loss: 0.0336 - val_mae: 24057.2539\n",
      "Epoch 734/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0436 - mae: 27480.9883 - val_loss: 0.0336 - val_mae: 24048.0625\n",
      "Epoch 735/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0436 - mae: 27463.2422 - val_loss: 0.0336 - val_mae: 24039.6055\n",
      "Epoch 736/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0435 - mae: 27474.8164 - val_loss: 0.0336 - val_mae: 24025.6582\n",
      "Epoch 737/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0436 - mae: 27452.1387 - val_loss: 0.0336 - val_mae: 24020.9512\n",
      "Epoch 738/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0435 - mae: 27433.7969 - val_loss: 0.0336 - val_mae: 24012.1895\n",
      "Epoch 739/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0435 - mae: 27420.6348 - val_loss: 0.0335 - val_mae: 24005.9160\n",
      "Epoch 740/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0434 - mae: 27396.2793 - val_loss: 0.0335 - val_mae: 23995.1934\n",
      "Epoch 741/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0434 - mae: 27396.7598 - val_loss: 0.0335 - val_mae: 23988.9727\n",
      "Epoch 742/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0434 - mae: 27395.7285 - val_loss: 0.0335 - val_mae: 23977.6191\n",
      "Epoch 743/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0433 - mae: 27358.4453 - val_loss: 0.0334 - val_mae: 23966.4375\n",
      "Epoch 744/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0433 - mae: 27373.7246 - val_loss: 0.0334 - val_mae: 23961.0117\n",
      "Epoch 745/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0433 - mae: 27334.4883 - val_loss: 0.0334 - val_mae: 23954.5898\n",
      "Epoch 746/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0433 - mae: 27383.7910 - val_loss: 0.0334 - val_mae: 23948.2715\n",
      "Epoch 747/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0432 - mae: 27322.6484 - val_loss: 0.0334 - val_mae: 23936.5273\n",
      "Epoch 748/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0432 - mae: 27298.6055 - val_loss: 0.0333 - val_mae: 23926.3848\n",
      "Epoch 749/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0432 - mae: 27326.0000 - val_loss: 0.0334 - val_mae: 23929.7344\n",
      "Epoch 750/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0433 - mae: 27339.9766 - val_loss: 0.0333 - val_mae: 23922.1738\n",
      "Epoch 751/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0432 - mae: 27316.2129 - val_loss: 0.0334 - val_mae: 23924.9219\n",
      "Epoch 752/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0432 - mae: 27259.4629 - val_loss: 0.0333 - val_mae: 23900.4707\n",
      "Epoch 753/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0431 - mae: 27264.8145 - val_loss: 0.0333 - val_mae: 23891.9668\n",
      "Epoch 754/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0431 - mae: 27254.7363 - val_loss: 0.0333 - val_mae: 23893.4941\n",
      "Epoch 755/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0431 - mae: 27265.2129 - val_loss: 0.0332 - val_mae: 23874.9863\n",
      "Epoch 756/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0430 - mae: 27235.6465 - val_loss: 0.0333 - val_mae: 23878.3301\n",
      "Epoch 757/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0431 - mae: 27303.3418 - val_loss: 0.0332 - val_mae: 23870.1113\n",
      "Epoch 758/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0430 - mae: 27213.8750 - val_loss: 0.0332 - val_mae: 23858.4316\n",
      "Epoch 759/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0430 - mae: 27179.0996 - val_loss: 0.0332 - val_mae: 23852.0723\n",
      "Epoch 760/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0430 - mae: 27256.0605 - val_loss: 0.0332 - val_mae: 23864.2520\n",
      "Epoch 761/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0429 - mae: 27183.7363 - val_loss: 0.0332 - val_mae: 23843.9395\n",
      "Epoch 762/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0429 - mae: 27186.0117 - val_loss: 0.0332 - val_mae: 23837.3027\n",
      "Epoch 763/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0429 - mae: 27164.0117 - val_loss: 0.0331 - val_mae: 23825.0469\n",
      "Epoch 764/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0429 - mae: 27161.5391 - val_loss: 0.0331 - val_mae: 23813.9395\n",
      "Epoch 765/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0430 - mae: 27267.6270 - val_loss: 0.0332 - val_mae: 23833.2422\n",
      "Epoch 766/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0428 - mae: 27133.5664 - val_loss: 0.0331 - val_mae: 23816.3574\n",
      "Epoch 767/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0428 - mae: 27121.5723 - val_loss: 0.0331 - val_mae: 23809.7949\n",
      "Epoch 768/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0428 - mae: 27149.7070 - val_loss: 0.0331 - val_mae: 23805.9531\n",
      "Epoch 769/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0427 - mae: 27121.3613 - val_loss: 0.0331 - val_mae: 23805.0723\n",
      "Epoch 770/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0428 - mae: 27113.4941 - val_loss: 0.0331 - val_mae: 23801.8906\n",
      "Epoch 771/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0427 - mae: 27128.8691 - val_loss: 0.0330 - val_mae: 23777.7344\n",
      "Epoch 772/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0427 - mae: 27075.4141 - val_loss: 0.0330 - val_mae: 23780.8008\n",
      "Epoch 773/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0427 - mae: 27104.6445 - val_loss: 0.0330 - val_mae: 23777.6758\n",
      "Epoch 774/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0427 - mae: 27062.4336 - val_loss: 0.0330 - val_mae: 23759.4668\n",
      "Epoch 775/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0426 - mae: 27079.5020 - val_loss: 0.0330 - val_mae: 23773.6348\n",
      "Epoch 776/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0426 - mae: 27070.4062 - val_loss: 0.0330 - val_mae: 23752.3770\n",
      "Epoch 777/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0426 - mae: 27043.7988 - val_loss: 0.0330 - val_mae: 23750.7871\n",
      "Epoch 778/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0427 - mae: 27106.9805 - val_loss: 0.0330 - val_mae: 23746.7910\n",
      "Epoch 779/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0426 - mae: 27004.4160 - val_loss: 0.0329 - val_mae: 23739.0684\n",
      "Epoch 780/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0427 - mae: 27104.2285 - val_loss: 0.0329 - val_mae: 23733.0293\n",
      "Epoch 781/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0426 - mae: 27003.7070 - val_loss: 0.0329 - val_mae: 23713.9902\n",
      "Epoch 782/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0425 - mae: 26997.3711 - val_loss: 0.0330 - val_mae: 23738.5039\n",
      "Epoch 783/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0425 - mae: 27047.0020 - val_loss: 0.0329 - val_mae: 23727.6992\n",
      "Epoch 784/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0425 - mae: 27009.3945 - val_loss: 0.0329 - val_mae: 23710.1074\n",
      "Epoch 785/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0424 - mae: 26999.4609 - val_loss: 0.0329 - val_mae: 23714.3535\n",
      "Epoch 786/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0424 - mae: 27000.5723 - val_loss: 0.0329 - val_mae: 23704.3809\n",
      "Epoch 787/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0424 - mae: 26960.0918 - val_loss: 0.0329 - val_mae: 23696.1523\n",
      "Epoch 788/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0424 - mae: 26973.2617 - val_loss: 0.0329 - val_mae: 23704.0938\n",
      "Epoch 789/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0424 - mae: 26982.4746 - val_loss: 0.0329 - val_mae: 23701.4746\n",
      "Epoch 790/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0424 - mae: 26966.0371 - val_loss: 0.0328 - val_mae: 23679.8086\n",
      "Epoch 791/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0424 - mae: 26938.0508 - val_loss: 0.0328 - val_mae: 23684.9414\n",
      "Epoch 792/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0424 - mae: 26950.1074 - val_loss: 0.0329 - val_mae: 23691.4512\n",
      "Epoch 793/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0423 - mae: 26952.1914 - val_loss: 0.0328 - val_mae: 23682.4609\n",
      "Epoch 794/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0423 - mae: 26923.6934 - val_loss: 0.0328 - val_mae: 23658.0918\n",
      "Epoch 795/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0423 - mae: 26920.1719 - val_loss: 0.0328 - val_mae: 23663.3418\n",
      "Epoch 796/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0423 - mae: 26912.0801 - val_loss: 0.0328 - val_mae: 23655.7695\n",
      "Epoch 797/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0423 - mae: 26928.7969 - val_loss: 0.0328 - val_mae: 23664.5664\n",
      "Epoch 798/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0423 - mae: 26912.3418 - val_loss: 0.0328 - val_mae: 23654.5176\n",
      "Epoch 799/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0422 - mae: 26911.1348 - val_loss: 0.0328 - val_mae: 23651.6328\n",
      "Epoch 800/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0422 - mae: 26912.0430 - val_loss: 0.0328 - val_mae: 23651.0801\n",
      "Epoch 801/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0422 - mae: 26889.2930 - val_loss: 0.0328 - val_mae: 23647.7148\n",
      "Epoch 802/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0422 - mae: 26909.9668 - val_loss: 0.0328 - val_mae: 23651.1406\n",
      "Epoch 803/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0422 - mae: 26877.0117 - val_loss: 0.0327 - val_mae: 23619.4941\n",
      "Epoch 804/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0422 - mae: 26919.7109 - val_loss: 0.0329 - val_mae: 23683.0586\n",
      "Epoch 805/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0422 - mae: 26861.1738 - val_loss: 0.0327 - val_mae: 23618.6738\n",
      "Epoch 806/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0422 - mae: 26849.4668 - val_loss: 0.0327 - val_mae: 23630.0488\n",
      "Epoch 807/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0421 - mae: 26868.9473 - val_loss: 0.0327 - val_mae: 23617.3867\n",
      "Epoch 808/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0421 - mae: 26826.1328 - val_loss: 0.0327 - val_mae: 23608.3242\n",
      "Epoch 809/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0421 - mae: 26853.4277 - val_loss: 0.0327 - val_mae: 23620.4863\n",
      "Epoch 810/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0421 - mae: 26824.6699 - val_loss: 0.0327 - val_mae: 23607.1797\n",
      "Epoch 811/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0421 - mae: 26851.8711 - val_loss: 0.0327 - val_mae: 23603.9805\n",
      "Epoch 812/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0421 - mae: 26818.1289 - val_loss: 0.0327 - val_mae: 23594.7988\n",
      "Epoch 813/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0420 - mae: 26803.2559 - val_loss: 0.0326 - val_mae: 23592.5215\n",
      "Epoch 814/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0420 - mae: 26831.0430 - val_loss: 0.0327 - val_mae: 23607.6133\n",
      "Epoch 815/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0420 - mae: 26789.5996 - val_loss: 0.0326 - val_mae: 23584.0312\n",
      "Epoch 816/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0420 - mae: 26793.4980 - val_loss: 0.0327 - val_mae: 23588.9609\n",
      "Epoch 817/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0420 - mae: 26857.8984 - val_loss: 0.0326 - val_mae: 23575.3047\n",
      "Epoch 818/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0420 - mae: 26770.5430 - val_loss: 0.0326 - val_mae: 23564.9512\n",
      "Epoch 819/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0420 - mae: 26804.4238 - val_loss: 0.0326 - val_mae: 23582.7676\n",
      "Epoch 820/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0419 - mae: 26773.9766 - val_loss: 0.0326 - val_mae: 23571.9004\n",
      "Epoch 821/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0419 - mae: 26795.2344 - val_loss: 0.0326 - val_mae: 23581.9805\n",
      "Epoch 822/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0419 - mae: 26759.5488 - val_loss: 0.0326 - val_mae: 23547.9805\n",
      "Epoch 823/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0419 - mae: 26751.9668 - val_loss: 0.0326 - val_mae: 23561.8203\n",
      "Epoch 824/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0419 - mae: 26769.0781 - val_loss: 0.0326 - val_mae: 23573.2559\n",
      "Epoch 825/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0419 - mae: 26770.1719 - val_loss: 0.0326 - val_mae: 23564.3438\n",
      "Epoch 826/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0419 - mae: 26742.4102 - val_loss: 0.0326 - val_mae: 23552.6035\n",
      "Epoch 827/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0419 - mae: 26775.4863 - val_loss: 0.0326 - val_mae: 23555.1504\n",
      "Epoch 828/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0418 - mae: 26738.4531 - val_loss: 0.0326 - val_mae: 23542.1680\n",
      "Epoch 829/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0419 - mae: 26713.2812 - val_loss: 0.0326 - val_mae: 23545.1230\n",
      "Epoch 830/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0419 - mae: 26792.9082 - val_loss: 0.0326 - val_mae: 23544.2695\n",
      "Epoch 831/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0418 - mae: 26714.4023 - val_loss: 0.0325 - val_mae: 23531.3047\n",
      "Epoch 832/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0418 - mae: 26722.6777 - val_loss: 0.0326 - val_mae: 23549.1855\n",
      "Epoch 833/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0418 - mae: 26722.1699 - val_loss: 0.0326 - val_mae: 23545.0781\n",
      "Epoch 834/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0418 - mae: 26739.7480 - val_loss: 0.0325 - val_mae: 23528.8379\n",
      "Epoch 835/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0418 - mae: 26700.1543 - val_loss: 0.0325 - val_mae: 23533.8711\n",
      "Epoch 836/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0418 - mae: 26723.4277 - val_loss: 0.0326 - val_mae: 23542.7070\n",
      "Epoch 837/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0417 - mae: 26704.5742 - val_loss: 0.0325 - val_mae: 23526.9277\n",
      "Epoch 838/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0417 - mae: 26677.1523 - val_loss: 0.0325 - val_mae: 23512.5977\n",
      "Epoch 839/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0417 - mae: 26694.1328 - val_loss: 0.0325 - val_mae: 23517.6680\n",
      "Epoch 840/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0417 - mae: 26693.8750 - val_loss: 0.0325 - val_mae: 23502.2305\n",
      "Epoch 841/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0417 - mae: 26722.6133 - val_loss: 0.0326 - val_mae: 23532.5332\n",
      "Epoch 842/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0417 - mae: 26668.9492 - val_loss: 0.0325 - val_mae: 23513.0410\n",
      "Epoch 843/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0417 - mae: 26675.0020 - val_loss: 0.0325 - val_mae: 23519.2324\n",
      "Epoch 844/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0417 - mae: 26670.9375 - val_loss: 0.0325 - val_mae: 23524.6797\n",
      "Epoch 845/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0417 - mae: 26706.4375 - val_loss: 0.0325 - val_mae: 23515.7949\n",
      "Epoch 846/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0417 - mae: 26672.1602 - val_loss: 0.0325 - val_mae: 23517.2734\n",
      "Epoch 847/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0416 - mae: 26652.4785 - val_loss: 0.0325 - val_mae: 23492.4629\n",
      "Epoch 848/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0416 - mae: 26667.3652 - val_loss: 0.0325 - val_mae: 23500.2207\n",
      "Epoch 849/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0416 - mae: 26637.3945 - val_loss: 0.0325 - val_mae: 23491.4336\n",
      "Epoch 850/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0416 - mae: 26638.7285 - val_loss: 0.0325 - val_mae: 23503.9492\n",
      "Epoch 851/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0416 - mae: 26666.7480 - val_loss: 0.0325 - val_mae: 23493.7266\n",
      "Epoch 852/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0416 - mae: 26676.3945 - val_loss: 0.0325 - val_mae: 23489.4707\n",
      "Epoch 853/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0416 - mae: 26622.2715 - val_loss: 0.0325 - val_mae: 23482.5742\n",
      "Epoch 854/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0416 - mae: 26665.6582 - val_loss: 0.0325 - val_mae: 23521.9277\n",
      "Epoch 855/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0416 - mae: 26640.2656 - val_loss: 0.0325 - val_mae: 23491.7109\n",
      "Epoch 856/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0415 - mae: 26619.0898 - val_loss: 0.0325 - val_mae: 23488.4316\n",
      "Epoch 857/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0416 - mae: 26606.5293 - val_loss: 0.0325 - val_mae: 23494.9980\n",
      "Epoch 858/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0415 - mae: 26609.6855 - val_loss: 0.0325 - val_mae: 23486.8281\n",
      "Epoch 859/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0416 - mae: 26678.1797 - val_loss: 0.0324 - val_mae: 23466.9883\n",
      "Epoch 860/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0415 - mae: 26596.8965 - val_loss: 0.0325 - val_mae: 23486.6855\n",
      "Epoch 861/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0415 - mae: 26625.5625 - val_loss: 0.0324 - val_mae: 23467.7891\n",
      "Epoch 862/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0415 - mae: 26588.4414 - val_loss: 0.0324 - val_mae: 23459.7715\n",
      "Epoch 863/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0415 - mae: 26603.4766 - val_loss: 0.0325 - val_mae: 23498.4961\n",
      "Epoch 864/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0415 - mae: 26619.4648 - val_loss: 0.0324 - val_mae: 23471.8750\n",
      "Epoch 865/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0415 - mae: 26607.8047 - val_loss: 0.0324 - val_mae: 23459.0234\n",
      "Epoch 866/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0415 - mae: 26592.7656 - val_loss: 0.0325 - val_mae: 23485.7305\n",
      "Epoch 867/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0415 - mae: 26584.5957 - val_loss: 0.0324 - val_mae: 23443.5391\n",
      "Epoch 868/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0415 - mae: 26584.4062 - val_loss: 0.0324 - val_mae: 23454.4980\n",
      "Epoch 869/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0414 - mae: 26584.9297 - val_loss: 0.0324 - val_mae: 23459.1992\n",
      "Epoch 870/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0415 - mae: 26557.0723 - val_loss: 0.0324 - val_mae: 23470.5762\n",
      "Epoch 871/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0415 - mae: 26594.7402 - val_loss: 0.0324 - val_mae: 23459.5586\n",
      "Epoch 872/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0414 - mae: 26599.1445 - val_loss: 0.0324 - val_mae: 23455.0098\n",
      "Epoch 873/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0414 - mae: 26546.8555 - val_loss: 0.0324 - val_mae: 23442.3398\n",
      "Epoch 874/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0414 - mae: 26591.8809 - val_loss: 0.0324 - val_mae: 23462.0566\n",
      "Epoch 875/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0414 - mae: 26573.1816 - val_loss: 0.0324 - val_mae: 23450.0137\n",
      "Epoch 876/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0414 - mae: 26577.4473 - val_loss: 0.0324 - val_mae: 23428.9395\n",
      "Epoch 877/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0414 - mae: 26573.5332 - val_loss: 0.0324 - val_mae: 23456.2832\n",
      "Epoch 878/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0414 - mae: 26548.0293 - val_loss: 0.0324 - val_mae: 23439.6387\n",
      "Epoch 879/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0414 - mae: 26548.7168 - val_loss: 0.0324 - val_mae: 23440.5293\n",
      "Epoch 880/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0414 - mae: 26555.1934 - val_loss: 0.0324 - val_mae: 23428.9590\n",
      "Epoch 881/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0413 - mae: 26549.4160 - val_loss: 0.0324 - val_mae: 23450.8105\n",
      "Epoch 882/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0413 - mae: 26562.2910 - val_loss: 0.0324 - val_mae: 23438.1992\n",
      "Epoch 883/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0413 - mae: 26550.9004 - val_loss: 0.0324 - val_mae: 23422.9082\n",
      "Epoch 884/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0414 - mae: 26568.0391 - val_loss: 0.0324 - val_mae: 23409.0879\n",
      "Epoch 885/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0413 - mae: 26519.1914 - val_loss: 0.0323 - val_mae: 23409.1426\n",
      "Epoch 886/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0413 - mae: 26514.6055 - val_loss: 0.0324 - val_mae: 23433.2324\n",
      "Epoch 887/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0413 - mae: 26539.3867 - val_loss: 0.0324 - val_mae: 23442.9199\n",
      "Epoch 888/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0413 - mae: 26555.2930 - val_loss: 0.0325 - val_mae: 23469.7969\n",
      "Epoch 889/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0413 - mae: 26555.7871 - val_loss: 0.0324 - val_mae: 23455.8008\n",
      "Epoch 890/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0413 - mae: 26515.4668 - val_loss: 0.0324 - val_mae: 23411.6973\n",
      "Epoch 891/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0413 - mae: 26560.0215 - val_loss: 0.0324 - val_mae: 23407.4004\n",
      "Epoch 892/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0413 - mae: 26523.0332 - val_loss: 0.0324 - val_mae: 23434.9102\n",
      "Epoch 893/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0413 - mae: 26506.1016 - val_loss: 0.0324 - val_mae: 23424.2969\n",
      "Epoch 894/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0413 - mae: 26541.3418 - val_loss: 0.0324 - val_mae: 23419.3457\n",
      "Epoch 895/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0413 - mae: 26487.8984 - val_loss: 0.0324 - val_mae: 23416.3262\n",
      "Epoch 896/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0413 - mae: 26544.8105 - val_loss: 0.0325 - val_mae: 23465.9902\n",
      "Epoch 897/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0413 - mae: 26496.8594 - val_loss: 0.0323 - val_mae: 23385.3145\n",
      "Epoch 898/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0413 - mae: 26538.8496 - val_loss: 0.0325 - val_mae: 23467.4531\n",
      "Epoch 899/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0413 - mae: 26569.5020 - val_loss: 0.0324 - val_mae: 23408.2891\n",
      "Epoch 900/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0413 - mae: 26477.0879 - val_loss: 0.0323 - val_mae: 23395.3535\n",
      "Epoch 901/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0413 - mae: 26536.5840 - val_loss: 0.0324 - val_mae: 23410.8574\n",
      "Epoch 902/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0413 - mae: 26482.2812 - val_loss: 0.0324 - val_mae: 23420.1992\n",
      "Epoch 903/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0413 - mae: 26548.5371 - val_loss: 0.0324 - val_mae: 23409.8809\n",
      "Epoch 904/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0412 - mae: 26493.8711 - val_loss: 0.0324 - val_mae: 23397.6094\n",
      "Epoch 905/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0412 - mae: 26502.2129 - val_loss: 0.0323 - val_mae: 23385.7578\n",
      "Epoch 906/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0412 - mae: 26503.7090 - val_loss: 0.0324 - val_mae: 23399.0508\n",
      "Epoch 907/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0413 - mae: 26514.6172 - val_loss: 0.0323 - val_mae: 23381.4824\n",
      "Epoch 908/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0412 - mae: 26488.7090 - val_loss: 0.0324 - val_mae: 23402.2363\n",
      "Epoch 909/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0412 - mae: 26517.7305 - val_loss: 0.0324 - val_mae: 23399.1289\n",
      "Epoch 910/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0412 - mae: 26462.7344 - val_loss: 0.0323 - val_mae: 23376.3711\n",
      "Epoch 911/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0412 - mae: 26474.9805 - val_loss: 0.0324 - val_mae: 23438.4551\n",
      "Epoch 912/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0412 - mae: 26510.1445 - val_loss: 0.0323 - val_mae: 23383.8770\n",
      "Epoch 913/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0412 - mae: 26460.0586 - val_loss: 0.0323 - val_mae: 23386.9883\n",
      "Epoch 914/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0412 - mae: 26496.5059 - val_loss: 0.0324 - val_mae: 23401.9570\n",
      "Epoch 915/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0412 - mae: 26454.4844 - val_loss: 0.0324 - val_mae: 23395.9121\n",
      "Epoch 916/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0412 - mae: 26465.7656 - val_loss: 0.0324 - val_mae: 23407.7793\n",
      "Epoch 917/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0412 - mae: 26510.2363 - val_loss: 0.0324 - val_mae: 23402.5352\n",
      "Epoch 918/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0412 - mae: 26441.7480 - val_loss: 0.0323 - val_mae: 23383.2930\n",
      "Epoch 919/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0412 - mae: 26507.5020 - val_loss: 0.0324 - val_mae: 23406.0938\n",
      "Epoch 920/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0412 - mae: 26464.0430 - val_loss: 0.0323 - val_mae: 23369.1582\n",
      "Epoch 921/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0412 - mae: 26499.6367 - val_loss: 0.0324 - val_mae: 23408.1230\n",
      "Epoch 922/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0411 - mae: 26457.5664 - val_loss: 0.0323 - val_mae: 23378.4727\n",
      "Epoch 923/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0411 - mae: 26460.4746 - val_loss: 0.0324 - val_mae: 23389.1191\n",
      "Epoch 924/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0411 - mae: 26435.0996 - val_loss: 0.0323 - val_mae: 23364.0703\n",
      "Epoch 925/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0411 - mae: 26485.7344 - val_loss: 0.0324 - val_mae: 23408.9824\n",
      "Epoch 926/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0412 - mae: 26447.2148 - val_loss: 0.0324 - val_mae: 23394.9023\n",
      "Epoch 927/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0411 - mae: 26508.9082 - val_loss: 0.0324 - val_mae: 23410.6387\n",
      "Epoch 928/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0411 - mae: 26447.4531 - val_loss: 0.0324 - val_mae: 23387.6699\n",
      "Epoch 929/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0411 - mae: 26482.3535 - val_loss: 0.0324 - val_mae: 23436.7051\n",
      "Epoch 930/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0411 - mae: 26438.4629 - val_loss: 0.0323 - val_mae: 23354.3809\n",
      "Epoch 931/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0411 - mae: 26467.7266 - val_loss: 0.0324 - val_mae: 23390.7598\n",
      "Epoch 932/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0411 - mae: 26470.0332 - val_loss: 0.0323 - val_mae: 23375.6777\n",
      "Epoch 933/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0411 - mae: 26449.2637 - val_loss: 0.0323 - val_mae: 23358.9082\n",
      "Epoch 934/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0411 - mae: 26484.2422 - val_loss: 0.0324 - val_mae: 23412.7910\n",
      "Epoch 935/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0411 - mae: 26452.4922 - val_loss: 0.0323 - val_mae: 23364.3926\n",
      "Epoch 936/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0411 - mae: 26450.6426 - val_loss: 0.0324 - val_mae: 23431.7188\n",
      "Epoch 937/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0411 - mae: 26451.4844 - val_loss: 0.0323 - val_mae: 23358.9902\n",
      "Epoch 938/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0411 - mae: 26461.4824 - val_loss: 0.0324 - val_mae: 23389.8789\n",
      "Epoch 939/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0411 - mae: 26401.0918 - val_loss: 0.0323 - val_mae: 23364.9316\n",
      "Epoch 940/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0410 - mae: 26455.4473 - val_loss: 0.0324 - val_mae: 23413.5957\n",
      "Epoch 941/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0411 - mae: 26459.8359 - val_loss: 0.0324 - val_mae: 23382.4961\n",
      "Epoch 942/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0411 - mae: 26417.7148 - val_loss: 0.0323 - val_mae: 23353.6797\n",
      "Epoch 943/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0411 - mae: 26454.8594 - val_loss: 0.0324 - val_mae: 23407.5527\n",
      "Epoch 944/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0410 - mae: 26432.8496 - val_loss: 0.0324 - val_mae: 23391.8574\n",
      "Epoch 945/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0411 - mae: 26401.8770 - val_loss: 0.0323 - val_mae: 23340.4121\n",
      "Epoch 946/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0411 - mae: 26505.8613 - val_loss: 0.0324 - val_mae: 23411.9297\n",
      "Epoch 947/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0411 - mae: 26406.5723 - val_loss: 0.0324 - val_mae: 23367.8750\n",
      "Epoch 948/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0411 - mae: 26463.0293 - val_loss: 0.0324 - val_mae: 23389.4102\n",
      "Epoch 949/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0410 - mae: 26393.8008 - val_loss: 0.0323 - val_mae: 23340.3652\n",
      "Epoch 950/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0410 - mae: 26434.2617 - val_loss: 0.0324 - val_mae: 23373.2832\n",
      "Epoch 951/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0411 - mae: 26412.3262 - val_loss: 0.0324 - val_mae: 23386.1953\n",
      "Epoch 952/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0410 - mae: 26429.8789 - val_loss: 0.0324 - val_mae: 23411.5840\n",
      "Epoch 953/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0410 - mae: 26452.6855 - val_loss: 0.0324 - val_mae: 23388.2793\n",
      "Epoch 954/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0410 - mae: 26415.8594 - val_loss: 0.0324 - val_mae: 23394.3145\n",
      "Epoch 955/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0410 - mae: 26412.5684 - val_loss: 0.0324 - val_mae: 23369.6562\n",
      "Epoch 956/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0411 - mae: 26462.4102 - val_loss: 0.0324 - val_mae: 23362.6895\n",
      "Epoch 957/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0410 - mae: 26399.4863 - val_loss: 0.0324 - val_mae: 23386.9570\n",
      "Epoch 958/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0411 - mae: 26401.3320 - val_loss: 0.0324 - val_mae: 23378.1094\n",
      "Epoch 959/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0411 - mae: 26467.1719 - val_loss: 0.0324 - val_mae: 23371.4980\n",
      "Epoch 960/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0410 - mae: 26399.2500 - val_loss: 0.0324 - val_mae: 23378.0293\n",
      "Epoch 961/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0410 - mae: 26409.9473 - val_loss: 0.0324 - val_mae: 23389.1523\n",
      "Epoch 962/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0411 - mae: 26473.0391 - val_loss: 0.0323 - val_mae: 23358.0039\n",
      "Epoch 963/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0411 - mae: 26413.1445 - val_loss: 0.0324 - val_mae: 23373.3535\n",
      "Epoch 964/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0411 - mae: 26377.1406 - val_loss: 0.0323 - val_mae: 23367.9121\n",
      "Epoch 965/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0410 - mae: 26424.8809 - val_loss: 0.0324 - val_mae: 23401.9668\n",
      "Epoch 966/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0410 - mae: 26444.6738 - val_loss: 0.0324 - val_mae: 23387.2852\n",
      "Epoch 967/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0410 - mae: 26404.6172 - val_loss: 0.0324 - val_mae: 23358.2207\n",
      "Epoch 968/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0410 - mae: 26368.2617 - val_loss: 0.0323 - val_mae: 23352.3965\n",
      "Epoch 969/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0411 - mae: 26482.1523 - val_loss: 0.0324 - val_mae: 23357.8613\n",
      "Epoch 970/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0410 - mae: 26433.6426 - val_loss: 0.0324 - val_mae: 23359.3242\n",
      "Epoch 971/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0410 - mae: 26346.7852 - val_loss: 0.0323 - val_mae: 23345.2754\n",
      "Epoch 972/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0410 - mae: 26414.4473 - val_loss: 0.0325 - val_mae: 23415.4785\n",
      "Epoch 973/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0410 - mae: 26445.2656 - val_loss: 0.0324 - val_mae: 23348.9297\n",
      "Epoch 974/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0410 - mae: 26372.6328 - val_loss: 0.0324 - val_mae: 23350.9707\n",
      "Epoch 975/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0410 - mae: 26383.4766 - val_loss: 0.0324 - val_mae: 23376.2891\n",
      "Epoch 976/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0410 - mae: 26471.6172 - val_loss: 0.0324 - val_mae: 23383.6484\n",
      "Epoch 977/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0410 - mae: 26377.7656 - val_loss: 0.0323 - val_mae: 23340.0605\n",
      "Epoch 978/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0410 - mae: 26426.3633 - val_loss: 0.0324 - val_mae: 23360.2461\n",
      "Epoch 979/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0409 - mae: 26393.5488 - val_loss: 0.0324 - val_mae: 23364.8984\n",
      "Epoch 980/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0409 - mae: 26401.6699 - val_loss: 0.0324 - val_mae: 23346.8457\n",
      "Epoch 981/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0409 - mae: 26386.6680 - val_loss: 0.0324 - val_mae: 23365.1328\n",
      "Epoch 982/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0409 - mae: 26402.1953 - val_loss: 0.0324 - val_mae: 23357.7637\n",
      "Epoch 983/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0409 - mae: 26368.7090 - val_loss: 0.0324 - val_mae: 23365.4922\n",
      "Epoch 984/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0409 - mae: 26397.5723 - val_loss: 0.0324 - val_mae: 23352.8262\n",
      "Epoch 985/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0410 - mae: 26401.8555 - val_loss: 0.0324 - val_mae: 23357.1074\n",
      "Epoch 986/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0410 - mae: 26382.7988 - val_loss: 0.0324 - val_mae: 23362.9805\n",
      "Epoch 987/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0410 - mae: 26437.2188 - val_loss: 0.0324 - val_mae: 23376.1328\n",
      "Epoch 988/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0409 - mae: 26369.5527 - val_loss: 0.0324 - val_mae: 23344.5586\n",
      "Epoch 989/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0409 - mae: 26357.9492 - val_loss: 0.0324 - val_mae: 23347.2207\n",
      "Epoch 990/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0409 - mae: 26368.6797 - val_loss: 0.0324 - val_mae: 23360.3242\n",
      "Epoch 991/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0409 - mae: 26420.9824 - val_loss: 0.0325 - val_mae: 23417.3516\n",
      "Epoch 992/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0409 - mae: 26394.3652 - val_loss: 0.0324 - val_mae: 23348.8906\n",
      "Epoch 993/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0409 - mae: 26369.0586 - val_loss: 0.0324 - val_mae: 23352.6680\n",
      "Epoch 994/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0409 - mae: 26378.6289 - val_loss: 0.0324 - val_mae: 23357.3066\n",
      "Epoch 995/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0409 - mae: 26369.6172 - val_loss: 0.0324 - val_mae: 23347.7715\n",
      "Epoch 996/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0409 - mae: 26389.9023 - val_loss: 0.0324 - val_mae: 23347.3770\n",
      "Epoch 997/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0409 - mae: 26367.3418 - val_loss: 0.0324 - val_mae: 23334.7383\n",
      "Epoch 998/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0409 - mae: 26369.8301 - val_loss: 0.0324 - val_mae: 23334.8320\n",
      "Epoch 999/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0409 - mae: 26361.4727 - val_loss: 0.0324 - val_mae: 23353.3613\n",
      "Epoch 1000/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0409 - mae: 26382.4707 - val_loss: 0.0324 - val_mae: 23373.5684\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5e1239f520>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=1000, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6uyqJ-rycHwk",
    "outputId": "e3e50a70-a10c-473c-a62c-4c83796fa4c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 153\n",
      "Trainable params: 153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Seca2eEWxinC"
   },
   "outputs": [],
   "source": [
    "new_data = np.array([[0.39130435, 0.        , 0.13127591, 0.25      , 0.        ,\n",
    "       0.33333333, 0.18181818, 0.75      ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PJE0O-0Bx9O0",
    "outputId": "f602b738-f58d-4280-fa7b-7287e14ab360"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.39130435, 0.        , 0.13127591, 0.25      , 0.        ,\n",
       "       0.33333333, 0.18181818, 0.75      ])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z72ixRt7xXp2",
    "outputId": "53db44a0-f4d2-4cde-9b78-a8008d56c3b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[117541.01]], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lTsRpiLoye3s",
    "outputId": "5a604282-a8d8-4e8c-b6ae-a5b892271e9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "809     166000\n",
       "1446    268500\n",
       "761     119000\n",
       "318     128500\n",
       "961     210000\n",
       "         ...  \n",
       "1027    200100\n",
       "1010    156500\n",
       "25      168165\n",
       "1285    221000\n",
       "1712    275000\n",
       "Name: SalePrice, Length: 517, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AC-1eSMVxdyA",
    "outputId": "1be730b5-cf0f-4e13-98d3-2cc315fa979d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.87681159, 0.        , 0.19714417, ..., 0.5       , 0.36363636,\n",
       "        0.75      ],\n",
       "       [0.92028986, 0.60042735, 0.43298019, ..., 0.5       , 0.54545455,\n",
       "        0.        ],\n",
       "       [0.39130435, 0.        , 0.13127591, ..., 0.33333333, 0.18181818,\n",
       "        0.75      ],\n",
       "       ...,\n",
       "       [0.97101449, 0.45405983, 0.25886688, ..., 0.5       , 0.36363636,\n",
       "        0.25      ],\n",
       "       [0.94202899, 0.        , 0.26715799, ..., 0.5       , 0.36363636,\n",
       "        0.5       ],\n",
       "       [0.95652174, 0.        , 0.3021649 , ..., 0.33333333, 0.27272727,\n",
       "        0.5       ]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5zR6To1Km07v",
    "outputId": "fef5db1b-5b24-446c-c85a-5c40933ad3fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 1ms/step - loss: 2820615936.0000\n"
     ]
    }
   ],
   "source": [
    "mse = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KHHVERTKm7Df",
    "outputId": "3ac7447b-e87e-4024-a0cc-c6b3314de658"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2820615936.0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6b2ijPDZocmU",
    "outputId": "63eca5c6-abf4-4c66-d35a-1dd3ac3a624b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "new_data = scaler.transform(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9aGBjAqyqcpY",
    "outputId": "baa7d844-e518-4174-e960-c0edfee90cd5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.93478261, 0.45673077, 0.30654076, 0.5       , 0.5       ,\n",
       "        0.5       , 0.36363636, 0.75      ]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_aHkM7m5noEy",
    "outputId": "a6fd823f-1cbb-4948-d224-df65c55c93b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[227439.48]], dtype=float32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_IHGb1eakHK8"
   },
   "outputs": [],
   "source": [
    "df1 = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o0Ib9ecwkavc"
   },
   "outputs": [],
   "source": [
    "df1 = df1.drop('PID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "HSuO7CcZkmnS",
    "outputId": "19fb92de-4d04-499b-aa8f-fcd47b4c203b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-5b23dae3-e358-411e-9af6-3698e8ded8e7\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>...</th>\n",
       "      <th>total_returns</th>\n",
       "      <th>adj_gross_inc</th>\n",
       "      <th>agi_per_ret</th>\n",
       "      <th>perc_business_ret</th>\n",
       "      <th>perc_farm_ret</th>\n",
       "      <th>perc_umemp_ret</th>\n",
       "      <th>perc_ssn_benefits</th>\n",
       "      <th>perc_student_loans</th>\n",
       "      <th>perc_child_credits</th>\n",
       "      <th>Perc_earned_inc_tax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>856</td>\n",
       "      <td>126000</td>\n",
       "      <td>68.516053</td>\n",
       "      <td>7890</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1939</td>\n",
       "      <td>1950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>14090.000000</td>\n",
       "      <td>1.036620e+06</td>\n",
       "      <td>73571.327182</td>\n",
       "      <td>0.021309</td>\n",
       "      <td>0.011356</td>\n",
       "      <td>0.134138</td>\n",
       "      <td>0.052438</td>\n",
       "      <td>0.107168</td>\n",
       "      <td>0.006404</td>\n",
       "      <td>0.002166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1049</td>\n",
       "      <td>139500</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>4235</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1984</td>\n",
       "      <td>1984</td>\n",
       "      <td>149.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>11300.000000</td>\n",
       "      <td>8.727720e+05</td>\n",
       "      <td>77236.460177</td>\n",
       "      <td>0.020427</td>\n",
       "      <td>0.013274</td>\n",
       "      <td>0.131858</td>\n",
       "      <td>0.036921</td>\n",
       "      <td>0.111504</td>\n",
       "      <td>0.006293</td>\n",
       "      <td>0.001735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>124900</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>6060</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1930</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>14090.000000</td>\n",
       "      <td>1.036620e+06</td>\n",
       "      <td>73571.327182</td>\n",
       "      <td>0.021309</td>\n",
       "      <td>0.011356</td>\n",
       "      <td>0.134138</td>\n",
       "      <td>0.052438</td>\n",
       "      <td>0.107168</td>\n",
       "      <td>0.006404</td>\n",
       "      <td>0.002166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1039</td>\n",
       "      <td>114000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8146</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1900</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>14090.000000</td>\n",
       "      <td>1.036620e+06</td>\n",
       "      <td>73571.327182</td>\n",
       "      <td>0.021309</td>\n",
       "      <td>0.011356</td>\n",
       "      <td>0.134138</td>\n",
       "      <td>0.052438</td>\n",
       "      <td>0.107168</td>\n",
       "      <td>0.006404</td>\n",
       "      <td>0.002166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1665</td>\n",
       "      <td>227000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>8400</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>2001</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>14090.000000</td>\n",
       "      <td>1.036620e+06</td>\n",
       "      <td>73571.327182</td>\n",
       "      <td>0.021309</td>\n",
       "      <td>0.011356</td>\n",
       "      <td>0.134138</td>\n",
       "      <td>0.052438</td>\n",
       "      <td>0.107168</td>\n",
       "      <td>0.006404</td>\n",
       "      <td>0.002166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577</th>\n",
       "      <td>952</td>\n",
       "      <td>121000</td>\n",
       "      <td>68.516053</td>\n",
       "      <td>8854</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1916</td>\n",
       "      <td>1950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>14090.000000</td>\n",
       "      <td>1.036620e+06</td>\n",
       "      <td>73571.327182</td>\n",
       "      <td>0.021309</td>\n",
       "      <td>0.011356</td>\n",
       "      <td>0.134138</td>\n",
       "      <td>0.052438</td>\n",
       "      <td>0.107168</td>\n",
       "      <td>0.006404</td>\n",
       "      <td>0.002166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2578</th>\n",
       "      <td>1733</td>\n",
       "      <td>139600</td>\n",
       "      <td>68.516053</td>\n",
       "      <td>13680</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1955</td>\n",
       "      <td>1955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>11300.000000</td>\n",
       "      <td>8.727720e+05</td>\n",
       "      <td>77236.460177</td>\n",
       "      <td>0.020427</td>\n",
       "      <td>0.013274</td>\n",
       "      <td>0.131858</td>\n",
       "      <td>0.036921</td>\n",
       "      <td>0.111504</td>\n",
       "      <td>0.006293</td>\n",
       "      <td>0.001735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2579</th>\n",
       "      <td>2002</td>\n",
       "      <td>145000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>6270</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1949</td>\n",
       "      <td>1950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>12778.271309</td>\n",
       "      <td>9.581146e+05</td>\n",
       "      <td>75180.309062</td>\n",
       "      <td>0.021022</td>\n",
       "      <td>0.014220</td>\n",
       "      <td>0.134879</td>\n",
       "      <td>0.046541</td>\n",
       "      <td>0.108049</td>\n",
       "      <td>0.006515</td>\n",
       "      <td>0.002067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2580</th>\n",
       "      <td>1842</td>\n",
       "      <td>217500</td>\n",
       "      <td>68.516053</td>\n",
       "      <td>8826</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>144.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>11300.000000</td>\n",
       "      <td>8.727720e+05</td>\n",
       "      <td>77236.460177</td>\n",
       "      <td>0.020427</td>\n",
       "      <td>0.013274</td>\n",
       "      <td>0.131858</td>\n",
       "      <td>0.036921</td>\n",
       "      <td>0.111504</td>\n",
       "      <td>0.006293</td>\n",
       "      <td>0.001735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2581</th>\n",
       "      <td>1911</td>\n",
       "      <td>215000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>9554</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1993</td>\n",
       "      <td>1994</td>\n",
       "      <td>125.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>11300.000000</td>\n",
       "      <td>8.727720e+05</td>\n",
       "      <td>77236.460177</td>\n",
       "      <td>0.020427</td>\n",
       "      <td>0.013274</td>\n",
       "      <td>0.131858</td>\n",
       "      <td>0.036921</td>\n",
       "      <td>0.111504</td>\n",
       "      <td>0.006293</td>\n",
       "      <td>0.001735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2582 rows × 269 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b23dae3-e358-411e-9af6-3698e8ded8e7')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-5b23dae3-e358-411e-9af6-3698e8ded8e7 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-5b23dae3-e358-411e-9af6-3698e8ded8e7');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      GrLivArea  SalePrice  LotFrontage  LotArea  OverallQual  OverallCond  \\\n",
       "0           856     126000    68.516053     7890            6            6   \n",
       "1          1049     139500    42.000000     4235            5            5   \n",
       "2          1001     124900    60.000000     6060            5            9   \n",
       "3          1039     114000    80.000000     8146            4            8   \n",
       "4          1665     227000    70.000000     8400            8            6   \n",
       "...         ...        ...          ...      ...          ...          ...   \n",
       "2577        952     121000    68.516053     8854            6            6   \n",
       "2578       1733     139600    68.516053    13680            3            5   \n",
       "2579       2002     145000    82.000000     6270            5            6   \n",
       "2580       1842     217500    68.516053     8826            7            5   \n",
       "2581       1911     215000    80.000000     9554            8            5   \n",
       "\n",
       "      YearBuilt  YearRemodAdd  MasVnrArea  ExterQual  ...  total_returns  \\\n",
       "0          1939          1950         0.0          3  ...   14090.000000   \n",
       "1          1984          1984       149.0          4  ...   11300.000000   \n",
       "2          1930          2007         0.0          4  ...   14090.000000   \n",
       "3          1900          2003         0.0          4  ...   14090.000000   \n",
       "4          2001          2001         0.0          4  ...   14090.000000   \n",
       "...         ...           ...         ...        ...  ...            ...   \n",
       "2577       1916          1950         0.0          3  ...   14090.000000   \n",
       "2578       1955          1955         0.0          3  ...   11300.000000   \n",
       "2579       1949          1950         0.0          3  ...   12778.271309   \n",
       "2580       2000          2000       144.0          4  ...   11300.000000   \n",
       "2581       1993          1994       125.0          4  ...   11300.000000   \n",
       "\n",
       "      adj_gross_inc   agi_per_ret  perc_business_ret  perc_farm_ret  \\\n",
       "0      1.036620e+06  73571.327182           0.021309       0.011356   \n",
       "1      8.727720e+05  77236.460177           0.020427       0.013274   \n",
       "2      1.036620e+06  73571.327182           0.021309       0.011356   \n",
       "3      1.036620e+06  73571.327182           0.021309       0.011356   \n",
       "4      1.036620e+06  73571.327182           0.021309       0.011356   \n",
       "...             ...           ...                ...            ...   \n",
       "2577   1.036620e+06  73571.327182           0.021309       0.011356   \n",
       "2578   8.727720e+05  77236.460177           0.020427       0.013274   \n",
       "2579   9.581146e+05  75180.309062           0.021022       0.014220   \n",
       "2580   8.727720e+05  77236.460177           0.020427       0.013274   \n",
       "2581   8.727720e+05  77236.460177           0.020427       0.013274   \n",
       "\n",
       "      perc_umemp_ret  perc_ssn_benefits  perc_student_loans  \\\n",
       "0           0.134138           0.052438            0.107168   \n",
       "1           0.131858           0.036921            0.111504   \n",
       "2           0.134138           0.052438            0.107168   \n",
       "3           0.134138           0.052438            0.107168   \n",
       "4           0.134138           0.052438            0.107168   \n",
       "...              ...                ...                 ...   \n",
       "2577        0.134138           0.052438            0.107168   \n",
       "2578        0.131858           0.036921            0.111504   \n",
       "2579        0.134879           0.046541            0.108049   \n",
       "2580        0.131858           0.036921            0.111504   \n",
       "2581        0.131858           0.036921            0.111504   \n",
       "\n",
       "      perc_child_credits  Perc_earned_inc_tax  \n",
       "0               0.006404             0.002166  \n",
       "1               0.006293             0.001735  \n",
       "2               0.006404             0.002166  \n",
       "3               0.006404             0.002166  \n",
       "4               0.006404             0.002166  \n",
       "...                  ...                  ...  \n",
       "2577            0.006404             0.002166  \n",
       "2578            0.006293             0.001735  \n",
       "2579            0.006515             0.002067  \n",
       "2580            0.006293             0.001735  \n",
       "2581            0.006293             0.001735  \n",
       "\n",
       "[2582 rows x 269 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C3jHT6RZks6_"
   },
   "outputs": [],
   "source": [
    "X = df1.drop('SalePrice', axis=1)\n",
    "y = df1['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K8ovaufykzNl"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kBBcbNJmk5y6"
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PFeJcFoJk_k_"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(268, activation='relu', input_shape=(268,)))\n",
    "model.add(keras.layers.Dense(268, activation='relu'))\n",
    "model.add(keras.layers.Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_logarithmic_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wdn0-jTtlKcb",
    "outputId": "5b11fbe9-c9e5-46fc-cbfe-63e179979d20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "26/26 [==============================] - 3s 14ms/step - loss: 124.8829 - val_loss: 84.9941\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 64.9512 - val_loss: 50.7576\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 44.0525 - val_loss: 38.4686\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 34.8790 - val_loss: 31.6464\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 29.2290 - val_loss: 27.0070\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 25.2363 - val_loss: 23.5955\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 22.2127 - val_loss: 20.9259\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 19.8031 - val_loss: 18.7617\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 17.8324 - val_loss: 16.9809\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 16.1968 - val_loss: 15.4835\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 14.8123 - val_loss: 14.2076\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 13.6252 - val_loss: 13.1024\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 12.5913 - val_loss: 12.1375\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 11.6835 - val_loss: 11.2842\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 10.8780 - val_loss: 10.5234\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 10.1575 - val_loss: 9.8406\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 9.5090 - val_loss: 9.2233\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 8.9211 - val_loss: 8.6630\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 8.3857 - val_loss: 8.1525\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 7.8972 - val_loss: 7.6822\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 7.4472 - val_loss: 7.2506\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 7.0328 - val_loss: 6.8522\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 6.6498 - val_loss: 6.4826\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 6.2945 - val_loss: 6.1393\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 5.9640 - val_loss: 5.8202\n",
      "Epoch 26/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 5.6559 - val_loss: 5.5219\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 5.3655 - val_loss: 5.2353\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 5.0799 - val_loss: 4.9485\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 4.7959 - val_loss: 4.6675\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 4.5214 - val_loss: 4.3991\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 4.2613 - val_loss: 4.1464\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 4.0179 - val_loss: 3.9103\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 3.7908 - val_loss: 3.6906\n",
      "Epoch 34/100\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.5795 - val_loss: 3.4869\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3833 - val_loss: 3.2969\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.2007 - val_loss: 3.1202\n",
      "Epoch 37/100\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.0307 - val_loss: 2.9553\n",
      "Epoch 38/100\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 2.8721 - val_loss: 2.8016\n",
      "Epoch 39/100\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 2.7239 - val_loss: 2.6579\n",
      "Epoch 40/100\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 2.5848 - val_loss: 2.5213\n",
      "Epoch 41/100\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 2.4503 - val_loss: 2.3874\n",
      "Epoch 42/100\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 2.3198 - val_loss: 2.2597\n",
      "Epoch 43/100\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 2.1958 - val_loss: 2.1390\n",
      "Epoch 44/100\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 2.0793 - val_loss: 2.0251\n",
      "Epoch 45/100\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.9698 - val_loss: 1.9184\n",
      "Epoch 46/100\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.8670 - val_loss: 1.8186\n",
      "Epoch 47/100\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.7707 - val_loss: 1.7251\n",
      "Epoch 48/100\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.6804 - val_loss: 1.6374\n",
      "Epoch 49/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.5957 - val_loss: 1.5546\n",
      "Epoch 50/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.5161 - val_loss: 1.4770\n",
      "Epoch 51/100\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.4412 - val_loss: 1.4039\n",
      "Epoch 52/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3708 - val_loss: 1.3350\n",
      "Epoch 53/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.3043 - val_loss: 1.2704\n",
      "Epoch 54/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.2418 - val_loss: 1.2091\n",
      "Epoch 55/100\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.1827 - val_loss: 1.1514\n",
      "Epoch 56/100\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.1270 - val_loss: 1.0967\n",
      "Epoch 57/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.0742 - val_loss: 1.0452\n",
      "Epoch 58/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1.0244 - val_loss: 0.9963\n",
      "Epoch 59/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.9773 - val_loss: 0.9500\n",
      "Epoch 60/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.9326 - val_loss: 0.9063\n",
      "Epoch 61/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.8903 - val_loss: 0.8649\n",
      "Epoch 62/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.8502 - val_loss: 0.8256\n",
      "Epoch 63/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.8123 - val_loss: 0.7881\n",
      "Epoch 64/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.7761 - val_loss: 0.7528\n",
      "Epoch 65/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.7421 - val_loss: 0.7191\n",
      "Epoch 66/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.7095 - val_loss: 0.6872\n",
      "Epoch 67/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.6787 - val_loss: 0.6568\n",
      "Epoch 68/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.6493 - val_loss: 0.6281\n",
      "Epoch 69/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.6216 - val_loss: 0.6006\n",
      "Epoch 70/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.5951 - val_loss: 0.5747\n",
      "Epoch 71/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.5701 - val_loss: 0.5497\n",
      "Epoch 72/100\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.5461 - val_loss: 0.5262\n",
      "Epoch 73/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.5234 - val_loss: 0.5039\n",
      "Epoch 74/100\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.5018 - val_loss: 0.4825\n",
      "Epoch 75/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.4813 - val_loss: 0.4622\n",
      "Epoch 76/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.4617 - val_loss: 0.4429\n",
      "Epoch 77/100\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.4431 - val_loss: 0.4247\n",
      "Epoch 78/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.4255 - val_loss: 0.4071\n",
      "Epoch 79/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.4086 - val_loss: 0.3906\n",
      "Epoch 80/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.3926 - val_loss: 0.3747\n",
      "Epoch 81/100\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.3774 - val_loss: 0.3596\n",
      "Epoch 82/100\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.3629 - val_loss: 0.3453\n",
      "Epoch 83/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.3491 - val_loss: 0.3317\n",
      "Epoch 84/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.3360 - val_loss: 0.3187\n",
      "Epoch 85/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.3236 - val_loss: 0.3062\n",
      "Epoch 86/100\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.3116 - val_loss: 0.2945\n",
      "Epoch 87/100\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.3004 - val_loss: 0.2833\n",
      "Epoch 88/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.2896 - val_loss: 0.2728\n",
      "Epoch 89/100\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.2794 - val_loss: 0.2626\n",
      "Epoch 90/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.2698 - val_loss: 0.2530\n",
      "Epoch 91/100\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.2605 - val_loss: 0.2438\n",
      "Epoch 92/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.2517 - val_loss: 0.2351\n",
      "Epoch 93/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.2434 - val_loss: 0.2268\n",
      "Epoch 94/100\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.2355 - val_loss: 0.2190\n",
      "Epoch 95/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.2280 - val_loss: 0.2115\n",
      "Epoch 96/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.2209 - val_loss: 0.2044\n",
      "Epoch 97/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.2141 - val_loss: 0.1977\n",
      "Epoch 98/100\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.2076 - val_loss: 0.1913\n",
      "Epoch 99/100\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.2015 - val_loss: 0.1852\n",
      "Epoch 100/100\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.1957 - val_loss: 0.1795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5d127e52d0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qsqxd7EoqdtX"
   },
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "id": "zfmNz7i1sQJ9",
    "outputId": "71b56ec4-394a-4e5a-ad22-fc6fea380082"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-13ee73d4-2908-4fc5-98d0-141b76cb8545\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97.796585</td>\n",
       "      <td>66.337242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.171753</td>\n",
       "      <td>46.492065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.566326</td>\n",
       "      <td>37.228935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.118919</td>\n",
       "      <td>31.234934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.997488</td>\n",
       "      <td>26.904093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.201649</td>\n",
       "      <td>23.609268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22.266285</td>\n",
       "      <td>21.010641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19.899742</td>\n",
       "      <td>18.851484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17.902672</td>\n",
       "      <td>17.017118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16.200682</td>\n",
       "      <td>15.444719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13ee73d4-2908-4fc5-98d0-141b76cb8545')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-13ee73d4-2908-4fc5-98d0-141b76cb8545 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-13ee73d4-2908-4fc5-98d0-141b76cb8545');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "        loss   val_loss\n",
       "0  97.796585  66.337242\n",
       "1  55.171753  46.492065\n",
       "2  41.566326  37.228935\n",
       "3  34.118919  31.234934\n",
       "4  28.997488  26.904093\n",
       "5  25.201649  23.609268\n",
       "6  22.266285  21.010641\n",
       "7  19.899742  18.851484\n",
       "8  17.902672  17.017118\n",
       "9  16.200682  15.444719"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
